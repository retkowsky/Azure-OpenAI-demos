{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f292f216-448c-4304-8224-0cbf9a2022c9",
   "metadata": {},
   "source": [
    "# Sora with Azure AI Foundry\n",
    "\n",
    "Sora is an AI model from OpenAI that can create realistic and imaginative video scenes from text instructions. The model is capable of generating a wide range of video content, including realistic scenes, animations, and special effects. Several video resolutions and durations are supported.\n",
    "\n",
    "https://learn.microsoft.com/en-us/azure/ai-services/openai/concepts/video-generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "efafceee-6fbf-401d-bae8-824767771471",
   "metadata": {},
   "outputs": [],
   "source": [
    "import base64\n",
    "import datetime\n",
    "import os\n",
    "import requests\n",
    "import sys\n",
    "import time\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "from IPython.display import Video, FileLink\n",
    "from moviepy import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "029dd448-1591-4548-9e75-281d717a3062",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'3.10.14 (main, May  6 2024, 19:42:50) [GCC 11.2.0]'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sys.version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cd844f89-064a-4146-97b0-8bff137f02f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Today is 02-Jun-2025 10:03:43\n"
     ]
    }
   ],
   "source": [
    "print(f\"Today is {datetime.datetime.today().strftime('%d-%b-%Y %H:%M:%S')}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2c533a5-8e6e-426d-8010-684fc17b380b",
   "metadata": {},
   "source": [
    "## Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "560fe98b-dcdc-40d7-a449-152e77ff6359",
   "metadata": {},
   "outputs": [],
   "source": [
    "OUTPUT_DIR = \"videos\"\n",
    "\n",
    "os.makedirs(OUTPUT_DIR, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5143ddfb-603d-4cef-ad78-fefa7ed70c6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv(\"azure.env\")\n",
    "\n",
    "endpoint = os.environ['AZURE_OPENAI_ENDPOINT']\n",
    "api_key = os.environ['AZURE_OPENAI_API_KEY']\n",
    "\n",
    "model = \"sora\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e20797e2-8ca9-4f63-954f-2bfa1723b3be",
   "metadata": {},
   "source": [
    "# Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e9688580-4ed4-4e58-b162-ca62613b5e8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sora(prompt, width=480, height=480, n_seconds=5):\n",
    "    \"\"\"\n",
    "    Generates a video based on the given prompt using the SORA model.\n",
    "\n",
    "    Parameters:\n",
    "    prompt (str): The text prompt to generate the video.\n",
    "    width (int): The width of the video. Supported values are 480, 854, 720, 1080, and 1920.\n",
    "    height (int): The height of the video. Supported values are 480, 854, 720, 1080, and 1920.\n",
    "    n_seconds (int): The duration of the video in seconds. Must be between 1 and 20 seconds.\n",
    "    n_variants (int): The number of video variants to generate.\n",
    "    \n",
    "    Returns:\n",
    "    str: The filename of the generated video.\n",
    "\n",
    "    Raises:\n",
    "    Exception: If the video generation job fails or no generations are found.\n",
    "    \"\"\"\n",
    "    start = time.time()\n",
    "\n",
    "    api_version = 'preview'\n",
    "    headers = {\"api-key\": api_key, \"Content-Type\": \"application/json\"}\n",
    "\n",
    "    idx = datetime.datetime.today().strftime('%d%b%Y_%H%M%S')\n",
    "    suffix = prompt[:30].replace(\",\", \"_\").replace(\".\", \"_\").replace(\" \", \"_\")\n",
    "    output_filename = os.path.join(OUTPUT_DIR, f\"sora_{idx}_{suffix}.mp4\")\n",
    "\n",
    "    # 1. Create a video generation job\n",
    "    create_url = f\"{endpoint}/openai/v1/video/generations/jobs?api-version={api_version}\"\n",
    "    \n",
    "    body = {\n",
    "        \"prompt\": prompt,\n",
    "        \"width\": width,  # 480x480, 480x854, 854x480, 720x720, 720x1280, 1280x720, 1080x1080, 1080x1920, 1920x1080.\n",
    "        \"height\": height,  # 480x480, 480x854, 854x480, 720x720, 720x1280, 1280x720, 1080x1080, 1080x1920, 1920x1080.\n",
    "        \"n_seconds\": n_seconds,  # between 1 and 20 seconds\n",
    "        \"model\": model,  # SORA model\n",
    "    }\n",
    "    response = requests.post(create_url, headers=headers, json=body)\n",
    "    response.raise_for_status()\n",
    "\n",
    "    now = datetime.datetime.today().strftime('%d-%b-%Y %H:%M:%S')\n",
    "    print(f\"{now} Full response JSON:\", response.json())\n",
    "    print()\n",
    "\n",
    "    job_id = response.json()[\"id\"]\n",
    "    now = datetime.datetime.today().strftime('%d-%b-%Y %H:%M:%S')\n",
    "    print(f\"{now} Job created: {job_id}\")\n",
    "\n",
    "    # 2. Poll for job status\n",
    "    status_url = f\"{endpoint}/openai/v1/video/generations/jobs/{job_id}?api-version={api_version}\"\n",
    "    status = None\n",
    "\n",
    "    while status not in (\"succeeded\", \"failed\", \"cancelled\"):\n",
    "        time.sleep(5)  # Wait before polling again\n",
    "        status_response = requests.get(status_url, headers=headers).json()\n",
    "        status = status_response.get(\"status\")\n",
    "        now = datetime.datetime.today().strftime('%d-%b-%Y %H:%M:%S')\n",
    "        print(f\"{now} Job status: {status}\")\n",
    "\n",
    "    # 3. Retrieve generated video\n",
    "    if status == \"succeeded\":\n",
    "        generations = status_response.get(\"generations\", [])\n",
    "\n",
    "        if generations:\n",
    "            now = datetime.datetime.today().strftime('%d-%b-%Y %H:%M:%S')\n",
    "            print(f\"\\n{now} ✅ Done. Video generation succeeded.\")\n",
    "            generation_id = generations[0].get(\"id\")\n",
    "            video_url = f\"{endpoint}/openai/v1/video/generations/{generation_id}/content/video?api-version={api_version}\"\n",
    "            video_response = requests.get(video_url, headers=headers)\n",
    "\n",
    "            if video_response.ok:\n",
    "                # Downloading the video\n",
    "                print(\"\\nDownloading the video...\")\n",
    "                with open(output_filename, \"wb\") as file:\n",
    "                    file.write(video_response.content)\n",
    "                    print(f\"SORA Generated video saved: '{output_filename}'\")\n",
    "\n",
    "                elapsed = time.time() - start\n",
    "                minutes, seconds = divmod(elapsed, 60)\n",
    "                print(f\"Done in {minutes:.0f} minutes and {seconds:.0f} seconds\")\n",
    "\n",
    "                return output_filename\n",
    "        else:\n",
    "            raise Exception(\"Error. No generations found in job result.\")\n",
    "    else:\n",
    "        raise Exception(f\"Error. Job did not succeed. Status: {status}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b865643f-526e-409c-8ba8-9d8ee7a8ea46",
   "metadata": {},
   "source": [
    "## Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "950e76ca-3c62-45cb-bfbe-de46f8acf1fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "02-Jun-2025 10:03:44 Full response JSON: {'object': 'video.generation.job', 'id': 'task_01jwr1hp79ftw8ah1stqvdzk4r', 'status': 'queued', 'created_at': 1748858624, 'finished_at': None, 'expires_at': None, 'generations': [], 'prompt': 'A young boy and his father playing together in the ocean on the beach.', 'model': 'sora', 'n_variants': 1, 'n_seconds': 5, 'height': 480, 'width': 480, 'failure_reason': None}\n",
      "\n",
      "02-Jun-2025 10:03:44 Job created: task_01jwr1hp79ftw8ah1stqvdzk4r\n",
      "02-Jun-2025 10:03:49 Job status: running\n",
      "02-Jun-2025 10:03:55 Job status: running\n",
      "02-Jun-2025 10:04:00 Job status: processing\n",
      "02-Jun-2025 10:04:05 Job status: succeeded\n",
      "\n",
      "02-Jun-2025 10:04:05 ✅ Done. Video generation succeeded.\n",
      "\n",
      "Downloading the video...\n",
      "SORA Generated video saved: 'videos/sora_02Jun2025_100343_A_young_boy_and_his_father_pla.mp4'\n",
      "Done in 0 minutes and 25 seconds\n"
     ]
    }
   ],
   "source": [
    "prompt = \"A young boy and his father playing together in the ocean on the beach.\"\n",
    "\n",
    "generated_video = sora(prompt, width=480, height=480, n_seconds=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5dd7d05f-5314-4bee-aab2-209d60adab1b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<video src=\"videos/sora_02Jun2025_100343_A_young_boy_and_his_father_pla.mp4\" controls  >\n",
       "      Your browser does not support the <code>video</code> element.\n",
       "    </video>"
      ],
      "text/plain": [
       "<IPython.core.display.Video object>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Video(generated_video)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ce1df45d-e0aa-4994-a97a-0d195344618d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<a href='videos/sora_02Jun2025_100343_A_young_boy_and_his_father_pla.mp4' target='_blank'>videos/sora_02Jun2025_100343_A_young_boy_and_his_father_pla.mp4</a><br>"
      ],
      "text/plain": [
       "/mnt/batch/tasks/shared/LS_root/mounts/clusters/seretkow8/code/Users/seretkow/SORA/videos/sora_02Jun2025_100343_A_young_boy_and_his_father_pla.mp4"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "video_link = FileLink(path=generated_video)\n",
    "video_link"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6196535-f0f9-4bd6-a5b2-041f7a96d68b",
   "metadata": {},
   "source": [
    "## Another example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "16a869c9-2a21-4141-9167-b504e28f9c3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "02-Jun-2025 10:04:09 Full response JSON: {'object': 'video.generation.job', 'id': 'task_01jwr1jey8fmsarw05npkcvyx7', 'status': 'queued', 'created_at': 1748858649, 'finished_at': None, 'expires_at': None, 'generations': [], 'prompt': 'A close up view of a glass sphere that has a zen garden within it. There is a small dwarf in the sphere who is raking the zen garden and creating patterns in the sand.', 'model': 'sora', 'n_variants': 1, 'n_seconds': 5, 'height': 480, 'width': 480, 'failure_reason': None}\n",
      "\n",
      "02-Jun-2025 10:04:09 Job created: task_01jwr1jey8fmsarw05npkcvyx7\n",
      "02-Jun-2025 10:04:15 Job status: running\n",
      "02-Jun-2025 10:04:20 Job status: processing\n",
      "02-Jun-2025 10:04:25 Job status: succeeded\n",
      "\n",
      "02-Jun-2025 10:04:25 ✅ Done. Video generation succeeded.\n",
      "\n",
      "Downloading the video...\n",
      "SORA Generated video saved: 'videos/sora_02Jun2025_100409_A_close_up_view_of_a_glass_sph.mp4'\n",
      "Done in 0 minutes and 18 seconds\n"
     ]
    }
   ],
   "source": [
    "prompt = \"A close up view of a glass sphere that has a zen garden within it. There is a small dwarf in the sphere who is raking the zen garden and creating patterns in the sand.\"\n",
    "\n",
    "generated_video = sora(prompt, width=480, height=480, n_seconds=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fd8a2d32-1a32-45f4-86e4-41379c79e6a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<video src=\"videos/sora_02Jun2025_100409_A_close_up_view_of_a_glass_sph.mp4\" controls  >\n",
       "      Your browser does not support the <code>video</code> element.\n",
       "    </video>"
      ],
      "text/plain": [
       "<IPython.core.display.Video object>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Video(generated_video)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b0e6ce17-0165-4f3c-837c-ee0259c4fdad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<a href='videos/sora_02Jun2025_100409_A_close_up_view_of_a_glass_sph.mp4' target='_blank'>videos/sora_02Jun2025_100409_A_close_up_view_of_a_glass_sph.mp4</a><br>"
      ],
      "text/plain": [
       "/mnt/batch/tasks/shared/LS_root/mounts/clusters/seretkow8/code/Users/seretkow/SORA/videos/sora_02Jun2025_100409_A_close_up_view_of_a_glass_sph.mp4"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "video_link = FileLink(path=generated_video)\n",
    "video_link"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ab9b28e-1715-4c40-8a62-da9f443b3218",
   "metadata": {},
   "source": [
    "## Another example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5d6fdc78-666a-48f1-bc34-6d205853557f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "02-Jun-2025 10:04:27 Full response JSON: {'object': 'video.generation.job', 'id': 'task_01jwr1k0veevyrdmkqh58enarb', 'status': 'queued', 'created_at': 1748858667, 'finished_at': None, 'expires_at': None, 'generations': [], 'prompt': 'Several giant wooly mammoths approach treading through a snowy meadow, their long wooly fur lightly blows in the wind as they walk, snow covered trees and dramatic snow capped mountains in the distance, mid afternoon light with wispy clouds and a sun high in the distance creates a warm glow, the low camera view is stunning capturing the large furry mammal with beautiful photography, depth of field.', 'model': 'sora', 'n_variants': 1, 'n_seconds': 5, 'height': 720, 'width': 1280, 'failure_reason': None}\n",
      "\n",
      "02-Jun-2025 10:04:27 Job created: task_01jwr1k0veevyrdmkqh58enarb\n",
      "02-Jun-2025 10:04:33 Job status: queued\n",
      "02-Jun-2025 10:04:38 Job status: running\n",
      "02-Jun-2025 10:04:44 Job status: running\n",
      "02-Jun-2025 10:04:49 Job status: running\n",
      "02-Jun-2025 10:04:54 Job status: processing\n",
      "02-Jun-2025 10:05:00 Job status: succeeded\n",
      "\n",
      "02-Jun-2025 10:05:00 ✅ Done. Video generation succeeded.\n",
      "\n",
      "Downloading the video...\n",
      "SORA Generated video saved: 'videos/sora_02Jun2025_100427_Several_giant_wooly_mammoths_a.mp4'\n",
      "Done in 0 minutes and 38 seconds\n"
     ]
    }
   ],
   "source": [
    "prompt = \"Several giant wooly mammoths approach treading through a snowy meadow, their long wooly fur lightly blows in the wind as they walk, snow covered trees and dramatic snow capped mountains in the distance, mid afternoon light with wispy clouds and a sun high in the distance creates a warm glow, the low camera view is stunning capturing the large furry mammal with beautiful photography, depth of field.\"\n",
    "\n",
    "generated_video = sora(prompt,\n",
    "                       width=1280,\n",
    "                       height=720,\n",
    "                       n_seconds=5,\n",
    "                       )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7ee2ddc6-e664-49d5-93e3-388ba3febbd2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<video src=\"videos/sora_02Jun2025_100427_Several_giant_wooly_mammoths_a.mp4\" controls  width=\"640\" >\n",
       "      Your browser does not support the <code>video</code> element.\n",
       "    </video>"
      ],
      "text/plain": [
       "<IPython.core.display.Video object>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Video(generated_video, width=640)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f3356def-6777-4143-8ddd-9f2b18d923c0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<a href='videos/sora_02Jun2025_100427_Several_giant_wooly_mammoths_a.mp4' target='_blank'>videos/sora_02Jun2025_100427_Several_giant_wooly_mammoths_a.mp4</a><br>"
      ],
      "text/plain": [
       "/mnt/batch/tasks/shared/LS_root/mounts/clusters/seretkow8/code/Users/seretkow/SORA/videos/sora_02Jun2025_100427_Several_giant_wooly_mammoths_a.mp4"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "video_link = FileLink(path=generated_video)\n",
    "video_link"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9661cd10-e188-4df2-b757-2c4b0614e3f2",
   "metadata": {},
   "source": [
    "## Another example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2598dd4e-db78-4ef1-9e7c-e9d6c6ad5386",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "02-Jun-2025 10:05:05 Full response JSON: {'object': 'video.generation.job', 'id': 'task_01jwr1m5v2ek284z52ybkb223s', 'status': 'queued', 'created_at': 1748858705, 'finished_at': None, 'expires_at': None, 'generations': [], 'prompt': \"Drone view of waves crashing against the rugged cliffs along Big Sur's garay point beach. The crashing blue waters create white-tipped waves, while the golden light of the setting sun illuminates the rocky shore. A small island with a lighthouse sits in the distance, and green shrubbery covers the cliff's edge. The steep drop from the road down to the beach is a dramatic feat, with the cliff's edges jutting out over the sea. This is a view that captures the raw beauty of the coast and the rugged landscape of the Pacific Coast Highway.\", 'model': 'sora', 'n_variants': 1, 'n_seconds': 15, 'height': 720, 'width': 1280, 'failure_reason': None}\n",
      "\n",
      "02-Jun-2025 10:05:05 Job created: task_01jwr1m5v2ek284z52ybkb223s\n",
      "02-Jun-2025 10:05:11 Job status: queued\n",
      "02-Jun-2025 10:05:16 Job status: running\n",
      "02-Jun-2025 10:05:22 Job status: running\n",
      "02-Jun-2025 10:05:27 Job status: running\n",
      "02-Jun-2025 10:05:32 Job status: running\n",
      "02-Jun-2025 10:05:38 Job status: running\n",
      "02-Jun-2025 10:05:43 Job status: running\n",
      "02-Jun-2025 10:05:49 Job status: running\n",
      "02-Jun-2025 10:05:54 Job status: running\n",
      "02-Jun-2025 10:06:00 Job status: running\n",
      "02-Jun-2025 10:06:05 Job status: running\n",
      "02-Jun-2025 10:06:10 Job status: running\n",
      "02-Jun-2025 10:06:16 Job status: running\n",
      "02-Jun-2025 10:06:21 Job status: running\n",
      "02-Jun-2025 10:06:27 Job status: running\n",
      "02-Jun-2025 10:06:32 Job status: running\n",
      "02-Jun-2025 10:06:37 Job status: running\n",
      "02-Jun-2025 10:06:43 Job status: processing\n",
      "02-Jun-2025 10:06:48 Job status: processing\n",
      "02-Jun-2025 10:06:54 Job status: processing\n",
      "02-Jun-2025 10:06:59 Job status: succeeded\n",
      "\n",
      "02-Jun-2025 10:06:59 ✅ Done. Video generation succeeded.\n",
      "\n",
      "Downloading the video...\n",
      "SORA Generated video saved: 'videos/sora_02Jun2025_100505_Drone_view_of_waves_crashing_a.mp4'\n",
      "Done in 2 minutes and 6 seconds\n"
     ]
    }
   ],
   "source": [
    "prompt = \"Drone view of waves crashing against the rugged cliffs along Big Sur's garay point beach. The crashing blue waters create white-tipped waves, while the golden light of the setting sun illuminates the rocky shore. A small island with a lighthouse sits in the distance, and green shrubbery covers the cliff's edge. The steep drop from the road down to the beach is a dramatic feat, with the cliff's edges jutting out over the sea. This is a view that captures the raw beauty of the coast and the rugged landscape of the Pacific Coast Highway.\"\n",
    "\n",
    "generated_video = sora(prompt,\n",
    "                       width=1280,\n",
    "                       height=720,\n",
    "                       n_seconds=15,\n",
    "                       )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "771bb959-f85d-4fd3-a647-83fc31e6ad40",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<video src=\"videos/sora_02Jun2025_100505_Drone_view_of_waves_crashing_a.mp4\" controls  >\n",
       "      Your browser does not support the <code>video</code> element.\n",
       "    </video>"
      ],
      "text/plain": [
       "<IPython.core.display.Video object>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Video(generated_video)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e14979f4-d297-478a-a7dd-4c790ea12db0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<a href='videos/sora_02Jun2025_100505_Drone_view_of_waves_crashing_a.mp4' target='_blank'>videos/sora_02Jun2025_100505_Drone_view_of_waves_crashing_a.mp4</a><br>"
      ],
      "text/plain": [
       "/mnt/batch/tasks/shared/LS_root/mounts/clusters/seretkow8/code/Users/seretkow/SORA/videos/sora_02Jun2025_100505_Drone_view_of_waves_crashing_a.mp4"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "video_link = FileLink(path=generated_video)\n",
    "video_link"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac85e2a9-fb55-4f9e-893c-e5172a465766",
   "metadata": {},
   "source": [
    "## Another example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9b9b850e-d477-444b-96ea-fd9dbc6813ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "02-Jun-2025 10:07:11 Full response JSON: {'object': 'video.generation.job', 'id': 'task_01jwr1r0hdewvbkkvy2p5mwts7', 'status': 'queued', 'created_at': 1748858831, 'finished_at': None, 'expires_at': None, 'generations': [], 'prompt': \"Extreme close up of a 25 year old woman's eye blinking, cinematic film shot in 70mm, depth of field, vivid colors, cinematic\", 'model': 'sora', 'n_variants': 1, 'n_seconds': 5, 'height': 720, 'width': 1280, 'failure_reason': None}\n",
      "\n",
      "02-Jun-2025 10:07:11 Job created: task_01jwr1r0hdewvbkkvy2p5mwts7\n",
      "02-Jun-2025 10:07:16 Job status: preprocessing\n",
      "02-Jun-2025 10:07:22 Job status: running\n",
      "02-Jun-2025 10:07:27 Job status: running\n",
      "02-Jun-2025 10:07:33 Job status: running\n",
      "02-Jun-2025 10:07:38 Job status: processing\n",
      "02-Jun-2025 10:07:43 Job status: succeeded\n",
      "\n",
      "02-Jun-2025 10:07:43 ✅ Done. Video generation succeeded.\n",
      "\n",
      "Downloading the video...\n",
      "SORA Generated video saved: 'videos/sora_02Jun2025_100711_Extreme_close_up_of_a_25_year_.mp4'\n",
      "Done in 0 minutes and 38 seconds\n"
     ]
    }
   ],
   "source": [
    "prompt = \"Extreme close up of a 25 year old woman's eye blinking, cinematic film shot in 70mm, depth of field, vivid colors, cinematic\"\n",
    "\n",
    "generated_video = sora(prompt,\n",
    "                       width=1280,\n",
    "                       height=720,\n",
    "                       n_seconds=5,\n",
    "                       )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6e76495a-217a-486a-9877-19155e4d7e91",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<video src=\"videos/sora_02Jun2025_100711_Extreme_close_up_of_a_25_year_.mp4\" controls  width=\"860\" >\n",
       "      Your browser does not support the <code>video</code> element.\n",
       "    </video>"
      ],
      "text/plain": [
       "<IPython.core.display.Video object>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Video(generated_video, width=860)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "37f21e2c-75bb-4974-9e3c-dc96e658fb96",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<a href='videos/sora_02Jun2025_100711_Extreme_close_up_of_a_25_year_.mp4' target='_blank'>videos/sora_02Jun2025_100711_Extreme_close_up_of_a_25_year_.mp4</a><br>"
      ],
      "text/plain": [
       "/mnt/batch/tasks/shared/LS_root/mounts/clusters/seretkow8/code/Users/seretkow/SORA/videos/sora_02Jun2025_100711_Extreme_close_up_of_a_25_year_.mp4"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "video_link = FileLink(path=generated_video)\n",
    "video_link"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5ed2ddc-8cd9-4d98-9f9b-8d10142d3bb7",
   "metadata": {},
   "source": [
    "## Another example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a4713e1d-e219-4c06-9e3b-60b101a219a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "02-Jun-2025 10:07:49 Full response JSON: {'object': 'video.generation.job', 'id': 'task_01jwr1s5a9fgj8tvnfs4ncg513', 'status': 'queued', 'created_at': 1748858869, 'finished_at': None, 'expires_at': None, 'generations': [], 'prompt': \"Extreme close up of a 50 year old male's eye blinking, cinematic film shot in 70mm, depth of field, vivid colors, cinematic\", 'model': 'sora', 'n_variants': 1, 'n_seconds': 5, 'height': 720, 'width': 1280, 'failure_reason': None}\n",
      "\n",
      "02-Jun-2025 10:07:49 Job created: task_01jwr1s5a9fgj8tvnfs4ncg513\n",
      "02-Jun-2025 10:07:54 Job status: queued\n",
      "02-Jun-2025 10:07:59 Job status: running\n",
      "02-Jun-2025 10:08:05 Job status: running\n",
      "02-Jun-2025 10:08:10 Job status: running\n",
      "02-Jun-2025 10:08:16 Job status: processing\n",
      "02-Jun-2025 10:08:21 Job status: succeeded\n",
      "\n",
      "02-Jun-2025 10:08:21 ✅ Done. Video generation succeeded.\n",
      "\n",
      "Downloading the video...\n",
      "SORA Generated video saved: 'videos/sora_02Jun2025_100748_Extreme_close_up_of_a_50_year_.mp4'\n",
      "Done in 0 minutes and 38 seconds\n"
     ]
    }
   ],
   "source": [
    "prompt = \"Extreme close up of a 50 year old male's eye blinking, cinematic film shot in 70mm, depth of field, vivid colors, cinematic\"\n",
    "\n",
    "generated_video = sora(prompt,\n",
    "                       width=1280,\n",
    "                       height=720,\n",
    "                       n_seconds=5,\n",
    "                       )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "281c2346-7841-40e2-bffc-77616f49ab38",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<video src=\"videos/sora_02Jun2025_100748_Extreme_close_up_of_a_50_year_.mp4\" controls  width=\"860\" >\n",
       "      Your browser does not support the <code>video</code> element.\n",
       "    </video>"
      ],
      "text/plain": [
       "<IPython.core.display.Video object>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Video(generated_video, width=860)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "6033e815-71bf-4988-8711-e1aa8f8dd28b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<a href='videos/sora_02Jun2025_100748_Extreme_close_up_of_a_50_year_.mp4' target='_blank'>videos/sora_02Jun2025_100748_Extreme_close_up_of_a_50_year_.mp4</a><br>"
      ],
      "text/plain": [
       "/mnt/batch/tasks/shared/LS_root/mounts/clusters/seretkow8/code/Users/seretkow/SORA/videos/sora_02Jun2025_100748_Extreme_close_up_of_a_50_year_.mp4"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "video_link = FileLink(path=generated_video)\n",
    "video_link"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "125f4680-b315-42f7-a7d9-e4696df3d0ce",
   "metadata": {},
   "source": [
    "## Another example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "fd05049d-235b-46f4-8014-8da05daf7f69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "02-Jun-2025 10:08:26 Full response JSON: {'object': 'video.generation.job', 'id': 'task_01jwr1ta4qfb18fx1he5xsns07', 'status': 'queued', 'created_at': 1748858906, 'finished_at': None, 'expires_at': None, 'generations': [], 'prompt': 'Reflections in the window of a train traveling through the Tokyo suburbs.', 'model': 'sora', 'n_variants': 1, 'n_seconds': 10, 'height': 720, 'width': 1280, 'failure_reason': None}\n",
      "\n",
      "02-Jun-2025 10:08:26 Job created: task_01jwr1ta4qfb18fx1he5xsns07\n",
      "02-Jun-2025 10:08:32 Job status: queued\n",
      "02-Jun-2025 10:08:37 Job status: running\n",
      "02-Jun-2025 10:08:43 Job status: running\n",
      "02-Jun-2025 10:08:48 Job status: running\n",
      "02-Jun-2025 10:08:53 Job status: running\n",
      "02-Jun-2025 10:08:59 Job status: running\n",
      "02-Jun-2025 10:09:04 Job status: running\n",
      "02-Jun-2025 10:09:10 Job status: running\n",
      "02-Jun-2025 10:09:15 Job status: running\n",
      "02-Jun-2025 10:09:20 Job status: processing\n",
      "02-Jun-2025 10:09:26 Job status: processing\n",
      "02-Jun-2025 10:09:31 Job status: succeeded\n",
      "\n",
      "02-Jun-2025 10:09:31 ✅ Done. Video generation succeeded.\n",
      "\n",
      "Downloading the video...\n",
      "SORA Generated video saved: 'videos/sora_02Jun2025_100826_Reflections_in_the_window_of_a.mp4'\n",
      "Done in 1 minutes and 14 seconds\n"
     ]
    }
   ],
   "source": [
    "prompt = \"Reflections in the window of a train traveling through the Tokyo suburbs.\"\n",
    "\n",
    "generated_video = sora(prompt,\n",
    "                       width=1280,\n",
    "                       height=720,\n",
    "                       n_seconds=10,\n",
    "                       )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "3b79463f-0ba5-48e5-85da-e01ce0575ebd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<video src=\"videos/sora_02Jun2025_100826_Reflections_in_the_window_of_a.mp4\" controls  width=\"860\" >\n",
       "      Your browser does not support the <code>video</code> element.\n",
       "    </video>"
      ],
      "text/plain": [
       "<IPython.core.display.Video object>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Video(generated_video, width=860)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "ba9add9e-ded0-4faf-a7e1-59db37d935b7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<a href='videos/sora_02Jun2025_100826_Reflections_in_the_window_of_a.mp4' target='_blank'>videos/sora_02Jun2025_100826_Reflections_in_the_window_of_a.mp4</a><br>"
      ],
      "text/plain": [
       "/mnt/batch/tasks/shared/LS_root/mounts/clusters/seretkow8/code/Users/seretkow/SORA/videos/sora_02Jun2025_100826_Reflections_in_the_window_of_a.mp4"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "video_link = FileLink(path=generated_video)\n",
    "video_link"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6439e9d-5b89-4317-8108-973df8e12e83",
   "metadata": {},
   "source": [
    "## Another example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "01f28c2f-5f04-4514-ab33-77abe283bfb2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "02-Jun-2025 10:09:40 Full response JSON: {'object': 'video.generation.job', 'id': 'task_01jwr1wj27fke9jhgwhftvggzy', 'status': 'queued', 'created_at': 1748858980, 'finished_at': None, 'expires_at': None, 'generations': [], 'prompt': 'A drone view of flock of paper airplanes multicolors flutters through a dense jungle, weaving around trees as if they were migrating birds.', 'model': 'sora', 'n_variants': 1, 'n_seconds': 7, 'height': 720, 'width': 1280, 'failure_reason': None}\n",
      "\n",
      "02-Jun-2025 10:09:40 Job created: task_01jwr1wj27fke9jhgwhftvggzy\n",
      "02-Jun-2025 10:09:45 Job status: preprocessing\n",
      "02-Jun-2025 10:09:51 Job status: running\n",
      "02-Jun-2025 10:09:56 Job status: running\n",
      "02-Jun-2025 10:10:02 Job status: running\n",
      "02-Jun-2025 10:10:07 Job status: running\n",
      "02-Jun-2025 10:10:12 Job status: running\n",
      "02-Jun-2025 10:10:18 Job status: processing\n",
      "02-Jun-2025 10:10:23 Job status: succeeded\n",
      "\n",
      "02-Jun-2025 10:10:23 ✅ Done. Video generation succeeded.\n",
      "\n",
      "Downloading the video...\n",
      "SORA Generated video saved: 'videos/sora_02Jun2025_100940_A_drone_view_of_flock_of_paper.mp4'\n",
      "Done in 0 minutes and 50 seconds\n"
     ]
    }
   ],
   "source": [
    "prompt = \"A drone view of flock of paper airplanes multicolors flutters through a dense jungle, weaving around trees as if they were migrating birds.\"\n",
    "\n",
    "generated_video = sora(prompt,\n",
    "                       width=1280,\n",
    "                       height=720,\n",
    "                       n_seconds=7,\n",
    "                       )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "94fb2a60-2c8b-4867-aa80-e77301856b39",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<video src=\"videos/sora_02Jun2025_100940_A_drone_view_of_flock_of_paper.mp4\" controls  width=\"860\" >\n",
       "      Your browser does not support the <code>video</code> element.\n",
       "    </video>"
      ],
      "text/plain": [
       "<IPython.core.display.Video object>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Video(generated_video, width=860)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "f327fb07-0788-4b76-b4b2-6ed45cff6633",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<a href='videos/sora_02Jun2025_100940_A_drone_view_of_flock_of_paper.mp4' target='_blank'>videos/sora_02Jun2025_100940_A_drone_view_of_flock_of_paper.mp4</a><br>"
      ],
      "text/plain": [
       "/mnt/batch/tasks/shared/LS_root/mounts/clusters/seretkow8/code/Users/seretkow/SORA/videos/sora_02Jun2025_100940_A_drone_view_of_flock_of_paper.mp4"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "video_link = FileLink(path=generated_video)\n",
    "video_link"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8529a33c-cdbd-49d3-a1f6-b2860d69087d",
   "metadata": {},
   "source": [
    "## Another exemple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "55420c94-944f-491a-86b2-17bcad5a15c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "02-Jun-2025 10:10:30 Full response JSON: {'object': 'video.generation.job', 'id': 'task_01jwr1y2q1fy1at3w70k52s6xd', 'status': 'queued', 'created_at': 1748859030, 'finished_at': None, 'expires_at': None, 'generations': [], 'prompt': 'Street of Tokyo, rainy day with people walking in a street, restaurants in the street.', 'model': 'sora', 'n_variants': 1, 'n_seconds': 7, 'height': 720, 'width': 1280, 'failure_reason': None}\n",
      "\n",
      "02-Jun-2025 10:10:30 Job created: task_01jwr1y2q1fy1at3w70k52s6xd\n",
      "02-Jun-2025 10:10:35 Job status: preprocessing\n",
      "02-Jun-2025 10:10:41 Job status: running\n",
      "02-Jun-2025 10:10:46 Job status: running\n",
      "02-Jun-2025 10:10:51 Job status: running\n",
      "02-Jun-2025 10:10:57 Job status: running\n",
      "02-Jun-2025 10:11:02 Job status: running\n",
      "02-Jun-2025 10:11:08 Job status: processing\n",
      "02-Jun-2025 10:11:13 Job status: succeeded\n",
      "\n",
      "02-Jun-2025 10:11:13 ✅ Done. Video generation succeeded.\n",
      "\n",
      "Downloading the video...\n",
      "SORA Generated video saved: 'videos/sora_02Jun2025_101029_Street_of_Tokyo__rainy_day_wit.mp4'\n",
      "Done in 0 minutes and 50 seconds\n"
     ]
    }
   ],
   "source": [
    "prompt = \"Street of Tokyo, rainy day with people walking in a street, restaurants in the street.\"\n",
    "\n",
    "generated_video = sora(prompt,\n",
    "                       width=1280,\n",
    "                       height=720,\n",
    "                       n_seconds=7,\n",
    "                       )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "da4a5811-483f-49fb-98eb-4b612258ad03",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<video src=\"videos/sora_02Jun2025_101029_Street_of_Tokyo__rainy_day_wit.mp4\" controls  width=\"860\" >\n",
       "      Your browser does not support the <code>video</code> element.\n",
       "    </video>"
      ],
      "text/plain": [
       "<IPython.core.display.Video object>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Video(generated_video, width=860)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "325d9bc1-294b-4f0d-be04-9b89c1deae32",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<a href='videos/sora_02Jun2025_101029_Street_of_Tokyo__rainy_day_wit.mp4' target='_blank'>videos/sora_02Jun2025_101029_Street_of_Tokyo__rainy_day_wit.mp4</a><br>"
      ],
      "text/plain": [
       "/mnt/batch/tasks/shared/LS_root/mounts/clusters/seretkow8/code/Users/seretkow/SORA/videos/sora_02Jun2025_101029_Street_of_Tokyo__rainy_day_wit.mp4"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "video_link = FileLink(path=generated_video)\n",
    "video_link"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "21876621-5cce-49f8-9f67-5579ecf12a2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 75M\n",
      "-rwxrwxrwx 1 root root 3.9M Jun  2 10:04 sora_02Jun2025_100343_A_young_boy_and_his_father_pla.mp4\n",
      "-rwxrwxrwx 1 root root 1.1M Jun  2 10:04 sora_02Jun2025_100409_A_close_up_view_of_a_glass_sph.mp4\n",
      "-rwxrwxrwx 1 root root 6.7M Jun  2 10:05 sora_02Jun2025_100427_Several_giant_wooly_mammoths_a.mp4\n",
      "-rwxrwxrwx 1 root root  19M Jun  2 10:07 sora_02Jun2025_100505_Drone_view_of_waves_crashing_a.mp4\n",
      "-rwxrwxrwx 1 root root 6.8M Jun  2 10:07 sora_02Jun2025_100711_Extreme_close_up_of_a_25_year_.mp4\n",
      "-rwxrwxrwx 1 root root 6.8M Jun  2 10:08 sora_02Jun2025_100748_Extreme_close_up_of_a_50_year_.mp4\n",
      "-rwxrwxrwx 1 root root  13M Jun  2 10:09 sora_02Jun2025_100826_Reflections_in_the_window_of_a.mp4\n",
      "-rwxrwxrwx 1 root root 9.0M Jun  2 10:10 sora_02Jun2025_100940_A_drone_view_of_flock_of_paper.mp4\n",
      "-rwxrwxrwx 1 root root 9.2M Jun  2 10:11 sora_02Jun2025_101029_Street_of_Tokyo__rainy_day_wit.mp4\n"
     ]
    }
   ],
   "source": [
    "!ls $OUTPUT_DIR -lh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3fa82c7-a118-47ff-9e0b-9b743984a0f1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10 - SDK v2",
   "language": "python",
   "name": "python310-sdkv2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
