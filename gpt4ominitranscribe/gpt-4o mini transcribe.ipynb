{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "26fcfcc5-f475-43ec-a724-fb791cd16410",
   "metadata": {},
   "source": [
    "# gpt-4o mini transcribe for TTS with Azure AI Foundry\n",
    "\n",
    "<img src=\"https://devblogs.microsoft.com/foundry/wp-content/uploads/sites/89/2025/04/image-1024x576.png\">\n",
    "\n",
    "> https://devblogs.microsoft.com/foundry/get-started-azure-openai-advanced-audio-models/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "91f30632-eec5-4695-bb82-e9ae772b2d0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import time\n",
    "\n",
    "from datetime import datetime\n",
    "from dotenv import load_dotenv\n",
    "from openai import AzureOpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "891a49d5-ce99-41e4-97d8-fdf10d1c8444",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = \"gpt-4o-mini-transcribe\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e070f2e3-5c94-4104-9910-35f1fe284099",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'3.10.14 (main, May  6 2024, 19:42:50) [GCC 11.2.0]'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sys.version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e8650762-cc6f-4fbd-84ad-4d9527ae98d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Today is 18-Apr-2025 07:46:48\n"
     ]
    }
   ],
   "source": [
    "print(f\"Today is {datetime.today().strftime('%d-%b-%Y %H:%M:%S')}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7d46f647-ac84-40e8-8c63-38ef05483055",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OK\n"
     ]
    }
   ],
   "source": [
    "print('OK') if load_dotenv(\"azure.env\") else print('ERROR: Check file location or name.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80edf87d-a7ec-4517-bf9a-a477196f4477",
   "metadata": {},
   "source": [
    "## Client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "be053b88-3625-4448-9a44-e71ba20343b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "client = AzureOpenAI(\n",
    "    azure_endpoint=os.getenv(\"endpoint\"),\n",
    "    api_key=os.getenv(\"key\"),\n",
    "    api_version=\"2025-01-01-preview\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6293c1b-8b20-4174-ae0c-148c3c7e8b80",
   "metadata": {},
   "source": [
    "## Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f2c9866a-43a9-4975-9e3d-8c79b33fa1ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "audiofile_path = \"speech.wav\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5a1c4de5-8dec-4beb-ae82-588d0e271e4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done in 2.285 seconds\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "\n",
    "audio_file = open(audiofile_path, \"rb\")\n",
    "\n",
    "transcription = client.audio.transcriptions.create(model=model,\n",
    "                                                   file=audio_file)\n",
    "\n",
    "end = time.time()\n",
    "print(f\"Done in {end - start:.3f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a9cba4b2-7475-42d6-acbb-ecd74e15c07c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Transcription(text=\"There are some parts that I quibbled with because I didn't understand at the time that it's in the editing that a film is shaped. So I noticed that Stephen had shot almost everything I had demanded, you know, that had to be there, but a lot of it ended up cut. And that wasn't very good to see. But the story is strong. It's a very robust story, and it's very universal, so that no matter how they cut it, it's always true.\", logprobs=None)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transcription"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "568e9e41-8cde-4f0f-ba62-a9ecaf6e27fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are some parts that I quibbled with because I didn't understand at the time that it's in the editing that a film is shaped. So I noticed that Stephen had shot almost everything I had demanded, you know, that had to be there, but a lot of it ended up cut. And that wasn't very good to see. But the story is strong. It's a very robust story, and it's very universal, so that no matter how they cut it, it's always true.\n"
     ]
    }
   ],
   "source": [
    "print(transcription.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb4908b4-a7b6-476a-ae74-7ff3a0947968",
   "metadata": {},
   "source": [
    "## Response format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fb9c0f2b-ee3c-44ac-a2ca-4763abb6c9cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "And there are some parts that I quibbled with, because I didn't understand at the time that it's in the editing that a film is shaped. So I noticed that Stephen had shot almost everything I had demanded, you know, that had to be there, but a lot of it ended up cut. And that wasn't very good to see. But the story is strong. It's a very robust story, and it's very universal. So that no matter how they cut it, it's always true.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "transcription = client.audio.transcriptions.create(model=model,\n",
    "                                                   file=audio_file,\n",
    "                                                   response_format=\"text\")\n",
    "\n",
    "print(transcription)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e1a9453-9fbf-49a9-929e-b3ca4b630c1a",
   "metadata": {},
   "source": [
    "## Streaming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d35100d4-6d96-4853-b30d-1a4acea83d32",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "001 word: There           [1.504 sec]\n",
      "002 word:  are            [1.543 sec]\n",
      "003 word:  some           [1.558 sec]\n",
      "004 word:  parts          [1.567 sec]\n",
      "005 word:  that           [1.568 sec]\n",
      "006 word:  I              [1.573 sec]\n",
      "007 word:  qu             [1.574 sec]\n",
      "008 word: ibb             [1.576 sec]\n",
      "009 word: led             [1.577 sec]\n",
      "010 word:  with           [1.579 sec]\n",
      "011 word:  because        [1.579 sec]\n",
      "012 word:  I              [1.580 sec]\n",
      "013 word:  didn't         [1.581 sec]\n",
      "014 word:  understand     [1.583 sec]\n",
      "015 word:  at             [1.583 sec]\n",
      "016 word:  the            [1.584 sec]\n",
      "017 word:  time           [1.584 sec]\n",
      "018 word:  that           [1.585 sec]\n",
      "019 word:  it's           [1.585 sec]\n",
      "020 word:  in             [1.586 sec]\n",
      "021 word:  the            [1.587 sec]\n",
      "022 word:  editing        [1.588 sec]\n",
      "023 word:  that           [1.588 sec]\n",
      "024 word:  a              [1.589 sec]\n",
      "025 word:  film           [1.589 sec]\n",
      "026 word:  is             [1.591 sec]\n",
      "027 word:  shaped         [1.591 sec]\n",
      "028 word: .               [1.592 sec]\n",
      "029 word:  So             [1.592 sec]\n",
      "030 word:  I              [1.593 sec]\n",
      "031 word:  noticed        [1.593 sec]\n",
      "032 word:  that           [1.595 sec]\n",
      "033 word:  Stephen        [1.595 sec]\n",
      "034 word:  had            [1.596 sec]\n",
      "035 word:  shot           [1.596 sec]\n",
      "036 word:  almost         [1.597 sec]\n",
      "037 word:  everything     [1.598 sec]\n",
      "038 word:  I              [1.598 sec]\n",
      "039 word:  had            [1.609 sec]\n",
      "040 word:  demanded       [1.610 sec]\n",
      "041 word: ,               [1.610 sec]\n",
      "042 word:  you            [1.610 sec]\n",
      "043 word:  know           [1.610 sec]\n",
      "044 word: ,               [1.610 sec]\n",
      "045 word:  that           [1.610 sec]\n",
      "046 word:  had            [1.610 sec]\n",
      "047 word:  to             [1.610 sec]\n",
      "048 word:  be             [1.611 sec]\n",
      "049 word:  there          [1.611 sec]\n",
      "050 word: ,               [1.611 sec]\n",
      "051 word:  but            [1.611 sec]\n",
      "052 word:  a              [1.611 sec]\n",
      "053 word:  lot            [1.611 sec]\n",
      "054 word:  of             [1.611 sec]\n",
      "055 word:  it             [1.612 sec]\n",
      "056 word:  ended          [1.612 sec]\n",
      "057 word:  up             [1.612 sec]\n",
      "058 word:  cut            [1.612 sec]\n",
      "059 word: .               [1.612 sec]\n",
      "060 word:  And            [1.613 sec]\n",
      "061 word:  that           [1.632 sec]\n",
      "062 word:  wasn't         [1.632 sec]\n",
      "063 word:  very           [1.632 sec]\n",
      "064 word:  good           [1.632 sec]\n",
      "065 word:  to             [1.636 sec]\n",
      "066 word:  see            [1.640 sec]\n",
      "067 word: .               [1.644 sec]\n",
      "068 word:  But            [1.650 sec]\n",
      "069 word:  the            [1.654 sec]\n",
      "070 word:  story          [1.660 sec]\n",
      "071 word:  is             [1.664 sec]\n",
      "072 word:  strong         [1.670 sec]\n",
      "073 word: .               [1.673 sec]\n",
      "074 word:  It's           [1.679 sec]\n",
      "075 word:  a              [1.684 sec]\n",
      "076 word:  very           [1.689 sec]\n",
      "077 word:  robust         [1.693 sec]\n",
      "078 word:  story          [1.699 sec]\n",
      "079 word:  and            [1.703 sec]\n",
      "080 word:  it's           [1.708 sec]\n",
      "081 word:  very           [1.727 sec]\n",
      "082 word:  universal      [1.727 sec]\n",
      "083 word: ,               [1.727 sec]\n",
      "084 word:  so             [1.730 sec]\n",
      "085 word:  that           [1.732 sec]\n",
      "086 word:  no             [1.738 sec]\n",
      "087 word:  matter         [1.742 sec]\n",
      "088 word:  how            [1.747 sec]\n",
      "089 word:  they           [1.753 sec]\n",
      "090 word:  cut            [1.758 sec]\n",
      "091 word:  it             [1.761 sec]\n",
      "092 word: ,               [1.768 sec]\n",
      "093 word:  it's           [1.772 sec]\n",
      "094 word:  always         [1.777 sec]\n",
      "095 word:  true           [1.781 sec]\n",
      "096 word: .               [1.788 sec]\n",
      "\n",
      "Done in 1.801 seconds\n"
     ]
    }
   ],
   "source": [
    "start = time.perf_counter()\n",
    "\n",
    "stream = client.audio.transcriptions.create(model=\"gpt-4o-mini-transcribe\",\n",
    "                                            file=audio_file,\n",
    "                                            stream=True)\n",
    "\n",
    "for idx, event in enumerate(stream, start=1):\n",
    "    if event.type == \"transcript.text.delta\":\n",
    "        elapsed = time.perf_counter() - start\n",
    "        print(f\"{idx:03} word: {event.delta:15} [{elapsed:.3f} sec]\")\n",
    "\n",
    "end = time.perf_counter()\n",
    "print(f\"\\nDone in {end - start:.3f} seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fd98a05-aa4d-4354-a255-045073242017",
   "metadata": {},
   "source": [
    "## Logprob\n",
    "When the AI is transcribing audio, it guesses what the next word or sound might be. For each guess, it assigns a probabilityâ€”a measure of how confident it is.\n",
    "\n",
    "Instead of showing that probability directly (like 0.92 or 92%), it uses the logarithm of that probability, which is what logprob represents.\n",
    "\n",
    "The closer to 0 the logprob, the more confident the model is."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "786e2b37-9b9b-4dfe-b37e-283dd0244ec2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.489 sec: There                [logprob = -0.1535009100]\n",
      "1.490 sec:  are                 [logprob = -0.0040983470]\n",
      "1.494 sec:  some                [logprob = -0.0000057962]\n",
      "1.498 sec:  parts               [logprob = -0.0000006704]\n",
      "1.505 sec:  that                [logprob = -0.0000341667]\n",
      "1.509 sec:  I                   [logprob = -0.0000077034]\n",
      "1.514 sec:  qu                  [logprob = -0.0000022201]\n",
      "1.519 sec: ibb                  [logprob = -0.0001161788]\n",
      "1.524 sec: led                  [logprob = 0.0000000000]\n",
      "1.532 sec:  with                [logprob = -0.0000023393]\n",
      "1.534 sec:  because             [logprob = -0.2032676200]\n",
      "1.539 sec:  I                   [logprob = -0.0000065114]\n",
      "1.543 sec:  didn't              [logprob = -0.0004909569]\n",
      "1.549 sec:  understand          [logprob = -0.0000026969]\n",
      "1.556 sec:  at                  [logprob = -0.0000160477]\n",
      "1.560 sec:  the                 [logprob = -0.0000253456]\n",
      "1.563 sec:  time                [logprob = -0.0000003128]\n",
      "1.569 sec:  that                [logprob = -0.0002054476]\n",
      "1.572 sec:  it's                [logprob = -0.0012204634]\n",
      "1.578 sec:  in                  [logprob = -0.0000133060]\n",
      "1.582 sec:  the                 [logprob = -0.0000321402]\n",
      "1.589 sec:  editing             [logprob = 0.0000000000]\n",
      "1.592 sec:  that                [logprob = -0.0000231999]\n",
      "1.597 sec:  a                   [logprob = -0.0000062730]\n",
      "1.603 sec:  film                [logprob = -0.0000007896]\n",
      "1.606 sec:  is                  [logprob = -0.0000029353]\n",
      "1.612 sec:  shaped              [logprob = -0.0000009088]\n",
      "1.617 sec: .                    [logprob = -0.0919640800]\n",
      "1.623 sec:  So                  [logprob = -0.0003063838]\n",
      "1.626 sec:  I                   [logprob = -0.0052357680]\n",
      "1.634 sec:  noticed             [logprob = -0.0001400122]\n",
      "1.641 sec:  that                [logprob = -0.0000003128]\n",
      "1.644 sec:  Stephen             [logprob = -0.2519777400]\n",
      "1.647 sec:  had                 [logprob = -0.0000011472]\n",
      "1.654 sec:  shot                [logprob = -0.0000005512]\n",
      "1.658 sec:  almost              [logprob = -0.0000001936]\n",
      "1.662 sec:  everything          [logprob = -0.0000001936]\n",
      "1.666 sec:  I                   [logprob = -0.0000406037]\n",
      "1.676 sec:  had                 [logprob = -0.0000016241]\n",
      "1.676 sec:  demanded            [logprob = -0.0000049618]\n",
      "1.682 sec: ,                    [logprob = -0.3877070500]\n",
      "1.686 sec:  you                 [logprob = -0.0040849280]\n",
      "1.692 sec:  know                [logprob = -0.0000001936]\n",
      "1.696 sec: ,                    [logprob = -0.0000167629]\n",
      "1.710 sec:  that                [logprob = -0.0000035313]\n",
      "1.710 sec:  had                 [logprob = -0.0000004320]\n",
      "1.714 sec:  to                  [logprob = 0.0000000000]\n",
      "1.715 sec:  be                  [logprob = 0.0000000000]\n",
      "1.721 sec:  there               [logprob = -0.0000003128]\n",
      "1.731 sec: ,                    [logprob = -0.1437094400]\n",
      "1.731 sec:  but                 [logprob = -0.0000017433]\n",
      "1.736 sec:  a                   [logprob = 0.0000000000]\n",
      "1.742 sec:  lot                 [logprob = 0.0000000000]\n",
      "1.745 sec:  of                  [logprob = -0.0000004320]\n",
      "1.760 sec:  it                  [logprob = -0.0000001936]\n",
      "1.760 sec:  ended               [logprob = 0.0000000000]\n",
      "1.761 sec:  up                  [logprob = -0.0000001936]\n",
      "1.765 sec:  cut                 [logprob = -0.0000003128]\n",
      "1.771 sec: .                    [logprob = -0.0502958370]\n",
      "1.776 sec:  And                 [logprob = -0.0000046041]\n",
      "1.781 sec:  that                [logprob = -0.0000007896]\n",
      "1.795 sec:  wasn't              [logprob = -0.0000006704]\n",
      "1.796 sec:  very                [logprob = -0.0000015049]\n",
      "1.796 sec:  good                [logprob = 0.0000000000]\n",
      "1.802 sec:  to                  [logprob = -0.0000004320]\n",
      "1.805 sec:  see                 [logprob = -0.0000001936]\n",
      "1.812 sec: .                    [logprob = -0.1604283300]\n",
      "1.815 sec:  But                 [logprob = -0.0000035313]\n",
      "1.821 sec:  the                 [logprob = -0.0000001936]\n",
      "1.826 sec:  story               [logprob = 0.0000000000]\n",
      "1.832 sec:  is                  [logprob = -0.0000001936]\n",
      "1.835 sec:  strong              [logprob = 0.0000000000]\n",
      "1.843 sec: .                    [logprob = -0.0077623120]\n",
      "1.846 sec:  It's                [logprob = -0.0002391786]\n",
      "1.853 sec:  a                   [logprob = 0.0000000000]\n",
      "1.855 sec:  very                [logprob = 0.0000000000]\n",
      "1.862 sec:  robust              [logprob = 0.0000000000]\n",
      "1.866 sec:  story               [logprob = 0.0000000000]\n",
      "1.872 sec:  and                 [logprob = -0.5890799000]\n",
      "1.876 sec:  it's                [logprob = -0.0000003128]\n",
      "1.881 sec:  very                [logprob = 0.0000000000]\n",
      "1.885 sec:  universal           [logprob = -0.0000001936]\n",
      "1.890 sec: .                    [logprob = -0.5998294000]\n",
      "1.895 sec:  So                  [logprob = -0.0000080611]\n",
      "1.902 sec:  that                [logprob = -0.0000344051]\n",
      "1.906 sec:  no                  [logprob = -0.0000003128]\n",
      "1.923 sec:  matter              [logprob = 0.0000000000]\n",
      "1.923 sec:  how                 [logprob = 0.0000000000]\n",
      "1.924 sec:  they                [logprob = -0.0000001936]\n",
      "1.925 sec:  cut                 [logprob = 0.0000000000]\n",
      "1.931 sec:  it                  [logprob = -0.0000015049]\n",
      "1.941 sec: ,                    [logprob = -0.0000259416]\n",
      "1.941 sec:  it's                [logprob = -0.0040807780]\n",
      "1.944 sec:  always              [logprob = 0.0000000000]\n",
      "1.951 sec:  true                [logprob = 0.0000000000]\n",
      "1.955 sec: .                    [logprob = -0.0087604020]\n",
      "\n",
      "Finished at 1.969s: There are some parts...\n"
     ]
    }
   ],
   "source": [
    "start = time.perf_counter()\n",
    "\n",
    "stream = client.audio.transcriptions.create(model=model,\n",
    "                                            file=audio_file,\n",
    "                                            response_format=\"json\",\n",
    "                                            stream=True,\n",
    "                                            include=[\"logprobs\"])\n",
    "\n",
    "for idx, event in enumerate(stream):\n",
    "    timestamp = time.perf_counter() - start\n",
    "\n",
    "    if event.type == \"transcript.text.delta\":\n",
    "        logprob = event.logprobs[0].logprob if event.logprobs else None\n",
    "        print(f\"{timestamp:.3f} sec: {event.delta:20} [logprob = {logprob:.10f}]\")\n",
    "\n",
    "    elif event.type == \"transcript.text.done\":\n",
    "        snippet = event.text[:20] + \"...\" if len(\n",
    "            event.text) > 20 else event.text\n",
    "        print(f\"\\nFinished at {timestamp:.3f}s: {snippet}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79e0986a-b7c6-45fb-9aff-4a22889ff554",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10 - SDK v2",
   "language": "python",
   "name": "python310-sdkv2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
