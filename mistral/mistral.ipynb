{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e71b18cb-23bf-4703-a9e6-03dc2b35f881",
   "metadata": {},
   "source": [
    "# Mistral with Azure AI Foundry\n",
    "\n",
    "> https://learn.microsoft.com/en-us/azure/machine-learning/concept-models-featured?view=azureml-api-2#mistral-ai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b01b5d5b-b1dd-414c-9ae3-a2f9696484dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gradio as gr\n",
    "import os\n",
    "import requests\n",
    "import sys\n",
    "\n",
    "from azure.ai.inference import ChatCompletionsClient\n",
    "from azure.ai.inference.models import SystemMessage, UserMessage, AssistantMessage\n",
    "from azure.core.credentials import AzureKeyCredential\n",
    "from azure.core.exceptions import HttpResponseError\n",
    "from datetime import datetime\n",
    "from dotenv import load_dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f9c389b0-bfc6-4346-b4eb-b2a4c9c5da29",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'3.10.14 (main, May  6 2024, 19:42:50) [GCC 11.2.0]'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sys.version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "08e37ef6-dcab-40a0-a8e1-086f62ef4dfd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Today is 18-Apr-2025 07:36:00\n"
     ]
    }
   ],
   "source": [
    "print(f\"Today is {datetime.today().strftime('%d-%b-%Y %H:%M:%S')}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "33261a68-9a71-4190-aa63-2ae05cb46694",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_dotenv(\"azure.env\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "40412407-d035-4f1c-84fe-eb53d33a240d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = \"mistral-small-2503\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffe04d75-797e-4806-9020-32338e78659e",
   "metadata": {},
   "source": [
    "\"mistral-small-2503\"\n",
    "- Input: text and images (131,072 tokens),\n",
    "image-based tokens are 16px x 16px\n",
    "blocks of the original images\n",
    "- Output: text (4,096 tokens)\n",
    "- Tool calling: Yes\n",
    "- Response formats: Text, JSON"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2ed6df10-5664-4c3f-a667-780cc510079c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ask_mistral(prompt: str) -> str:\n",
    "    \"\"\"\n",
    "    Sends a prompt to the Mistral model via Azure's ChatCompletionsClient and returns the response.\n",
    "\n",
    "    Args:\n",
    "        prompt (str): The user's input prompt to be processed by the AI assistant.\n",
    "\n",
    "    Returns:\n",
    "        str: The AI-generated response from the Mistral model. If an error occurs, \n",
    "             a fallback error message is returned.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        client = ChatCompletionsClient(endpoint=os.getenv(\"endpoint\"),\n",
    "                                       credential=AzureKeyCredential(os.getenv(\"key\")))\n",
    "\n",
    "        response = client.complete(\n",
    "            messages=[\n",
    "                SystemMessage(content=\"You are a helpful AI assistant.\"),\n",
    "                UserMessage(content=prompt),\n",
    "            ],\n",
    "            model=model,\n",
    "            max_tokens=1000,\n",
    "        )\n",
    "        return response.choices[0].message.content.strip()\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error during completion: {e}\")\n",
    "        return \"Sorry, something went wrong while processing your request.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b99d8aa8-40e2-45c4-880f-6074c9b1e69d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The capital of France is Paris. It is known for iconic landmarks such as the Eiffel Tower, the Louvre Museum, and Notre-Dame Cathedral, as well as its rich history, culture, and cuisine.\n"
     ]
    }
   ],
   "source": [
    "prompt = \"What is the capital of France?\"\n",
    "\n",
    "print(ask_mistral(prompt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3512bf89-9022-41c7-bcc4-5b1e72f25d3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Paris, the City of Light, offers a wealth of iconic sites to visit. Here are three must-see attractions:\n",
      "\n",
      "1. **Eiffel Tower**:\n",
      "   - **Description**: The most famous symbol of Paris, the Eiffel Tower offers breathtaking views of the city from its three levels. You can dine at one of its restaurants or simply enjoy the panoramic vista.\n",
      "   - **Location**: Champ de Mars, 5 Avenue Anatole France, 75007 Paris\n",
      "\n",
      "2. **Louvre Museum**:\n",
      "   - **Description**: Home to thousands of works of art, including the Mona Lisa and the Winged Victory, the Louvre is the world's largest and most visited art museum. The glass pyramid in the courtyard is also a notable landmark.\n",
      "   - **Location**: Rue de Rivoli, 75001 Paris\n",
      "\n",
      "3. **Notre-Dame Cathedral**:\n",
      "   - **Description**: Although severely damaged by a fire in 2019, Notre-Dame remains an iconic symbol of Paris. The cathedral's Gothic architecture and historical significance make it a must-visit. Restoration work is ongoing, but you can still admire its exterior and learn about its history.\n",
      "   - **Location**: 6 Parvis Notre-Dame - Place Jean-Paul II, 75004 Paris\n",
      "\n",
      "These three sites offer a mix of history, art, and iconic Parisian experiences. Enjoy your trip!\n"
     ]
    }
   ],
   "source": [
    "prompt = \"What are 3 things to visit in Paris?\"\n",
    "\n",
    "print(ask_mistral(prompt))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e6dc26e-d315-4945-a0bf-078dcff6b84c",
   "metadata": {},
   "source": [
    "## Webapp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7e99ab1f-84db-4167-98de-7ee1a8bfabf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mistral_chat(user_input, history):\n",
    "\n",
    "    try:\n",
    "        client = ChatCompletionsClient(endpoint=os.getenv(\"endpoint\"),\n",
    "                                       credential=AzureKeyCredential(os.getenv(\"key\")))\n",
    "\n",
    "        # Convert previous messages to Azure message objects\n",
    "        messages = [\n",
    "            SystemMessage(\n",
    "                content=\n",
    "                \"You are an AI assistant that helps people find information.\")\n",
    "        ]\n",
    "\n",
    "        for user_msg, assistant_msg in history:\n",
    "            messages.append(UserMessage(content=user_msg))\n",
    "            messages.append(AssistantMessage(content=assistant_msg))\n",
    "            messages.append(UserMessage(content=user_input))\n",
    "        response = client.complete(\n",
    "            messages=messages,\n",
    "            model=model,\n",
    "        )\n",
    "        reply = response.choices[0].message.content\n",
    "\n",
    "    except HttpResponseError as ex:\n",
    "        if ex.status_code == 400:\n",
    "            try:\n",
    "                error_data = json.loads(ex.response._content.decode('utf-8'))\n",
    "                if isinstance(error_data, dict) and \"error\" in error_data:\n",
    "                    reply = f\"[ERROR {error_data['error']['code']}] {error_data['error']['message']}\"\n",
    "                else:\n",
    "                    reply = \"An unknown error occurred while processing your request.\"\n",
    "            except Exception:\n",
    "                reply = \"Failed to decode error response.\"\n",
    "        else:\n",
    "            reply = f\"An unexpected error occurred: {str(ex)}\"\n",
    "\n",
    "    history.append((user_input, reply))\n",
    "\n",
    "    return history, history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f55df30a-ed01-4f96-82ef-11d1c7d37252",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages/gradio/components/chatbot.py:242: UserWarning: You have not specified a value for the `type` parameter. Defaulting to the 'tuples' format for chatbot messages, but this is deprecated and will be removed in a future version of Gradio. Please set type='messages' instead, which uses openai-style dictionaries with 'role' and 'content' keys.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7861\n",
      "* Running on public URL: https://cc0ecbe0902243c16e.gradio.live\n",
      "\n",
      "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"https://cc0ecbe0902243c16e.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with gr.Blocks() as webapp:\n",
    "    gr.Markdown(\"# ðŸ¤– Chat with Mistral in Azure AI Foundry\")\n",
    "    chatbot = gr.Chatbot()\n",
    "    msg = gr.Textbox(label=\"Your message\", placeholder=\"Your prompt:\", lines=1)\n",
    "    clear = gr.Button(\"CLEAR\")\n",
    "    state = gr.State([])\n",
    "    msg.submit(mistral_chat, [msg, state], [chatbot, state])\n",
    "    clear.click(lambda: ([], []), None, [chatbot, state])\n",
    "\n",
    "\n",
    "webapp.launch(share=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0a9e2fe-171d-4ee8-93dd-51b42092e5ab",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10 - SDK v2",
   "language": "python",
   "name": "python310-sdkv2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
