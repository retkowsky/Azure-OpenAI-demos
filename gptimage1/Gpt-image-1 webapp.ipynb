{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "46e99d98-74b1-40af-a794-a4b88c05592e",
   "metadata": {},
   "source": [
    "# Azure AI Foundry - Gpt-image-1 webapp\n",
    "\n",
    "Gpt-image-1 includes significant improvements on image generation: it has generate high-quality images in challenging scenarios and solving challenging prompts.\n",
    "\n",
    "Currently the model has great zero-shot capabilities in image in-painting,\n",
    "photorealistic photos, and wireframe designs.\n",
    "\n",
    "> https://ai.azure.com/catalog/models/gpt-image-1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f25ff8fa-b3cf-435c-b06e-1c81d177fc98",
   "metadata": {},
   "source": [
    "<img src=\"capture1.jpg\">\n",
    "<img src=\"capture2.jpg\">\n",
    "<img src=\"capture3.jpg\">\n",
    "<img src=\"capture4.jpg\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0787c201-e2f8-4cb0-9809-63bafc53355e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import base64\n",
    "import datetime\n",
    "import gradio as gr\n",
    "import ipyplot\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import requests\n",
    "import sys\n",
    "import tempfile\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "from io import BytesIO\n",
    "from openai import AzureOpenAI\n",
    "from pathlib import Path\n",
    "from PIL import Image\n",
    "from rembg import remove"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afca0e39-9e92-4fbb-914b-3c85b57e6df1",
   "metadata": {},
   "source": [
    "## 1. Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4749116b-a28e-42e8-86ff-58235ac2b581",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Today is 2025-07-31\n"
     ]
    }
   ],
   "source": [
    "print(f\"Today is {datetime.datetime.now().strftime('%Y-%m-%d')}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "74b09709-a004-4cdb-a2a6-48e1837eeab1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'3.10.14 (main, May  6 2024, 19:42:50) [GCC 11.2.0]'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sys.version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a356a9a1-39b4-4ad2-8001-147cc617a3b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv(\"azure.env\")\n",
    "\n",
    "API_VERSION = \"2025-04-01-preview\"\n",
    "MODEL = \"gpt-image-1\"  # As deployed in Azure AI Foundry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f62cd045-e7c6-4ec0-b4ed-e702821ff01c",
   "metadata": {},
   "outputs": [],
   "source": [
    "IMAGES_DIR = \"images\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b46c382e-c379-4ae0-88d0-c234a5c3d529",
   "metadata": {},
   "source": [
    "## 2. Helper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c5ad22c8-e1c2-4872-80eb-768e8af3fdbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GPTImageApp:\n",
    "    def __init__(self):\n",
    "        self.setup_directories()\n",
    "\n",
    "    def setup_directories(self):\n",
    "        \"\"\"Create necessary directories for storing results\"\"\"\n",
    "        self.results_dirs = {\n",
    "            'edition': f'{IMAGES_DIR}/edition',\n",
    "            'composition': f'{IMAGES_DIR}/composition',\n",
    "            'inpainting': f'{IMAGES_DIR}/inpainting',\n",
    "            'generation': f'{IMAGES_DIR}/generation',\n",
    "        }\n",
    "\n",
    "        for dir_path in self.results_dirs.values():\n",
    "            os.makedirs(dir_path, exist_ok=True)\n",
    "\n",
    "    def save_image_with_timestamp(self, image, directory, prefix):\n",
    "        \"\"\"Save image with timestamp and return the path\"\"\"\n",
    "        now = datetime.datetime.now().strftime(\"%Y%m%d_%H%M%S_%f\")[:-3]\n",
    "        filename = f\"azure_ai_foundry_gptimage1_{prefix}_{now}.jpg\"\n",
    "        filepath = os.path.join(directory, filename)\n",
    "\n",
    "        if isinstance(image, str):  # base64 encoded\n",
    "            img = Image.open(BytesIO(base64.b64decode(image)))\n",
    "        else:\n",
    "            img = image\n",
    "\n",
    "        img.save(filepath)\n",
    "        return filepath\n",
    "\n",
    "    def image_generation(self,\n",
    "                         prompt,\n",
    "                         num_images=3,\n",
    "                         size=\"1024x1024\",\n",
    "                         quality=\"high\"):\n",
    "        \"\"\"Generate images using a text prompt\"\"\"\n",
    "        try:\n",
    "            client = AzureOpenAI(\n",
    "                azure_endpoint=os.getenv(\"endpoint\"),\n",
    "                api_key=os.getenv(\"key\"),\n",
    "                api_version=API_VERSION,\n",
    "            )\n",
    "\n",
    "            params = {\n",
    "                \"model\": MODEL,\n",
    "                \"prompt\": prompt,\n",
    "                \"n\": num_images,  # Number of images up to 10\n",
    "                \"quality\": quality,  # low, medium, high\n",
    "                \"size\": size,  # Values are: 1024x1024, 1536x1024, 1024x1536\n",
    "                \"output_compression\": 70,  # JPEG compression level (0-100)\n",
    "                \"output_format\": \"jpeg\",  # png, jpeg or webp\n",
    "                \"moderation\":\"auto\",  # auto or low\n",
    "                \"background\": \"auto\"  # auto, transparent or opaque\n",
    "\n",
    "            }\n",
    "\n",
    "            result = client.images.generate(**params)\n",
    "            images_data = result.model_dump().get(\"data\", [])\n",
    "            encoded_images = [\n",
    "                img.get(\"b64_json\") for img in images_data if \"b64_json\" in img\n",
    "            ]\n",
    "\n",
    "            output_images = []\n",
    "            for encoded_image in encoded_images:\n",
    "                filepath = self.save_image_with_timestamp(\n",
    "                    encoded_image, self.results_dirs['generation'],\n",
    "                    \"generated\")\n",
    "                output_images.append(filepath)\n",
    "\n",
    "            return output_images, f\"Successfully generated {len(output_images)} image(s)\"\n",
    "\n",
    "        except Exception as e:\n",
    "            return [], f\"Error generating images: {str(e)}\"\n",
    "\n",
    "    def image_edit(self,\n",
    "                   image_file,\n",
    "                   prompt,\n",
    "                   num_images=3,\n",
    "                   size=\"1024x1024\",\n",
    "                   quality=\"high\"):\n",
    "        \"\"\"Edit an existing image based on text prompt\"\"\"\n",
    "        try:\n",
    "            # Save uploaded image temporarily\n",
    "            with tempfile.NamedTemporaryFile(delete=False,\n",
    "                                             suffix='.jpg') as tmp_file:\n",
    "                image_file.save(tmp_file.name)\n",
    "                temp_path = tmp_file.name\n",
    "\n",
    "            headers = {\"api-key\": os.getenv(\"key\")}\n",
    "            aoai_name = re.search(r'https://(.*?)/openai',\n",
    "                                  os.getenv(\"endpoint\")).group(1)\n",
    "            url = f\"https://{aoai_name}/openai/deployments/{MODEL}/images/edits?api-version={API_VERSION}\"\n",
    "\n",
    "            files = {\"image\": open(temp_path, \"rb\")}\n",
    "\n",
    "            data = {\n",
    "                \"prompt\": prompt,\n",
    "                \"n\": num_images,  # Number of images up to 10\n",
    "                \"quality\": quality,  # low, medium, high\n",
    "                \"size\": size,  # Values are: 1024x1024, 1536x1024, 1024x1536\n",
    "                \"output_compression\": 70,  # JPEG compression level (0-100)\n",
    "                \"output_format\": \"jpeg\",  # png, jpeg or webp\n",
    "                \"moderation\": \"auto\",  # auto or low\n",
    "                \"background\": \"auto\"  # auto, transparent or opaque\n",
    "            }\n",
    "\n",
    "            response = requests.post(url,\n",
    "                                     headers=headers,\n",
    "                                     files=files,\n",
    "                                     data=data)\n",
    "            response.raise_for_status()\n",
    "\n",
    "            images_data = response.json()[\"data\"]\n",
    "            encoded_images = [img[\"b64_json\"] for img in images_data]\n",
    "\n",
    "            output_images = []\n",
    "            for encoded_image in encoded_images:\n",
    "                filepath = self.save_image_with_timestamp(\n",
    "                    encoded_image, self.results_dirs['edition'], \"edited\")\n",
    "                output_images.append(filepath)\n",
    "\n",
    "            # Cleanup\n",
    "            os.unlink(temp_path)\n",
    "            files[\"image\"].close()\n",
    "\n",
    "            return output_images, f\"Successfully edited image with {len(output_images)} result(s)\"\n",
    "\n",
    "        except Exception as e:\n",
    "            return [], f\"Error editing image: {str(e)}\"\n",
    "\n",
    "    def image_compose(self,\n",
    "                      source_images,\n",
    "                      prompt,\n",
    "                      num_images=3,\n",
    "                      size=\"1024x1024\",\n",
    "                      quality=\"high\"):\n",
    "        \"\"\"Compose a new image using multiple source images\"\"\"\n",
    "        try:\n",
    "            if not source_images or len(source_images) == 0:\n",
    "                return [], \"Please upload at least one source image\"\n",
    "\n",
    "            # Save uploaded images temporarily\n",
    "            temp_paths = []\n",
    "            for img in source_images:\n",
    "                with tempfile.NamedTemporaryFile(delete=False,\n",
    "                                                 suffix='.jpg') as tmp_file:\n",
    "                    img.save(tmp_file.name)\n",
    "                    temp_paths.append(tmp_file.name)\n",
    "\n",
    "            files = [(f\"image[]\", open(path, \"rb\")) for path in temp_paths]\n",
    "            headers = {\"api-key\": os.getenv(\"key\")}\n",
    "            aoai_name = re.search(r'https://(.*?)/openai',\n",
    "                                  os.getenv(\"endpoint\")).group(1)\n",
    "            url = f\"https://{aoai_name}/openai/deployments/{MODEL}/images/edits?api-version={API_VERSION}\"\n",
    "\n",
    "            data = {\n",
    "                \"prompt\": prompt,\n",
    "                \"n\": num_images,  # Number of images up to 10\n",
    "                \"quality\": quality,  # low, medium, high\n",
    "                \"size\": size,  # Values are: 1024x1024, 1536x1024, 1024x1536\n",
    "                \"output_compression\": 70,  # JPEG compression level (0-100)\n",
    "                \"output_format\": \"jpeg\",  # png, jpeg or webp\n",
    "                \"moderation\": \"auto\",  # auto or low\n",
    "                \"background\": \"auto\"  # auto, transparent or opaque\n",
    "            }\n",
    "\n",
    "            response = requests.post(url,\n",
    "                                     headers=headers,\n",
    "                                     files=files,\n",
    "                                     data=data)\n",
    "            response.raise_for_status()\n",
    "\n",
    "            images_data = response.json()[\"data\"]\n",
    "            encoded_images = [img[\"b64_json\"] for img in images_data]\n",
    "\n",
    "            output_images = []\n",
    "            for encoded_image in encoded_images:\n",
    "                filepath = self.save_image_with_timestamp(\n",
    "                    encoded_image, self.results_dirs['composition'],\n",
    "                    \"composed\")\n",
    "                output_images.append(filepath)\n",
    "\n",
    "            # Cleanup\n",
    "            for file_tuple in files:\n",
    "                file_tuple[1].close()\n",
    "            for path in temp_paths:\n",
    "                os.unlink(path)\n",
    "\n",
    "            return output_images, f\"Successfully composed {len(output_images)} image(s) from {len(source_images)} source images\"\n",
    "\n",
    "        except Exception as e:\n",
    "            return [], f\"Error composing images: {str(e)}\"\n",
    "\n",
    "    def image_inpainting(self,\n",
    "                         initial_image,\n",
    "                         prompt,\n",
    "                         num_images=3,\n",
    "                         size=\"1024x1024\",\n",
    "                         quality=\"high\"):\n",
    "        \"\"\"Perform inpainting on an image by removing automatically the background of the image\"\"\"\n",
    "        try:\n",
    "            # Save uploaded image temporarily\n",
    "            with tempfile.NamedTemporaryFile(delete=False,\n",
    "                                             suffix='.jpg') as tmp_file:\n",
    "                initial_image.save(tmp_file.name)\n",
    "                temp_original = tmp_file.name\n",
    "\n",
    "            # Create mask by removing background\n",
    "            temp_mask = tempfile.NamedTemporaryFile(delete=False,\n",
    "                                                    suffix='.jpg').name\n",
    "\n",
    "            with open(temp_original, 'rb') as input_file:\n",
    "                with open(temp_mask, 'wb') as output_file:\n",
    "                    input_data = input_file.read()\n",
    "                    output_data = remove(input_data)\n",
    "                    output_file.write(output_data)\n",
    "\n",
    "            headers = {\"api-key\": os.getenv(\"key\")}\n",
    "            aoai_name = re.search(r'https://(.*?)/openai',\n",
    "                                  os.getenv(\"endpoint\")).group(1)\n",
    "            url = f\"https://{aoai_name}/openai/deployments/{MODEL}/images/edits?api-version={API_VERSION}\"\n",
    "\n",
    "            files = {\n",
    "                \"image\": open(temp_original, \"rb\"),\n",
    "                \"mask\": open(temp_mask, \"rb\"),\n",
    "            }\n",
    "            data = {\n",
    "                \"prompt\": prompt,\n",
    "                \"n\": num_images,  # Number of images up to 10\n",
    "                \"quality\": quality,  # low, medium, high\n",
    "                \"size\": size,  # Values are: 1024x1024, 1536x1024, 1024x1536\n",
    "                \"output_compression\": 70,  # JPEG compression level (0-100)\n",
    "                \"output_format\": \"jpeg\",  # png, jpeg or webp\n",
    "                \"moderation\": \"auto\",  # auto or low\n",
    "                \"background\": \"auto\"  # auto, transparent or opaque\n",
    "            }\n",
    "\n",
    "            response = requests.post(url,\n",
    "                                     headers=headers,\n",
    "                                     files=files,\n",
    "                                     data=data)\n",
    "            response.raise_for_status()\n",
    "\n",
    "            images_data = response.json()[\"data\"]\n",
    "            encoded_images = [img[\"b64_json\"] for img in images_data]\n",
    "\n",
    "            output_images = []\n",
    "            for encoded_image in encoded_images:\n",
    "                filepath = self.save_image_with_timestamp(\n",
    "                    encoded_image, self.results_dirs['inpainting'],\n",
    "                    \"inpainted\")\n",
    "                output_images.append(filepath)\n",
    "\n",
    "            # Cleanup\n",
    "            files[\"image\"].close()\n",
    "            files[\"mask\"].close()\n",
    "            os.unlink(temp_original)\n",
    "            os.unlink(temp_mask)\n",
    "\n",
    "            return output_images, f\"Successfully inpainted image with {len(output_images)} result(s)\"\n",
    "\n",
    "        except Exception as e:\n",
    "            return [], f\"Error inpainting image: {str(e)}\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4527516b-3c34-4244-94d6-b41492878792",
   "metadata": {},
   "source": [
    "## 3. Gradio webapp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "51a03561-3196-4963-9299-497e399df12d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the app\n",
    "app = GPTImageApp()\n",
    "\n",
    "\n",
    "def create_interface():\n",
    "    with gr.Blocks(title=\"Azure AI Foundry GPT-Image-1 Studio\",\n",
    "                   theme=gr.themes.Soft()) as webapp:\n",
    "\n",
    "        gr.Markdown(\"\"\"\n",
    "        # üé® Azure AI Foundry GPT-Image-1 Studio\n",
    "        \n",
    "        A comprehensive web application for AI-powered image generation, editing, composition, and inpainting using Azure AI Foundry GPT-Image-1 model.\n",
    "        \n",
    "        **Features:**\n",
    "        - üñºÔ∏è **Image Generation**: Create images from text prompts\n",
    "        - ‚úèÔ∏è **Image Editing**: Modify existing images with text instructions\n",
    "        - üé≠ **Image Composition**: Combine multiple images into one\n",
    "        - üé® **Image Inpainting**: Fill in or modify parts of images (background replacement)\n",
    "        \"\"\")\n",
    "\n",
    "        with gr.Tabs():\n",
    "            # Image Generation Tab\n",
    "            with gr.Tab(\"üñºÔ∏è 1. Image Generation\"):\n",
    "                gr.Markdown(\"### Generate images from text descriptions\")\n",
    "\n",
    "                # Example prompts for generation\n",
    "                gen_examples = [\n",
    "                    \"Generate a high-quality, realistic image of a stylish and cozy modern apartment interior. Include large windows with natural light, minimalist furniture, warm neutral tones, and a clean inviting atmosphere. The space should feel both elegant and livable.\",\n",
    "                    \"A man with a dog in Paris street close to a red car with a licence plate named 'a red car'\",\n",
    "                    \"A beautiful house in tropical modernism style inside of a forest and full of trees and plants\",\n",
    "                    \"A 3D cartoon-style action figure of a man named John, displayed inside a clear plastic blister package like a collectible toy. The figure resembles a Caucasian male with black hair, wearing a blue polo with the French flag in the upper left of the polo, black fitted pants, and black dress shoes. He has a titanium wedding band on his left hand. The packaging has a clean, modern, cartoonish design. The top of the packaging is bright blue, with bold white text that reads: 'John' as the name, and below it, in smaller text: 'I love Azure AI'. Inside the blister package, next to the figure, are miniature job-related accessories: a black iPhone, black Bose over-ear headphones, a tall coffee cup with the French flag, and a silver Microsoft Surface laptop. The overall look is colorful, professional, and playful ‚Äî like a limited-edition tech professional collectible figure sold in stores.\"\n",
    "                    \"A futuristic cityscape at sunset with flying cars and neon lights\",\n",
    "                    \"A cozy coffee shop interior with warm lighting and vintage furniture\",\n",
    "                    \"A high-resolution, commercial-quality perfume bottle with elegant design and transparent background\"\n",
    "                ]\n",
    "\n",
    "                with gr.Row():\n",
    "                    with gr.Column(scale=2):\n",
    "                        gen_prompt = gr.Textbox(\n",
    "                            label=\"‚úèÔ∏è Prompt\",\n",
    "                            placeholder=\"Describe the image you want to generate...\",\n",
    "                            lines=3)\n",
    "\n",
    "                        # Dropdown for example prompts\n",
    "                        gen_example_dropdown = gr.Dropdown(\n",
    "                            choices=gen_examples,\n",
    "                            label=\"üí° Examples prompts (click to use)\",\n",
    "                            value=None,\n",
    "                            interactive=True)\n",
    "\n",
    "                        with gr.Row():\n",
    "                            gen_num_images = gr.Slider(\n",
    "                                1,\n",
    "                                10,\n",
    "                                value=3,\n",
    "                                step=1,\n",
    "                                label=\"Number of images\")\n",
    "                            gen_size = gr.Dropdown(choices=[\"1024x1024\", \"1536x1024\", \"1024x1536\"],\n",
    "                                                   value=\"1024x1024\",\n",
    "                                                   label=\"Image resolution\")\n",
    "                            gen_quality = gr.Dropdown(\n",
    "                                choices=[\"high\", \"medium\", \"low\"],\n",
    "                                value=\"high\",\n",
    "                                label=\"Image quality\")\n",
    "\n",
    "                        gen_button = gr.Button(\"üé® IMAGE GENERATION\",\n",
    "                                               variant=\"primary\")\n",
    "\n",
    "                    with gr.Column(scale=4):\n",
    "                        gen_output = gr.Gallery(label=\"üñºÔ∏è Image resolution\",\n",
    "                                                columns=2,\n",
    "                                                rows=2)\n",
    "                        gen_status = gr.Textbox(label=\"‚úÖ Status\",\n",
    "                                                interactive=False)\n",
    "\n",
    "                # Event handlers\n",
    "                gen_example_dropdown.change(lambda x: x if x else \"\",\n",
    "                                            inputs=[gen_example_dropdown],\n",
    "                                            outputs=[gen_prompt])\n",
    "\n",
    "                gen_button.click(\n",
    "                    app.image_generation,\n",
    "                    inputs=[gen_prompt, gen_num_images, gen_size, gen_quality],\n",
    "                    outputs=[gen_output, gen_status])\n",
    "\n",
    "            # Image Editing Tab\n",
    "            with gr.Tab(\"‚úèÔ∏è 2. Image editing\"):\n",
    "                gr.Markdown(\"### Edit existing images with text instructions\")\n",
    "\n",
    "                # Example prompts for editing\n",
    "                edit_examples = [\n",
    "                    \"Change the color of the walls in light blue\",\n",
    "                    \"Add a darker sky\",\n",
    "                    \"Add some beard to the man\",\n",
    "                    \"Add a hat to the man\",\n",
    "                    \"Add sunglasses to the face\",\n",
    "                    \"Add some people in the background\",\n",
    "                ]\n",
    "\n",
    "                with gr.Row():\n",
    "                    with gr.Column(scale=2):\n",
    "                        edit_image = gr.Image(label=\"üì§ Upload image to edit\",\n",
    "                                              type=\"pil\")\n",
    "                        edit_prompt = gr.Textbox(\n",
    "                            label=\"‚úèÔ∏è Edit instructions\",\n",
    "                            placeholder=\"Describe how you want to modify the image...\",\n",
    "                            lines=3)\n",
    "\n",
    "                        # Dropdown for example prompts\n",
    "                        edit_example_dropdown = gr.Dropdown(\n",
    "                            choices=edit_examples,\n",
    "                            label=\"üí° Examples edit instructions (click to use)\",\n",
    "                            value=None,\n",
    "                            interactive=True)\n",
    "\n",
    "                        with gr.Row():\n",
    "                            edit_num_images = gr.Slider(\n",
    "                                1,\n",
    "                                10,\n",
    "                                value=3,\n",
    "                                step=1,\n",
    "                                label=\"Number of images\")\n",
    "                            edit_size = gr.Dropdown(choices=[\"1024x1024\", \"1536x1024\", \"1024x1536\"],\n",
    "                                                    value=\"1024x1024\",\n",
    "                                                    label=\"Image resolution\")\n",
    "                            edit_quality = gr.Dropdown(\n",
    "                                choices=[\"high\", \"medium\", \"low\"],\n",
    "                                value=\"high\",\n",
    "                                label=\"Image quality\")\n",
    "\n",
    "                        edit_button = gr.Button(\"‚úèÔ∏è IMAGE EDITION\",\n",
    "                                                variant=\"primary\")\n",
    "\n",
    "                    with gr.Column(scale=4):\n",
    "                        edit_output = gr.Gallery(label=\"üñºÔ∏è Edited images\",\n",
    "                                                 columns=2,\n",
    "                                                 rows=2)\n",
    "                        edit_status = gr.Textbox(label=\"‚úÖ Status\",\n",
    "                                                 interactive=False)\n",
    "\n",
    "                # Event handlers\n",
    "                edit_example_dropdown.change(lambda x: x if x else \"\",\n",
    "                                             inputs=[edit_example_dropdown],\n",
    "                                             outputs=[edit_prompt])\n",
    "\n",
    "                edit_button.click(app.image_edit,\n",
    "                                  inputs=[\n",
    "                                      edit_image, edit_prompt, edit_num_images,\n",
    "                                      edit_size, edit_quality\n",
    "                                  ],\n",
    "                                  outputs=[edit_output, edit_status])\n",
    "\n",
    "            # Image Composition Tab\n",
    "            with gr.Tab(\"üé≠ 3. Image composition\"):\n",
    "                gr.Markdown(\n",
    "                    \"### Combine multiple images into a single composition\")\n",
    "\n",
    "                # Example prompts for composition\n",
    "                compose_examples = [\n",
    "                    \"Combine the different images into a single one\",\n",
    "                    \"Generate a photorealistic image of a man wearing these items in the reference pictures. The man should walk in a busy street. We must see the Eiffel tower in the background.\",\n",
    "                    \"Show a person wearing these items in a professional office setting\",\n",
    "                    \"Display the items as a coordinated outfit in a fashion magazine layout\"\n",
    "                ]\n",
    "\n",
    "                with gr.Row():\n",
    "                    with gr.Column(scale=2):\n",
    "                        compose_images = gr.File(\n",
    "                            label=\"üì§ Upload source image(s)\",\n",
    "                            file_count=\"multiple\",\n",
    "                            file_types=[\"image\"])\n",
    "                        compose_prompt = gr.Textbox(\n",
    "                            label=\"‚úèÔ∏è Composition instructions\",\n",
    "                            placeholder=\"Describe how you want to combine the uploaded images...\",\n",
    "                            lines=3)\n",
    "\n",
    "                        # Dropdown for example prompts\n",
    "                        compose_example_dropdown = gr.Dropdown(\n",
    "                            choices=compose_examples,\n",
    "                            label=\"üí° Example composition instructions (click to use)\",\n",
    "                            value=None,\n",
    "                            interactive=True)\n",
    "\n",
    "                        with gr.Row():\n",
    "                            compose_num_images = gr.Slider(\n",
    "                                1,\n",
    "                                10,\n",
    "                                value=3,\n",
    "                                step=1,\n",
    "                                label=\"Number of images\")\n",
    "                            compose_size = gr.Dropdown(\n",
    "                                choices=[\"1024x1024\", \"1536x1024\", \"1024x1536\"],\n",
    "                                value=\"1024x1024\",\n",
    "                                label=\"Image resolution\")\n",
    "                            compose_quality = gr.Dropdown(\n",
    "                                choices=[\"high\", \"medium\", \"low\"],\n",
    "                                value=\"high\",\n",
    "                                label=\"Image quality\")\n",
    "\n",
    "                        compose_button = gr.Button(\"üé≠ IMAGE COMPOSITION\",\n",
    "                                                   variant=\"primary\")\n",
    "\n",
    "                    with gr.Column(scale=4):\n",
    "                        compose_output = gr.Gallery(label=\"üñºÔ∏è Composed images\",\n",
    "                                                    columns=2,\n",
    "                                                    rows=2)\n",
    "                        compose_status = gr.Textbox(label=\"‚úÖ Status\",\n",
    "                                                    interactive=False)\n",
    "\n",
    "                def handle_compose(files, prompt, num_images, size, quality):\n",
    "                    if not files:\n",
    "                        return [], \"Please upload at least one image\"\n",
    "\n",
    "                    # Convert uploaded files to PIL Images\n",
    "                    images = []\n",
    "                    for file in files:\n",
    "                        try:\n",
    "                            img = Image.open(file.name)\n",
    "                            images.append(img)\n",
    "                        except Exception as e:\n",
    "                            return [], f\"Error loading image {file.name}: {str(e)}\"\n",
    "\n",
    "                    return app.image_compose(images, prompt, num_images, size,\n",
    "                                             quality)\n",
    "\n",
    "                compose_button.click(handle_compose,\n",
    "                                     inputs=[\n",
    "                                         compose_images, compose_prompt,\n",
    "                                         compose_num_images, compose_size,\n",
    "                                         compose_quality\n",
    "                                     ],\n",
    "                                     outputs=[compose_output, compose_status])\n",
    "\n",
    "            # Image Inpainting Tab\n",
    "            with gr.Tab(\"üé® 4. Image inpainting\"):\n",
    "                gr.Markdown(\"### Fill in or modify parts of images using inpainting technique\")\n",
    "\n",
    "                # Example prompts for inpainting\n",
    "                inpaint_examples = [\n",
    "                    \"Add a busy street in the background. We must see the Eiffel tower in the background\",\n",
    "                    \"The car should be close to the sea. Change the color of the car to green. Change the licence plate to 'I am a green car'\",\n",
    "                    \"Change the color car to blue, white and red. Add a transparent background.\",\n",
    "                    \"Add a beautiful sunset sky with dramatic clouds\",\n",
    "                    \"Replace the background with a tropical beach scene\",\n",
    "                ]\n",
    "\n",
    "                with gr.Row():\n",
    "                    with gr.Column(scale=2):\n",
    "                        inpaint_image = gr.Image(\n",
    "                            label=\"üì§ Upload image for inpainting\", type=\"pil\")\n",
    "                        inpaint_prompt = gr.Textbox(\n",
    "                            label=\"‚úèÔ∏è Inpainting instructions\",\n",
    "                            placeholder=\"Describe what to add or change in the background...\",\n",
    "                            lines=3)\n",
    "\n",
    "                        # Dropdown for example prompts\n",
    "                        inpaint_example_dropdown = gr.Dropdown(\n",
    "                            choices=inpaint_examples,\n",
    "                            label=\"üí° Example inpainting instructions (click to use)\",\n",
    "                            value=None,\n",
    "                            interactive=True)\n",
    "\n",
    "                        with gr.Row():\n",
    "                            inpaint_num_images = gr.Slider(\n",
    "                                1,\n",
    "                                10,\n",
    "                                value=3,\n",
    "                                step=1,\n",
    "                                label=\"Number of images\")\n",
    "                            inpaint_size = gr.Dropdown(\n",
    "                                choices=[\"1024x1024\", \"1536x1024\", \"1024x1536\"],\n",
    "                                value=\"1024x1024\",\n",
    "                                label=\"Image resolution\")\n",
    "                            inpaint_quality = gr.Dropdown(\n",
    "                                choices=[\"high\", \"medium\", \"low\"],\n",
    "                                value=\"high\",\n",
    "                                label=\"Image quality\")\n",
    "\n",
    "                        inpaint_button = gr.Button(\"üé® IMAGE INPAINTING\",\n",
    "                                                   variant=\"primary\")\n",
    "\n",
    "                    with gr.Column(scale=4):\n",
    "                        inpaint_output = gr.Gallery(label=\"üñºÔ∏è Inpainted images\",\n",
    "                                                    columns=2,\n",
    "                                                    rows=2)\n",
    "                        inpaint_status = gr.Textbox(label=\"‚úÖ Status\",\n",
    "                                                    interactive=False)\n",
    "\n",
    "                # Event handlers\n",
    "                inpaint_example_dropdown.change(\n",
    "                    lambda x: x if x else \"\",\n",
    "                    inputs=[inpaint_example_dropdown],\n",
    "                    outputs=[inpaint_prompt])\n",
    "\n",
    "                inpaint_button.click(app.image_inpainting,\n",
    "                                     inputs=[\n",
    "                                         inpaint_image, inpaint_prompt,\n",
    "                                         inpaint_num_images, inpaint_size,\n",
    "                                         inpaint_quality\n",
    "                                     ],\n",
    "                                     outputs=[inpaint_output, inpaint_status])\n",
    "\n",
    "        gr.Markdown(\"\"\"\n",
    "        ---\n",
    "                        \n",
    "        ### üéØ Tips:\n",
    "        - Be specific and detailed in your prompts for better results\n",
    "        - Try different quality settings for various use cases\n",
    "        - Experiment with different image sizes based on your needs\n",
    "\n",
    "        All results powered by Azure AI Foundry\n",
    "        \"\"\")\n",
    "\n",
    "    return webapp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6d241d33-1377-40cb-93ed-6c1c37c27174",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7860\n",
      "* Running on public URL: https://8d09b9ee2b4bf8d4e5.gradio.live\n",
      "\n",
      "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"https://8d09b9ee2b4bf8d4e5.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "webapp = create_interface()\n",
    "\n",
    "webapp.launch(\n",
    "    share=True,\n",
    "    show_error=True,\n",
    "    favicon_path=None,  # Add your favicon path here\n",
    "    auth=None,  # Add authentication if needed: (\"username\", \"password\")\n",
    "    max_threads=40, # By default, Gradio uses a thread pool (inherited from FastAPI) with a maximum of 40 threads.\n",
    "    debug=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da3474cd-4d5a-4886-bcbe-31ac9d1ae41c",
   "metadata": {},
   "source": [
    "## 4. All generated images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1d191f74-5ac5-4f4b-9e99-aa320f4cca55",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['images/composition/azure_ai_foundry_gptimage1_composed_20250731_085845_086.jpg',\n",
       " 'images/composition/azure_ai_foundry_gptimage1_composed_20250731_085845_179.jpg',\n",
       " 'images/composition/azure_ai_foundry_gptimage1_composed_20250731_085845_235.jpg',\n",
       " 'images/edition/azure_ai_foundry_gptimage1_edited_20250731_085704_576.jpg',\n",
       " 'images/edition/azure_ai_foundry_gptimage1_edited_20250731_085704_655.jpg',\n",
       " 'images/edition/azure_ai_foundry_gptimage1_edited_20250731_085704_706.jpg',\n",
       " 'images/generation/azure_ai_foundry_gptimage1_generated_20250731_085520_839.jpg',\n",
       " 'images/generation/azure_ai_foundry_gptimage1_generated_20250731_085520_915.jpg',\n",
       " 'images/generation/azure_ai_foundry_gptimage1_generated_20250731_085520_966.jpg',\n",
       " 'images/inpainting/azure_ai_foundry_gptimage1_inpainted_20250731_090015_624.jpg',\n",
       " 'images/inpainting/azure_ai_foundry_gptimage1_inpainted_20250731_090015_706.jpg',\n",
       " 'images/inpainting/azure_ai_foundry_gptimage1_inpainted_20250731_090015_758.jpg']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gen_image_files_list = []\n",
    "\n",
    "for root, dirs, files in os.walk(IMAGES_DIR):\n",
    "    for file in files:\n",
    "        if file.lower().endswith((\".jpg\", \".jpeg\", \".png\", \".gif\", \".bmp\", \".tiff\", \".webp\")):\n",
    "            gen_image_files_list.append(os.path.join(root, file))\n",
    "\n",
    "\n",
    "gen_image_files_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "784584b0-eed9-4b51-a78c-c3227f23b4d9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <style>\n",
       "        #ipyplot-html-viewer-toggle-Emr2wCAuPvgnQ4TPPG92Gd {\n",
       "            position: absolute;\n",
       "            top: -9999px;\n",
       "            left: -9999px;\n",
       "            visibility: hidden;\n",
       "        }\n",
       "\n",
       "        #ipyplot-html-viewer-label-Emr2wCAuPvgnQ4TPPG92Gd { \n",
       "            position: relative;\n",
       "            display: inline-block;\n",
       "            cursor: pointer;\n",
       "            color: blue;\n",
       "            text-decoration: underline;\n",
       "        }\n",
       "\n",
       "        #ipyplot-html-viewer-textarea-Emr2wCAuPvgnQ4TPPG92Gd {\n",
       "            background: lightgrey;\n",
       "            width: 100%;\n",
       "            height: 0px;\n",
       "            display: none;\n",
       "        }\n",
       "\n",
       "        #ipyplot-html-viewer-toggle-Emr2wCAuPvgnQ4TPPG92Gd:checked ~ #ipyplot-html-viewer-textarea-Emr2wCAuPvgnQ4TPPG92Gd {\n",
       "            height: 200px;\n",
       "            display: block;\n",
       "        }\n",
       "\n",
       "        #ipyplot-html-viewer-toggle-Emr2wCAuPvgnQ4TPPG92Gd:checked + #ipyplot-html-viewer-label-Emr2wCAuPvgnQ4TPPG92Gd:after {\n",
       "            content: \"hide html\";\n",
       "            position: absolute;\n",
       "            top: 0;\n",
       "            left: 0;\n",
       "            right: 0;\n",
       "            bottom: 0;\n",
       "            background: white;\n",
       "            cursor: pointer;\n",
       "            color: blue;\n",
       "            text-decoration: underline;\n",
       "        }\n",
       "    </style>\n",
       "    <div>\n",
       "        <input type=\"checkbox\" id=\"ipyplot-html-viewer-toggle-Emr2wCAuPvgnQ4TPPG92Gd\">\n",
       "        <label id=\"ipyplot-html-viewer-label-Emr2wCAuPvgnQ4TPPG92Gd\" for=\"ipyplot-html-viewer-toggle-Emr2wCAuPvgnQ4TPPG92Gd\">show html</label>\n",
       "        <textarea id=\"ipyplot-html-viewer-textarea-Emr2wCAuPvgnQ4TPPG92Gd\" readonly>\n",
       "            \n",
       "        <style>\n",
       "        #ipyplot-imgs-container-div-AKCb26sPr7h6jfXHUsF2r4 {\n",
       "            width: 100%;\n",
       "            height: 100%;\n",
       "            margin: 0%;\n",
       "            overflow: auto;\n",
       "            position: relative;\n",
       "            overflow-y: scroll;\n",
       "        }\n",
       "\n",
       "        div.ipyplot-placeholder-div-AKCb26sPr7h6jfXHUsF2r4 {\n",
       "            width: 200px;\n",
       "            display: inline-block;\n",
       "            margin: 3px;\n",
       "            position: relative;\n",
       "        }\n",
       "\n",
       "        div.ipyplot-content-div-AKCb26sPr7h6jfXHUsF2r4 {\n",
       "            width: 200px;\n",
       "            background: white;\n",
       "            display: inline-block;\n",
       "            vertical-align: top;\n",
       "            text-align: center;\n",
       "            position: relative;\n",
       "            border: 2px solid #ddd;\n",
       "            top: 0;\n",
       "            left: 0;\n",
       "        }\n",
       "\n",
       "        div.ipyplot-content-div-AKCb26sPr7h6jfXHUsF2r4 span.ipyplot-img-close {\n",
       "            display: none;\n",
       "        }\n",
       "\n",
       "        div.ipyplot-content-div-AKCb26sPr7h6jfXHUsF2r4 span {\n",
       "            width: 100%;\n",
       "            height: 100%;\n",
       "            position: absolute;\n",
       "            top: 0;\n",
       "            left: 0;\n",
       "        }\n",
       "\n",
       "        div.ipyplot-content-div-AKCb26sPr7h6jfXHUsF2r4 img {\n",
       "            width: 200px;\n",
       "        }\n",
       "\n",
       "        div.ipyplot-content-div-AKCb26sPr7h6jfXHUsF2r4 span.ipyplot-img-close:hover {\n",
       "            cursor: zoom-out;\n",
       "        }\n",
       "        div.ipyplot-content-div-AKCb26sPr7h6jfXHUsF2r4 span.ipyplot-img-expand:hover {\n",
       "            cursor: zoom-in;\n",
       "        }\n",
       "\n",
       "        div[id^=ipyplot-content-div-AKCb26sPr7h6jfXHUsF2r4]:target {\n",
       "            transform: scale(2.5);\n",
       "            transform-origin: left top;\n",
       "            z-index: 5000;\n",
       "            top: 0;\n",
       "            left: 0;\n",
       "            position: absolute;\n",
       "        }\n",
       "\n",
       "        div[id^=ipyplot-content-div-AKCb26sPr7h6jfXHUsF2r4]:target span.ipyplot-img-close {\n",
       "            display: block;\n",
       "        }\n",
       "\n",
       "        div[id^=ipyplot-content-div-AKCb26sPr7h6jfXHUsF2r4]:target span.ipyplot-img-expand {\n",
       "            display: none;\n",
       "        }\n",
       "        </style>\n",
       "    <div id=\"ipyplot-imgs-container-div-AKCb26sPr7h6jfXHUsF2r4\">\n",
       "    <div class=\"ipyplot-placeholder-div-AKCb26sPr7h6jfXHUsF2r4\">\n",
       "        <div id=\"ipyplot-content-div-AKCb26sPr7h6jfXHUsF2r4-d8LqLUKL7ZrCCGpxTU2fYk\" class=\"ipyplot-content-div-AKCb26sPr7h6jfXHUsF2r4\">\n",
       "            <h4 style=\"font-size: 12px; word-wrap: break-word;\">0</h4>\n",
       "            <h4 style=\"font-size: 9px; padding-left: 10px; padding-right: 10px; width: 95%; word-wrap: break-word; white-space: normal;\">images/composition/azure_ai_foundry_gptimage1_composed_20250731_085845_086.jpg</h4><img src=\"images/composition/azure_ai_foundry_gptimage1_composed_20250731_085845_086.jpg\"/>\n",
       "            <a href=\"#!\">\n",
       "                <span class=\"ipyplot-img-close\"/>\n",
       "            </a>\n",
       "            <a href=\"#ipyplot-content-div-AKCb26sPr7h6jfXHUsF2r4-d8LqLUKL7ZrCCGpxTU2fYk\">\n",
       "                <span class=\"ipyplot-img-expand\"/>\n",
       "            </a>\n",
       "        </div>\n",
       "    </div>\n",
       "    \n",
       "    <div class=\"ipyplot-placeholder-div-AKCb26sPr7h6jfXHUsF2r4\">\n",
       "        <div id=\"ipyplot-content-div-AKCb26sPr7h6jfXHUsF2r4-NFWYApKQ58Rz5xLKdL7FTP\" class=\"ipyplot-content-div-AKCb26sPr7h6jfXHUsF2r4\">\n",
       "            <h4 style=\"font-size: 12px; word-wrap: break-word;\">1</h4>\n",
       "            <h4 style=\"font-size: 9px; padding-left: 10px; padding-right: 10px; width: 95%; word-wrap: break-word; white-space: normal;\">images/composition/azure_ai_foundry_gptimage1_composed_20250731_085845_179.jpg</h4><img src=\"images/composition/azure_ai_foundry_gptimage1_composed_20250731_085845_179.jpg\"/>\n",
       "            <a href=\"#!\">\n",
       "                <span class=\"ipyplot-img-close\"/>\n",
       "            </a>\n",
       "            <a href=\"#ipyplot-content-div-AKCb26sPr7h6jfXHUsF2r4-NFWYApKQ58Rz5xLKdL7FTP\">\n",
       "                <span class=\"ipyplot-img-expand\"/>\n",
       "            </a>\n",
       "        </div>\n",
       "    </div>\n",
       "    \n",
       "    <div class=\"ipyplot-placeholder-div-AKCb26sPr7h6jfXHUsF2r4\">\n",
       "        <div id=\"ipyplot-content-div-AKCb26sPr7h6jfXHUsF2r4-kAgeCtrSBE2mb8iS8yngHe\" class=\"ipyplot-content-div-AKCb26sPr7h6jfXHUsF2r4\">\n",
       "            <h4 style=\"font-size: 12px; word-wrap: break-word;\">2</h4>\n",
       "            <h4 style=\"font-size: 9px; padding-left: 10px; padding-right: 10px; width: 95%; word-wrap: break-word; white-space: normal;\">images/composition/azure_ai_foundry_gptimage1_composed_20250731_085845_235.jpg</h4><img src=\"images/composition/azure_ai_foundry_gptimage1_composed_20250731_085845_235.jpg\"/>\n",
       "            <a href=\"#!\">\n",
       "                <span class=\"ipyplot-img-close\"/>\n",
       "            </a>\n",
       "            <a href=\"#ipyplot-content-div-AKCb26sPr7h6jfXHUsF2r4-kAgeCtrSBE2mb8iS8yngHe\">\n",
       "                <span class=\"ipyplot-img-expand\"/>\n",
       "            </a>\n",
       "        </div>\n",
       "    </div>\n",
       "    \n",
       "    <div class=\"ipyplot-placeholder-div-AKCb26sPr7h6jfXHUsF2r4\">\n",
       "        <div id=\"ipyplot-content-div-AKCb26sPr7h6jfXHUsF2r4-3GJ5NPJKpqDohEBfip7Thg\" class=\"ipyplot-content-div-AKCb26sPr7h6jfXHUsF2r4\">\n",
       "            <h4 style=\"font-size: 12px; word-wrap: break-word;\">3</h4>\n",
       "            <h4 style=\"font-size: 9px; padding-left: 10px; padding-right: 10px; width: 95%; word-wrap: break-word; white-space: normal;\">images/edition/azure_ai_foundry_gptimage1_edited_20250731_085704_576.jpg</h4><img src=\"images/edition/azure_ai_foundry_gptimage1_edited_20250731_085704_576.jpg\"/>\n",
       "            <a href=\"#!\">\n",
       "                <span class=\"ipyplot-img-close\"/>\n",
       "            </a>\n",
       "            <a href=\"#ipyplot-content-div-AKCb26sPr7h6jfXHUsF2r4-3GJ5NPJKpqDohEBfip7Thg\">\n",
       "                <span class=\"ipyplot-img-expand\"/>\n",
       "            </a>\n",
       "        </div>\n",
       "    </div>\n",
       "    \n",
       "    <div class=\"ipyplot-placeholder-div-AKCb26sPr7h6jfXHUsF2r4\">\n",
       "        <div id=\"ipyplot-content-div-AKCb26sPr7h6jfXHUsF2r4-jPLrvaCV7jN4eJWXBg8hsg\" class=\"ipyplot-content-div-AKCb26sPr7h6jfXHUsF2r4\">\n",
       "            <h4 style=\"font-size: 12px; word-wrap: break-word;\">4</h4>\n",
       "            <h4 style=\"font-size: 9px; padding-left: 10px; padding-right: 10px; width: 95%; word-wrap: break-word; white-space: normal;\">images/edition/azure_ai_foundry_gptimage1_edited_20250731_085704_655.jpg</h4><img src=\"images/edition/azure_ai_foundry_gptimage1_edited_20250731_085704_655.jpg\"/>\n",
       "            <a href=\"#!\">\n",
       "                <span class=\"ipyplot-img-close\"/>\n",
       "            </a>\n",
       "            <a href=\"#ipyplot-content-div-AKCb26sPr7h6jfXHUsF2r4-jPLrvaCV7jN4eJWXBg8hsg\">\n",
       "                <span class=\"ipyplot-img-expand\"/>\n",
       "            </a>\n",
       "        </div>\n",
       "    </div>\n",
       "    \n",
       "    <div class=\"ipyplot-placeholder-div-AKCb26sPr7h6jfXHUsF2r4\">\n",
       "        <div id=\"ipyplot-content-div-AKCb26sPr7h6jfXHUsF2r4-MjEDKDPfqRWLwhVvYMVidH\" class=\"ipyplot-content-div-AKCb26sPr7h6jfXHUsF2r4\">\n",
       "            <h4 style=\"font-size: 12px; word-wrap: break-word;\">5</h4>\n",
       "            <h4 style=\"font-size: 9px; padding-left: 10px; padding-right: 10px; width: 95%; word-wrap: break-word; white-space: normal;\">images/edition/azure_ai_foundry_gptimage1_edited_20250731_085704_706.jpg</h4><img src=\"images/edition/azure_ai_foundry_gptimage1_edited_20250731_085704_706.jpg\"/>\n",
       "            <a href=\"#!\">\n",
       "                <span class=\"ipyplot-img-close\"/>\n",
       "            </a>\n",
       "            <a href=\"#ipyplot-content-div-AKCb26sPr7h6jfXHUsF2r4-MjEDKDPfqRWLwhVvYMVidH\">\n",
       "                <span class=\"ipyplot-img-expand\"/>\n",
       "            </a>\n",
       "        </div>\n",
       "    </div>\n",
       "    \n",
       "    <div class=\"ipyplot-placeholder-div-AKCb26sPr7h6jfXHUsF2r4\">\n",
       "        <div id=\"ipyplot-content-div-AKCb26sPr7h6jfXHUsF2r4-hsEqsGmc9G8QsPSf3UYRSq\" class=\"ipyplot-content-div-AKCb26sPr7h6jfXHUsF2r4\">\n",
       "            <h4 style=\"font-size: 12px; word-wrap: break-word;\">6</h4>\n",
       "            <h4 style=\"font-size: 9px; padding-left: 10px; padding-right: 10px; width: 95%; word-wrap: break-word; white-space: normal;\">images/generation/azure_ai_foundry_gptimage1_generated_20250731_085520_839.jpg</h4><img src=\"images/generation/azure_ai_foundry_gptimage1_generated_20250731_085520_839.jpg\"/>\n",
       "            <a href=\"#!\">\n",
       "                <span class=\"ipyplot-img-close\"/>\n",
       "            </a>\n",
       "            <a href=\"#ipyplot-content-div-AKCb26sPr7h6jfXHUsF2r4-hsEqsGmc9G8QsPSf3UYRSq\">\n",
       "                <span class=\"ipyplot-img-expand\"/>\n",
       "            </a>\n",
       "        </div>\n",
       "    </div>\n",
       "    \n",
       "    <div class=\"ipyplot-placeholder-div-AKCb26sPr7h6jfXHUsF2r4\">\n",
       "        <div id=\"ipyplot-content-div-AKCb26sPr7h6jfXHUsF2r4-PDNHXMEobYUbFxVAb6HQRg\" class=\"ipyplot-content-div-AKCb26sPr7h6jfXHUsF2r4\">\n",
       "            <h4 style=\"font-size: 12px; word-wrap: break-word;\">7</h4>\n",
       "            <h4 style=\"font-size: 9px; padding-left: 10px; padding-right: 10px; width: 95%; word-wrap: break-word; white-space: normal;\">images/generation/azure_ai_foundry_gptimage1_generated_20250731_085520_915.jpg</h4><img src=\"images/generation/azure_ai_foundry_gptimage1_generated_20250731_085520_915.jpg\"/>\n",
       "            <a href=\"#!\">\n",
       "                <span class=\"ipyplot-img-close\"/>\n",
       "            </a>\n",
       "            <a href=\"#ipyplot-content-div-AKCb26sPr7h6jfXHUsF2r4-PDNHXMEobYUbFxVAb6HQRg\">\n",
       "                <span class=\"ipyplot-img-expand\"/>\n",
       "            </a>\n",
       "        </div>\n",
       "    </div>\n",
       "    \n",
       "    <div class=\"ipyplot-placeholder-div-AKCb26sPr7h6jfXHUsF2r4\">\n",
       "        <div id=\"ipyplot-content-div-AKCb26sPr7h6jfXHUsF2r4-GyNnnweyCE3gfWqtN5jSH5\" class=\"ipyplot-content-div-AKCb26sPr7h6jfXHUsF2r4\">\n",
       "            <h4 style=\"font-size: 12px; word-wrap: break-word;\">8</h4>\n",
       "            <h4 style=\"font-size: 9px; padding-left: 10px; padding-right: 10px; width: 95%; word-wrap: break-word; white-space: normal;\">images/generation/azure_ai_foundry_gptimage1_generated_20250731_085520_966.jpg</h4><img src=\"images/generation/azure_ai_foundry_gptimage1_generated_20250731_085520_966.jpg\"/>\n",
       "            <a href=\"#!\">\n",
       "                <span class=\"ipyplot-img-close\"/>\n",
       "            </a>\n",
       "            <a href=\"#ipyplot-content-div-AKCb26sPr7h6jfXHUsF2r4-GyNnnweyCE3gfWqtN5jSH5\">\n",
       "                <span class=\"ipyplot-img-expand\"/>\n",
       "            </a>\n",
       "        </div>\n",
       "    </div>\n",
       "    \n",
       "    <div class=\"ipyplot-placeholder-div-AKCb26sPr7h6jfXHUsF2r4\">\n",
       "        <div id=\"ipyplot-content-div-AKCb26sPr7h6jfXHUsF2r4-KJFQjg3VgaFTmx2M9qFMCW\" class=\"ipyplot-content-div-AKCb26sPr7h6jfXHUsF2r4\">\n",
       "            <h4 style=\"font-size: 12px; word-wrap: break-word;\">9</h4>\n",
       "            <h4 style=\"font-size: 9px; padding-left: 10px; padding-right: 10px; width: 95%; word-wrap: break-word; white-space: normal;\">images/inpainting/azure_ai_foundry_gptimage1_inpainted_20250731_090015_624.jpg</h4><img src=\"images/inpainting/azure_ai_foundry_gptimage1_inpainted_20250731_090015_624.jpg\"/>\n",
       "            <a href=\"#!\">\n",
       "                <span class=\"ipyplot-img-close\"/>\n",
       "            </a>\n",
       "            <a href=\"#ipyplot-content-div-AKCb26sPr7h6jfXHUsF2r4-KJFQjg3VgaFTmx2M9qFMCW\">\n",
       "                <span class=\"ipyplot-img-expand\"/>\n",
       "            </a>\n",
       "        </div>\n",
       "    </div>\n",
       "    \n",
       "    <div class=\"ipyplot-placeholder-div-AKCb26sPr7h6jfXHUsF2r4\">\n",
       "        <div id=\"ipyplot-content-div-AKCb26sPr7h6jfXHUsF2r4-TU2BX5MepNeeRiE7TYekk9\" class=\"ipyplot-content-div-AKCb26sPr7h6jfXHUsF2r4\">\n",
       "            <h4 style=\"font-size: 12px; word-wrap: break-word;\">10</h4>\n",
       "            <h4 style=\"font-size: 9px; padding-left: 10px; padding-right: 10px; width: 95%; word-wrap: break-word; white-space: normal;\">images/inpainting/azure_ai_foundry_gptimage1_inpainted_20250731_090015_706.jpg</h4><img src=\"images/inpainting/azure_ai_foundry_gptimage1_inpainted_20250731_090015_706.jpg\"/>\n",
       "            <a href=\"#!\">\n",
       "                <span class=\"ipyplot-img-close\"/>\n",
       "            </a>\n",
       "            <a href=\"#ipyplot-content-div-AKCb26sPr7h6jfXHUsF2r4-TU2BX5MepNeeRiE7TYekk9\">\n",
       "                <span class=\"ipyplot-img-expand\"/>\n",
       "            </a>\n",
       "        </div>\n",
       "    </div>\n",
       "    \n",
       "    <div class=\"ipyplot-placeholder-div-AKCb26sPr7h6jfXHUsF2r4\">\n",
       "        <div id=\"ipyplot-content-div-AKCb26sPr7h6jfXHUsF2r4-VB7j2w78Hg9i3PPEbdPeX5\" class=\"ipyplot-content-div-AKCb26sPr7h6jfXHUsF2r4\">\n",
       "            <h4 style=\"font-size: 12px; word-wrap: break-word;\">11</h4>\n",
       "            <h4 style=\"font-size: 9px; padding-left: 10px; padding-right: 10px; width: 95%; word-wrap: break-word; white-space: normal;\">images/inpainting/azure_ai_foundry_gptimage1_inpainted_20250731_090015_758.jpg</h4><img src=\"images/inpainting/azure_ai_foundry_gptimage1_inpainted_20250731_090015_758.jpg\"/>\n",
       "            <a href=\"#!\">\n",
       "                <span class=\"ipyplot-img-close\"/>\n",
       "            </a>\n",
       "            <a href=\"#ipyplot-content-div-AKCb26sPr7h6jfXHUsF2r4-VB7j2w78Hg9i3PPEbdPeX5\">\n",
       "                <span class=\"ipyplot-img-expand\"/>\n",
       "            </a>\n",
       "        </div>\n",
       "    </div>\n",
       "    </div>\n",
       "        </textarea>\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "        <style>\n",
       "        #ipyplot-imgs-container-div-AKCb26sPr7h6jfXHUsF2r4 {\n",
       "            width: 100%;\n",
       "            height: 100%;\n",
       "            margin: 0%;\n",
       "            overflow: auto;\n",
       "            position: relative;\n",
       "            overflow-y: scroll;\n",
       "        }\n",
       "\n",
       "        div.ipyplot-placeholder-div-AKCb26sPr7h6jfXHUsF2r4 {\n",
       "            width: 200px;\n",
       "            display: inline-block;\n",
       "            margin: 3px;\n",
       "            position: relative;\n",
       "        }\n",
       "\n",
       "        div.ipyplot-content-div-AKCb26sPr7h6jfXHUsF2r4 {\n",
       "            width: 200px;\n",
       "            background: white;\n",
       "            display: inline-block;\n",
       "            vertical-align: top;\n",
       "            text-align: center;\n",
       "            position: relative;\n",
       "            border: 2px solid #ddd;\n",
       "            top: 0;\n",
       "            left: 0;\n",
       "        }\n",
       "\n",
       "        div.ipyplot-content-div-AKCb26sPr7h6jfXHUsF2r4 span.ipyplot-img-close {\n",
       "            display: none;\n",
       "        }\n",
       "\n",
       "        div.ipyplot-content-div-AKCb26sPr7h6jfXHUsF2r4 span {\n",
       "            width: 100%;\n",
       "            height: 100%;\n",
       "            position: absolute;\n",
       "            top: 0;\n",
       "            left: 0;\n",
       "        }\n",
       "\n",
       "        div.ipyplot-content-div-AKCb26sPr7h6jfXHUsF2r4 img {\n",
       "            width: 200px;\n",
       "        }\n",
       "\n",
       "        div.ipyplot-content-div-AKCb26sPr7h6jfXHUsF2r4 span.ipyplot-img-close:hover {\n",
       "            cursor: zoom-out;\n",
       "        }\n",
       "        div.ipyplot-content-div-AKCb26sPr7h6jfXHUsF2r4 span.ipyplot-img-expand:hover {\n",
       "            cursor: zoom-in;\n",
       "        }\n",
       "\n",
       "        div[id^=ipyplot-content-div-AKCb26sPr7h6jfXHUsF2r4]:target {\n",
       "            transform: scale(2.5);\n",
       "            transform-origin: left top;\n",
       "            z-index: 5000;\n",
       "            top: 0;\n",
       "            left: 0;\n",
       "            position: absolute;\n",
       "        }\n",
       "\n",
       "        div[id^=ipyplot-content-div-AKCb26sPr7h6jfXHUsF2r4]:target span.ipyplot-img-close {\n",
       "            display: block;\n",
       "        }\n",
       "\n",
       "        div[id^=ipyplot-content-div-AKCb26sPr7h6jfXHUsF2r4]:target span.ipyplot-img-expand {\n",
       "            display: none;\n",
       "        }\n",
       "        </style>\n",
       "    <div id=\"ipyplot-imgs-container-div-AKCb26sPr7h6jfXHUsF2r4\">\n",
       "    <div class=\"ipyplot-placeholder-div-AKCb26sPr7h6jfXHUsF2r4\">\n",
       "        <div id=\"ipyplot-content-div-AKCb26sPr7h6jfXHUsF2r4-d8LqLUKL7ZrCCGpxTU2fYk\" class=\"ipyplot-content-div-AKCb26sPr7h6jfXHUsF2r4\">\n",
       "            <h4 style=\"font-size: 12px; word-wrap: break-word;\">0</h4>\n",
       "            <h4 style=\"font-size: 9px; padding-left: 10px; padding-right: 10px; width: 95%; word-wrap: break-word; white-space: normal;\">images/composition/azure_ai_foundry_gptimage1_composed_20250731_085845_086.jpg</h4><img src=\"images/composition/azure_ai_foundry_gptimage1_composed_20250731_085845_086.jpg\"/>\n",
       "            <a href=\"#!\">\n",
       "                <span class=\"ipyplot-img-close\"/>\n",
       "            </a>\n",
       "            <a href=\"#ipyplot-content-div-AKCb26sPr7h6jfXHUsF2r4-d8LqLUKL7ZrCCGpxTU2fYk\">\n",
       "                <span class=\"ipyplot-img-expand\"/>\n",
       "            </a>\n",
       "        </div>\n",
       "    </div>\n",
       "    \n",
       "    <div class=\"ipyplot-placeholder-div-AKCb26sPr7h6jfXHUsF2r4\">\n",
       "        <div id=\"ipyplot-content-div-AKCb26sPr7h6jfXHUsF2r4-NFWYApKQ58Rz5xLKdL7FTP\" class=\"ipyplot-content-div-AKCb26sPr7h6jfXHUsF2r4\">\n",
       "            <h4 style=\"font-size: 12px; word-wrap: break-word;\">1</h4>\n",
       "            <h4 style=\"font-size: 9px; padding-left: 10px; padding-right: 10px; width: 95%; word-wrap: break-word; white-space: normal;\">images/composition/azure_ai_foundry_gptimage1_composed_20250731_085845_179.jpg</h4><img src=\"images/composition/azure_ai_foundry_gptimage1_composed_20250731_085845_179.jpg\"/>\n",
       "            <a href=\"#!\">\n",
       "                <span class=\"ipyplot-img-close\"/>\n",
       "            </a>\n",
       "            <a href=\"#ipyplot-content-div-AKCb26sPr7h6jfXHUsF2r4-NFWYApKQ58Rz5xLKdL7FTP\">\n",
       "                <span class=\"ipyplot-img-expand\"/>\n",
       "            </a>\n",
       "        </div>\n",
       "    </div>\n",
       "    \n",
       "    <div class=\"ipyplot-placeholder-div-AKCb26sPr7h6jfXHUsF2r4\">\n",
       "        <div id=\"ipyplot-content-div-AKCb26sPr7h6jfXHUsF2r4-kAgeCtrSBE2mb8iS8yngHe\" class=\"ipyplot-content-div-AKCb26sPr7h6jfXHUsF2r4\">\n",
       "            <h4 style=\"font-size: 12px; word-wrap: break-word;\">2</h4>\n",
       "            <h4 style=\"font-size: 9px; padding-left: 10px; padding-right: 10px; width: 95%; word-wrap: break-word; white-space: normal;\">images/composition/azure_ai_foundry_gptimage1_composed_20250731_085845_235.jpg</h4><img src=\"images/composition/azure_ai_foundry_gptimage1_composed_20250731_085845_235.jpg\"/>\n",
       "            <a href=\"#!\">\n",
       "                <span class=\"ipyplot-img-close\"/>\n",
       "            </a>\n",
       "            <a href=\"#ipyplot-content-div-AKCb26sPr7h6jfXHUsF2r4-kAgeCtrSBE2mb8iS8yngHe\">\n",
       "                <span class=\"ipyplot-img-expand\"/>\n",
       "            </a>\n",
       "        </div>\n",
       "    </div>\n",
       "    \n",
       "    <div class=\"ipyplot-placeholder-div-AKCb26sPr7h6jfXHUsF2r4\">\n",
       "        <div id=\"ipyplot-content-div-AKCb26sPr7h6jfXHUsF2r4-3GJ5NPJKpqDohEBfip7Thg\" class=\"ipyplot-content-div-AKCb26sPr7h6jfXHUsF2r4\">\n",
       "            <h4 style=\"font-size: 12px; word-wrap: break-word;\">3</h4>\n",
       "            <h4 style=\"font-size: 9px; padding-left: 10px; padding-right: 10px; width: 95%; word-wrap: break-word; white-space: normal;\">images/edition/azure_ai_foundry_gptimage1_edited_20250731_085704_576.jpg</h4><img src=\"images/edition/azure_ai_foundry_gptimage1_edited_20250731_085704_576.jpg\"/>\n",
       "            <a href=\"#!\">\n",
       "                <span class=\"ipyplot-img-close\"/>\n",
       "            </a>\n",
       "            <a href=\"#ipyplot-content-div-AKCb26sPr7h6jfXHUsF2r4-3GJ5NPJKpqDohEBfip7Thg\">\n",
       "                <span class=\"ipyplot-img-expand\"/>\n",
       "            </a>\n",
       "        </div>\n",
       "    </div>\n",
       "    \n",
       "    <div class=\"ipyplot-placeholder-div-AKCb26sPr7h6jfXHUsF2r4\">\n",
       "        <div id=\"ipyplot-content-div-AKCb26sPr7h6jfXHUsF2r4-jPLrvaCV7jN4eJWXBg8hsg\" class=\"ipyplot-content-div-AKCb26sPr7h6jfXHUsF2r4\">\n",
       "            <h4 style=\"font-size: 12px; word-wrap: break-word;\">4</h4>\n",
       "            <h4 style=\"font-size: 9px; padding-left: 10px; padding-right: 10px; width: 95%; word-wrap: break-word; white-space: normal;\">images/edition/azure_ai_foundry_gptimage1_edited_20250731_085704_655.jpg</h4><img src=\"images/edition/azure_ai_foundry_gptimage1_edited_20250731_085704_655.jpg\"/>\n",
       "            <a href=\"#!\">\n",
       "                <span class=\"ipyplot-img-close\"/>\n",
       "            </a>\n",
       "            <a href=\"#ipyplot-content-div-AKCb26sPr7h6jfXHUsF2r4-jPLrvaCV7jN4eJWXBg8hsg\">\n",
       "                <span class=\"ipyplot-img-expand\"/>\n",
       "            </a>\n",
       "        </div>\n",
       "    </div>\n",
       "    \n",
       "    <div class=\"ipyplot-placeholder-div-AKCb26sPr7h6jfXHUsF2r4\">\n",
       "        <div id=\"ipyplot-content-div-AKCb26sPr7h6jfXHUsF2r4-MjEDKDPfqRWLwhVvYMVidH\" class=\"ipyplot-content-div-AKCb26sPr7h6jfXHUsF2r4\">\n",
       "            <h4 style=\"font-size: 12px; word-wrap: break-word;\">5</h4>\n",
       "            <h4 style=\"font-size: 9px; padding-left: 10px; padding-right: 10px; width: 95%; word-wrap: break-word; white-space: normal;\">images/edition/azure_ai_foundry_gptimage1_edited_20250731_085704_706.jpg</h4><img src=\"images/edition/azure_ai_foundry_gptimage1_edited_20250731_085704_706.jpg\"/>\n",
       "            <a href=\"#!\">\n",
       "                <span class=\"ipyplot-img-close\"/>\n",
       "            </a>\n",
       "            <a href=\"#ipyplot-content-div-AKCb26sPr7h6jfXHUsF2r4-MjEDKDPfqRWLwhVvYMVidH\">\n",
       "                <span class=\"ipyplot-img-expand\"/>\n",
       "            </a>\n",
       "        </div>\n",
       "    </div>\n",
       "    \n",
       "    <div class=\"ipyplot-placeholder-div-AKCb26sPr7h6jfXHUsF2r4\">\n",
       "        <div id=\"ipyplot-content-div-AKCb26sPr7h6jfXHUsF2r4-hsEqsGmc9G8QsPSf3UYRSq\" class=\"ipyplot-content-div-AKCb26sPr7h6jfXHUsF2r4\">\n",
       "            <h4 style=\"font-size: 12px; word-wrap: break-word;\">6</h4>\n",
       "            <h4 style=\"font-size: 9px; padding-left: 10px; padding-right: 10px; width: 95%; word-wrap: break-word; white-space: normal;\">images/generation/azure_ai_foundry_gptimage1_generated_20250731_085520_839.jpg</h4><img src=\"images/generation/azure_ai_foundry_gptimage1_generated_20250731_085520_839.jpg\"/>\n",
       "            <a href=\"#!\">\n",
       "                <span class=\"ipyplot-img-close\"/>\n",
       "            </a>\n",
       "            <a href=\"#ipyplot-content-div-AKCb26sPr7h6jfXHUsF2r4-hsEqsGmc9G8QsPSf3UYRSq\">\n",
       "                <span class=\"ipyplot-img-expand\"/>\n",
       "            </a>\n",
       "        </div>\n",
       "    </div>\n",
       "    \n",
       "    <div class=\"ipyplot-placeholder-div-AKCb26sPr7h6jfXHUsF2r4\">\n",
       "        <div id=\"ipyplot-content-div-AKCb26sPr7h6jfXHUsF2r4-PDNHXMEobYUbFxVAb6HQRg\" class=\"ipyplot-content-div-AKCb26sPr7h6jfXHUsF2r4\">\n",
       "            <h4 style=\"font-size: 12px; word-wrap: break-word;\">7</h4>\n",
       "            <h4 style=\"font-size: 9px; padding-left: 10px; padding-right: 10px; width: 95%; word-wrap: break-word; white-space: normal;\">images/generation/azure_ai_foundry_gptimage1_generated_20250731_085520_915.jpg</h4><img src=\"images/generation/azure_ai_foundry_gptimage1_generated_20250731_085520_915.jpg\"/>\n",
       "            <a href=\"#!\">\n",
       "                <span class=\"ipyplot-img-close\"/>\n",
       "            </a>\n",
       "            <a href=\"#ipyplot-content-div-AKCb26sPr7h6jfXHUsF2r4-PDNHXMEobYUbFxVAb6HQRg\">\n",
       "                <span class=\"ipyplot-img-expand\"/>\n",
       "            </a>\n",
       "        </div>\n",
       "    </div>\n",
       "    \n",
       "    <div class=\"ipyplot-placeholder-div-AKCb26sPr7h6jfXHUsF2r4\">\n",
       "        <div id=\"ipyplot-content-div-AKCb26sPr7h6jfXHUsF2r4-GyNnnweyCE3gfWqtN5jSH5\" class=\"ipyplot-content-div-AKCb26sPr7h6jfXHUsF2r4\">\n",
       "            <h4 style=\"font-size: 12px; word-wrap: break-word;\">8</h4>\n",
       "            <h4 style=\"font-size: 9px; padding-left: 10px; padding-right: 10px; width: 95%; word-wrap: break-word; white-space: normal;\">images/generation/azure_ai_foundry_gptimage1_generated_20250731_085520_966.jpg</h4><img src=\"images/generation/azure_ai_foundry_gptimage1_generated_20250731_085520_966.jpg\"/>\n",
       "            <a href=\"#!\">\n",
       "                <span class=\"ipyplot-img-close\"/>\n",
       "            </a>\n",
       "            <a href=\"#ipyplot-content-div-AKCb26sPr7h6jfXHUsF2r4-GyNnnweyCE3gfWqtN5jSH5\">\n",
       "                <span class=\"ipyplot-img-expand\"/>\n",
       "            </a>\n",
       "        </div>\n",
       "    </div>\n",
       "    \n",
       "    <div class=\"ipyplot-placeholder-div-AKCb26sPr7h6jfXHUsF2r4\">\n",
       "        <div id=\"ipyplot-content-div-AKCb26sPr7h6jfXHUsF2r4-KJFQjg3VgaFTmx2M9qFMCW\" class=\"ipyplot-content-div-AKCb26sPr7h6jfXHUsF2r4\">\n",
       "            <h4 style=\"font-size: 12px; word-wrap: break-word;\">9</h4>\n",
       "            <h4 style=\"font-size: 9px; padding-left: 10px; padding-right: 10px; width: 95%; word-wrap: break-word; white-space: normal;\">images/inpainting/azure_ai_foundry_gptimage1_inpainted_20250731_090015_624.jpg</h4><img src=\"images/inpainting/azure_ai_foundry_gptimage1_inpainted_20250731_090015_624.jpg\"/>\n",
       "            <a href=\"#!\">\n",
       "                <span class=\"ipyplot-img-close\"/>\n",
       "            </a>\n",
       "            <a href=\"#ipyplot-content-div-AKCb26sPr7h6jfXHUsF2r4-KJFQjg3VgaFTmx2M9qFMCW\">\n",
       "                <span class=\"ipyplot-img-expand\"/>\n",
       "            </a>\n",
       "        </div>\n",
       "    </div>\n",
       "    \n",
       "    <div class=\"ipyplot-placeholder-div-AKCb26sPr7h6jfXHUsF2r4\">\n",
       "        <div id=\"ipyplot-content-div-AKCb26sPr7h6jfXHUsF2r4-TU2BX5MepNeeRiE7TYekk9\" class=\"ipyplot-content-div-AKCb26sPr7h6jfXHUsF2r4\">\n",
       "            <h4 style=\"font-size: 12px; word-wrap: break-word;\">10</h4>\n",
       "            <h4 style=\"font-size: 9px; padding-left: 10px; padding-right: 10px; width: 95%; word-wrap: break-word; white-space: normal;\">images/inpainting/azure_ai_foundry_gptimage1_inpainted_20250731_090015_706.jpg</h4><img src=\"images/inpainting/azure_ai_foundry_gptimage1_inpainted_20250731_090015_706.jpg\"/>\n",
       "            <a href=\"#!\">\n",
       "                <span class=\"ipyplot-img-close\"/>\n",
       "            </a>\n",
       "            <a href=\"#ipyplot-content-div-AKCb26sPr7h6jfXHUsF2r4-TU2BX5MepNeeRiE7TYekk9\">\n",
       "                <span class=\"ipyplot-img-expand\"/>\n",
       "            </a>\n",
       "        </div>\n",
       "    </div>\n",
       "    \n",
       "    <div class=\"ipyplot-placeholder-div-AKCb26sPr7h6jfXHUsF2r4\">\n",
       "        <div id=\"ipyplot-content-div-AKCb26sPr7h6jfXHUsF2r4-VB7j2w78Hg9i3PPEbdPeX5\" class=\"ipyplot-content-div-AKCb26sPr7h6jfXHUsF2r4\">\n",
       "            <h4 style=\"font-size: 12px; word-wrap: break-word;\">11</h4>\n",
       "            <h4 style=\"font-size: 9px; padding-left: 10px; padding-right: 10px; width: 95%; word-wrap: break-word; white-space: normal;\">images/inpainting/azure_ai_foundry_gptimage1_inpainted_20250731_090015_758.jpg</h4><img src=\"images/inpainting/azure_ai_foundry_gptimage1_inpainted_20250731_090015_758.jpg\"/>\n",
       "            <a href=\"#!\">\n",
       "                <span class=\"ipyplot-img-close\"/>\n",
       "            </a>\n",
       "            <a href=\"#ipyplot-content-div-AKCb26sPr7h6jfXHUsF2r4-VB7j2w78Hg9i3PPEbdPeX5\">\n",
       "                <span class=\"ipyplot-img-expand\"/>\n",
       "            </a>\n",
       "        </div>\n",
       "    </div>\n",
       "    </div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "if len(gen_image_files_list) > 0:\n",
    "    ipyplot.plot_images(gen_image_files_list, img_width=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d521b473-0dae-49ea-b144-1c2a767dc4ac",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10 - SDK v2",
   "language": "python",
   "name": "python310-sdkv2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
