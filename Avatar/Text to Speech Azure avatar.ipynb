{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "873786b9",
   "metadata": {},
   "source": [
    "# Text to Speech avatar\n",
    "\n",
    "## From text to speech with a video avatar provided by Azure Speech Services\n",
    "Custom text to speech avatar allows you to create a customized, one-of-a-kind synthetic talking avatar for your application. With custom text to speech avatar, you can build a unique and natural-looking avatar for your product or brand by providing video recording data of your selected actors. If you also create a custom neural voice for the same actor and use it as the avatar's voice, the avatar will be even more realistic.\n",
    "\n",
    "<img src=\"https://learn.microsoft.com/en-us/azure/ai-services/speech-service/text-to-speech-avatar/media/custom-avatar-workflow.png#lightbox\">\n",
    "\n",
    "> https://learn.microsoft.com/en-us/azure/ai-services/speech-service/text-to-speech-avatar/what-is-custom-text-to-speech-avatar \n",
    "> https://techcommunity.microsoft.com/t5/ai-azure-ai-services-blog/azure-ai-speech-announces-public-preview-of-text-to-speech/ba-p/3981448"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0441c52b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "import json\n",
    "import requests\n",
    "import sys\n",
    "import time\n",
    "\n",
    "from ipywidgets import Video\n",
    "from IPython.display import display\n",
    "from moviepy.editor import VideoFileClip\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "52c29b80",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'3.10.10 (main, Mar 21 2023, 18:45:11) [GCC 11.2.0]'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sys.version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "df759539",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Today is 16-Nov-2023 19:32:38\n"
     ]
    }
   ],
   "source": [
    "dt = datetime.datetime.today().strftime('%d-%b-%Y %H:%M:%S')\n",
    "print(f\"Today is {dt}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "65f1edbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.basicConfig(\n",
    "    stream=sys.stdout,\n",
    "    level=logging.INFO,\n",
    "    format=\"[%(asctime)s] %(message)s\",\n",
    "    datefmt=\"%m/%d/%Y %I:%M:%S %p %Z\",\n",
    ")\n",
    "logger = logging.getLogger(__name__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3a4adb2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Azure Speech services informations\n",
    "azure_speech_key = \"tobecompleted\"\n",
    "azure_speech_region = \"tobecompleted\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9eef643e",
   "metadata": {},
   "outputs": [],
   "source": [
    "service_host = \"customvoice.api.speech.microsoft.com\"  # Do not change"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b40bc904",
   "metadata": {},
   "source": [
    "## Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8be425bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def submit_synthesis(prompt):\n",
    "    url = f\"https://{azure_speech_region}.{service_host}/api/texttospeech/3.1-preview1/batchsynthesis/talkingavatar\"\n",
    "\n",
    "    header = {\n",
    "        \"Ocp-Apim-Subscription-Key\": azure_speech_key,\n",
    "        \"Content-Type\": \"application/json\",\n",
    "    }\n",
    "\n",
    "    payload = {\n",
    "        \"displayName\": \"Simple avatar synthesis\",\n",
    "        \"description\": \"Simple avatar synthesis description\",\n",
    "        \"textType\": \"PlainText\",\n",
    "        \"synthesisConfig\": {\n",
    "            \"voice\": \"en-US-JennyNeural\",\n",
    "        },\n",
    "        \"customVoices\": {\n",
    "            # \"YOUR_CUSTOM_VOICE_NAME\": \"YOUR_CUSTOM_VOICE_ID\"\n",
    "        },\n",
    "        \"inputs\": [\n",
    "            {\n",
    "                \"text\": prompt,\n",
    "            },\n",
    "        ],\n",
    "        \"properties\": {\n",
    "            \"customized\": False,  # set to True if you want to use customized avatar\n",
    "            \"talkingAvatarCharacter\": \"lisa\",  # talking avatar character\n",
    "            \"talkingAvatarStyle\": \"graceful-sitting\",  # talking avatar style, required for prebuilt avatar, optional for custom avatar\n",
    "            \"videoFormat\": \"webm\",  # mp4 or webm, webm is required for transparent background\n",
    "            \"videoCodec\": \"vp9\",  # hevc, h264 or vp9, vp9 is required for transparent background; default is hevc\n",
    "            \"subtitleType\": \"soft_embedded\",\n",
    "            \"backgroundColor\": \"transparent\",\n",
    "        },\n",
    "    }\n",
    "\n",
    "    response = requests.post(url, json.dumps(payload), headers=header)\n",
    "\n",
    "    if response.status_code < 400:\n",
    "        logger.info(\"Batch avatar synthesis job submitted successfully\")\n",
    "        logger.info(f'Job ID: {response.json()[\"id\"]}')\n",
    "        return response.json()[\"id\"]\n",
    "\n",
    "    else:\n",
    "        logger.error(f\"Failed to submit batch avatar synthesis job: {response.text}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9882191a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_synthesis(job_id):\n",
    "    global avatar_url\n",
    "    url = f\"https://{azure_speech_region}.{service_host}/api/texttospeech/3.1-preview1/batchsynthesis/talkingavatar/{job_id}\"\n",
    "\n",
    "    header = {\"Ocp-Apim-Subscription-Key\": azure_speech_key}\n",
    "\n",
    "    response = requests.get(url, headers=header)\n",
    "\n",
    "    if response.status_code < 400:\n",
    "        logger.debug(\"Get batch synthesis job successfully\")\n",
    "        logger.debug(response.json())\n",
    "\n",
    "        status = response.json()[\"status\"]\n",
    "\n",
    "        if status == \"Succeeded\":\n",
    "            avatar_url = response.json()[\"outputs\"][\"result\"]\n",
    "            logger.info(f\"Batch synthesis job succeeded, download URL: {avatar_url}\")\n",
    "\n",
    "        return status\n",
    "    else:\n",
    "        logger.error(f\"Failed to get batch synthesis job: {response.text}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "49770f32",
   "metadata": {},
   "outputs": [],
   "source": [
    "def list_synthesis_jobs(skip: int = 0, top: int = 100):\n",
    "    \"\"\"List all batch synthesis jobs in the subscription\"\"\"\n",
    "\n",
    "    url = f\"https://{azure_speech_region}.{service_host}/api/texttospeech/3.1-preview1/batchsynthesis/talkingavatar?skip={skip}&top={top}\"\n",
    "\n",
    "    header = {\"Ocp-Apim-Subscription-Key\": azure_speech_key}\n",
    "\n",
    "    response = requests.get(url, headers=header)\n",
    "\n",
    "    if response.status_code < 400:\n",
    "        logger.info(\n",
    "            f'List batch synthesis jobs successfully, got {len(response.json()[\"values\"])} jobs'\n",
    "        )\n",
    "        logger.info(response.json())\n",
    "    else:\n",
    "        logger.error(f\"Failed to list batch synthesis jobs: {response.text}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb178ad7",
   "metadata": {},
   "source": [
    "## Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9b65c5ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = f\"\"\"\n",
    "I am Lisa, your avatar powered by Azure Speech Services.\n",
    "Today is {dt}.\n",
    "\n",
    "Let me explain you what is Azure Open AI service.\n",
    "\n",
    "Azure OpenAI Service provides REST API access to OpenAI's powerful language models including the GPT-4, GPT-3.5-Turbo, and Embeddings model series. In addition, the new GPT-4 and GPT-3.5-Turbo model series have now reached general availability. These models can be easily adapted to your specific task including but not limited to content generation, summarization, semantic search, and natural language to code translation. Users can access the service through REST APIs, Python SDK, or our web-based interface in the Azure OpenAI Studio.\n",
    "\n",
    "At Microsoft, we're committed to the advancement of AI driven by principles that put people first. Generative models such as the ones available in Azure OpenAI have significant potential benefits, but without careful design and thoughtful mitigations, such models have the potential to generate incorrect or even harmful content. Microsoft has made significant investments to help guard against abuse and unintended harm, which includes requiring applicants to show well-defined use cases, incorporating Microsoft’s principles for responsible AI use, building content filters to support customers, and providing responsible AI implementation guidance to onboarded customers.\n",
    "\n",
    "To learn more go to https://azure.microsoft.com/en-us/products/ai-services/ai-speech\n",
    "\n",
    "Thank you and have a good day.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c824a0d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "I am Lisa, your avatar powered by Azure Speech Services.\n",
      "Today is 16-Nov-2023 19:32:38.\n",
      "\n",
      "Let me explain you what is Azure Open AI service.\n",
      "\n",
      "Azure OpenAI Service provides REST API access to OpenAI's powerful language models including the GPT-4, GPT-3.5-Turbo, and Embeddings model series. In addition, the new GPT-4 and GPT-3.5-Turbo model series have now reached general availability. These models can be easily adapted to your specific task including but not limited to content generation, summarization, semantic search, and natural language to code translation. Users can access the service through REST APIs, Python SDK, or our web-based interface in the Azure OpenAI Studio.\n",
      "\n",
      "At Microsoft, we're committed to the advancement of AI driven by principles that put people first. Generative models such as the ones available in Azure OpenAI have significant potential benefits, but without careful design and thoughtful mitigations, such models have the potential to generate incorrect or even harmful content. Microsoft has made significant investments to help guard against abuse and unintended harm, which includes requiring applicants to show well-defined use cases, incorporating Microsoft’s principles for responsible AI use, building content filters to support customers, and providing responsible AI implementation guidance to onboarded customers.\n",
      "\n",
      "To learn more go to https://azure.microsoft.com/en-us/products/ai-services/ai-speech\n",
      "\n",
      "Thank you and have a good day.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(prompt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b315fc2",
   "metadata": {},
   "source": [
    "## Avatar batch generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d69fbed5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11/16/2023 07:33:33 PM UTC] Batch avatar synthesis job submitted successfully\n",
      "[11/16/2023 07:33:33 PM UTC] Job ID: 85a1d905-48bc-4ade-bda3-0e69357032de\n",
      "[11/16/2023 07:33:33 PM UTC] Please wait. Status: [NotStarted]\n",
      "[11/16/2023 07:34:03 PM UTC] Please wait. Status: [Running]\n",
      "[11/16/2023 07:34:33 PM UTC] Please wait. Status: [Running]\n",
      "[11/16/2023 07:35:03 PM UTC] Please wait. Status: [Running]\n",
      "[11/16/2023 07:35:33 PM UTC] Please wait. Status: [Running]\n",
      "[11/16/2023 07:36:04 PM UTC] Please wait. Status: [Running]\n",
      "[11/16/2023 07:36:34 PM UTC] Please wait. Status: [Running]\n",
      "[11/16/2023 07:37:04 PM UTC] Please wait. Status: [Running]\n",
      "[11/16/2023 07:37:34 PM UTC] Please wait. Status: [Running]\n",
      "[11/16/2023 07:38:04 PM UTC] Please wait. Status: [Running]\n",
      "[11/16/2023 07:38:34 PM UTC] Please wait. Status: [Running]\n",
      "[11/16/2023 07:39:04 PM UTC] Please wait. Status: [Running]\n",
      "[11/16/2023 07:39:34 PM UTC] Please wait. Status: [Running]\n",
      "[11/16/2023 07:40:04 PM UTC] Please wait. Status: [Running]\n",
      "[11/16/2023 07:40:34 PM UTC] Please wait. Status: [Running]\n",
      "[11/16/2023 07:41:04 PM UTC] Please wait. Status: [Running]\n",
      "[11/16/2023 07:41:34 PM UTC] Please wait. Status: [Running]\n",
      "[11/16/2023 07:42:05 PM UTC] Please wait. Status: [Running]\n",
      "[11/16/2023 07:42:35 PM UTC] Please wait. Status: [Running]\n",
      "[11/16/2023 07:43:05 PM UTC] Please wait. Status: [Running]\n",
      "[11/16/2023 07:43:35 PM UTC] Please wait. Status: [Running]\n",
      "[11/16/2023 07:44:05 PM UTC] Please wait. Status: [Running]\n",
      "[11/16/2023 07:44:35 PM UTC] Please wait. Status: [Running]\n",
      "[11/16/2023 07:45:05 PM UTC] Batch synthesis job succeeded, download URL: https://cvoiceprodweu.blob.core.windows.net/batch-synthesis-output/85a1d905-48bc-4ade-bda3-0e69357032de/0001.webm?skoid=85130dbe-2390-4897-a9e9-5c88bb59daff&sktid=33e01921-4d64-4f8c-a055-5bdaffd5e33d&skt=2023-11-16T19%3A40%3A05Z&ske=2023-11-22T19%3A45%3A05Z&sks=b&skv=2023-08-03&sv=2023-08-03&st=2023-11-16T19%3A40%3A05Z&se=2023-11-17T19%3A45%3A05Z&sr=b&sp=rl&sig=tDnL4Rb9qLUC%2BAGjb1ZGOLHgsSuVC9PfoN9UTa9ksvc%3D\n",
      "[11/16/2023 07:45:05 PM UTC] Done! Azure batch avatar synthesis job succeeded.\n",
      "Elapsed time: 00:11:32.132668\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "\n",
    "job_id = submit_synthesis(prompt)\n",
    "\n",
    "if job_id is not None:\n",
    "    while True:\n",
    "        status = get_synthesis(job_id)\n",
    "        if status == \"Succeeded\":\n",
    "            logger.info(\"Done! Azure batch avatar synthesis job succeeded.\")\n",
    "            elapsed = time.time() - start\n",
    "            print(\"Elapsed time: \" + time.strftime(\"%H:%M:%S.{}\".format(str(elapsed % 1)[2:])[:15],\n",
    "                                                   time.gmtime(elapsed)))\n",
    "\n",
    "            break\n",
    "        elif status == \"Failed\":\n",
    "            logger.error(\"Failed\")\n",
    "            break\n",
    "        else:\n",
    "            logger.info(f\"Please wait. Status: [{status}]\")\n",
    "            time.sleep(30)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "648b22e3",
   "metadata": {},
   "source": [
    "## Avatar video file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "973f2119",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;34mThis is the prompt to speak:\n",
      " \n",
      "I am Lisa, your avatar powered by Azure Speech Services.\n",
      "Today is 16-Nov-2023 19:32:38.\n",
      "\n",
      "Let me explain you what is Azure Open AI service.\n",
      "\n",
      "Azure OpenAI Service provides REST API access to OpenAI's powerful language models including the GPT-4, GPT-3.5-Turbo, and Embeddings model series. In addition, the new GPT-4 and GPT-3.5-Turbo model series have now reached general availability. These models can be easily adapted to your specific task including but not limited to content generation, summarization, semantic search, and natural language to code translation. Users can access the service through REST APIs, Python SDK, or our web-based interface in the Azure OpenAI Studio.\n",
      "\n",
      "At Microsoft, we're committed to the advancement of AI driven by principles that put people first. Generative models such as the ones available in Azure OpenAI have significant potential benefits, but without careful design and thoughtful mitigations, such models have the potential to generate incorrect or even harmful content. Microsoft has made significant investments to help guard against abuse and unintended harm, which includes requiring applicants to show well-defined use cases, incorporating Microsoft’s principles for responsible AI use, building content filters to support customers, and providing responsible AI implementation guidance to onboarded customers.\n",
      "\n",
      "To learn more go to https://azure.microsoft.com/en-us/products/ai-services/ai-speech\n",
      "\n",
      "Thank you and have a good day.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(f\"\\033[1;31;34mThis is the prompt to speak:\\n {prompt}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "28b67132",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11/16/2023 07:46:47 PM UTC] /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages/moviepy/video/io/ffmpeg_reader.py:123: UserWarning: Warning: in file https://cvoiceprodweu.blob.core.windows.net/batch-synthesis-output/85a1d905-48bc-4ade-bda3-0e69357032de/0001.webm?skoid=85130dbe-2390-4897-a9e9-5c88bb59daff&sktid=33e01921-4d64-4f8c-a055-5bdaffd5e33d&skt=2023-11-16T19%3A40%3A05Z&ske=2023-11-22T19%3A45%3A05Z&sks=b&skv=2023-08-03&sv=2023-08-03&st=2023-11-16T19%3A40%3A05Z&se=2023-11-17T19%3A45%3A05Z&sr=b&sp=rl&sig=tDnL4Rb9qLUC%2BAGjb1ZGOLHgsSuVC9PfoN9UTa9ksvc%3D, 6220800 bytes wanted but 0 bytes read,at frame 2777/2778, at time 111.08/111.10 sec. Using the last valid frame instead.\n",
      "  warnings.warn(\"Warning: in file %s, \"%(self.filename)+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Save avatar video\n",
    "\n",
    "avatar_file = (\n",
    "    \"azure_avatar_\" + str(datetime.datetime.today().strftime(\"%d%b%Y_%H%M%S\")) + \".mp4\"\n",
    ")\n",
    "VideoFileClip(avatar_url).write_videofile(avatar_file, verbose=False, logger=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "4275e901",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cf2358039b0c47bda437380bfcf66626",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Video(value=b'\\x00\\x00\\x00 ftypisom\\x00\\x00\\x02\\x00isomiso2avc1mp41\\x00\\x00\\x00\\x08free...')"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Playing the avatar video\n",
    "\n",
    "Video.from_file(avatar_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cad125c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10 - SDK v2",
   "language": "python",
   "name": "python310-sdkv2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
