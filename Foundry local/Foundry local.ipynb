{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ee623337",
   "metadata": {},
   "source": [
    "# Foundry local\n",
    "\n",
    "<img src=\"https://learn.microsoft.com/en-us/azure/ai-foundry/foundry-local/media/architecture/foundry-local-arch.png\">\n",
    "\n",
    "Foundry Local is an on-device AI inference solution offering performance, privacy, customization, and cost advantages. It integrates seamlessly into your existing workflows and applications through an intuitive CLI, SDK, and REST API.\n",
    "\n",
    "## Key features\n",
    "- On-Device Inference: Run models locally on your own hardware, reducing your costs while keeping all your data on your device.\n",
    "- Model Customization: Select from preset models or use your own to meet specific requirements and use cases.\n",
    "- Cost Efficiency: Eliminate recurring cloud service costs by using your existing hardware, making AI more accessible.\n",
    "- Seamless Integration: Connect with your applications through an SDK, API endpoints, or the CLI, with easy scaling to Azure AI Foundry as your needs grow.\n",
    "\n",
    "## Use cases\n",
    "Foundry Local is ideal for scenarios where:\n",
    "- You want to keep sensitive data on your device.\n",
    "- You need to operate in environments with limited or no internet connectivity.\n",
    "- You want to reduce cloud inference costs.\n",
    "- You need low-latency AI responses for real-time applications.\n",
    "- You want to experiment with AI models before deploying to a cloud environment.\n",
    "\n",
    "## Documentation\n",
    "> https://learn.microsoft.com/en-us/azure/ai-foundry/foundry-local/what-is-foundry-local\n",
    "> https://github.com/microsoft/Foundry-Local/releases\n",
    "> https://github.com/microsoft/Foundry-Local/tree/main/docs\n",
    "\n",
    "## Note\n",
    "\n",
    "Foundry Local is available in preview. Public preview releases provide early access to features that are in active deployment.\n",
    "Features, approaches, and processes can change or have limited capabilities, before General Availability (GA)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7be3e75f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#%pip install foundry-local-sdk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "80582ebb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import openai\n",
    "import os\n",
    "import pandas as pd\n",
    "import requests\n",
    "\n",
    "from foundry_local import FoundryLocalManager"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b627423",
   "metadata": {},
   "source": [
    "## List of models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c47367e8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<foundry_local.api.FoundryLocalManager at 0x28a4f6e3bb0>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "manager = FoundryLocalManager()\n",
    "manager"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e10015c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "manager.is_service_running()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e7e84f06",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'http://localhost:5273'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "manager.service_uri"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6e71bb1e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'http://localhost:5273/v1'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "manager.endpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6a16e037",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Available models in the catalog: [FoundryModelInfo(alias=phi-4, id=Phi-4-cuda-gpu, runtime=cuda, file_size=8570 MB, license=MIT), FoundryModelInfo(alias=phi-4, id=Phi-4-generic-gpu, runtime=webgpu, file_size=8570 MB, license=MIT), FoundryModelInfo(alias=phi-4, id=Phi-4-generic-cpu, runtime=cpu, file_size=10403 MB, license=MIT), FoundryModelInfo(alias=phi-3-mini-128k, id=Phi-3-mini-128k-instruct-cuda-gpu, runtime=cuda, file_size=2181 MB, license=MIT), FoundryModelInfo(alias=phi-3-mini-128k, id=Phi-3-mini-128k-instruct-generic-gpu, runtime=webgpu, file_size=2181 MB, license=MIT), FoundryModelInfo(alias=phi-3-mini-128k, id=Phi-3-mini-128k-instruct-generic-cpu, runtime=cpu, file_size=2600 MB, license=MIT), FoundryModelInfo(alias=phi-3-mini-4k, id=Phi-3-mini-4k-instruct-cuda-gpu, runtime=cuda, file_size=2181 MB, license=MIT), FoundryModelInfo(alias=phi-3-mini-4k, id=Phi-3-mini-4k-instruct-generic-gpu, runtime=webgpu, file_size=2181 MB, license=MIT), FoundryModelInfo(alias=phi-3-mini-4k, id=Phi-3-mini-4k-instruct-generic-cpu, runtime=cpu, file_size=2590 MB, license=MIT), FoundryModelInfo(alias=mistral-7b-v0.2, id=mistralai-Mistral-7B-Instruct-v0-2-cuda-gpu, runtime=cuda, file_size=4075 MB, license=apache-2.0), FoundryModelInfo(alias=mistral-7b-v0.2, id=mistralai-Mistral-7B-Instruct-v0-2-generic-gpu, runtime=webgpu, file_size=4167 MB, license=apache-2.0), FoundryModelInfo(alias=mistral-7b-v0.2, id=mistralai-Mistral-7B-Instruct-v0-2-generic-cpu, runtime=cpu, file_size=4167 MB, license=apache-2.0), FoundryModelInfo(alias=phi-3.5-mini, id=Phi-3.5-mini-instruct-cuda-gpu, runtime=cuda, file_size=2181 MB, license=MIT), FoundryModelInfo(alias=phi-3.5-mini, id=Phi-3.5-mini-instruct-generic-gpu, runtime=webgpu, file_size=2211 MB, license=MIT), FoundryModelInfo(alias=phi-3.5-mini, id=Phi-3.5-mini-instruct-generic-cpu, runtime=cpu, file_size=2590 MB, license=MIT), FoundryModelInfo(alias=deepseek-r1-14b, id=deepseek-r1-distill-qwen-14b-cuda-gpu, runtime=cuda, file_size=10065 MB, license=MIT), FoundryModelInfo(alias=deepseek-r1-14b, id=deepseek-r1-distill-qwen-14b-generic-gpu, runtime=webgpu, file_size=10516 MB, license=MIT), FoundryModelInfo(alias=deepseek-r1-14b, id=deepseek-r1-distill-qwen-14b-generic-cpu, runtime=cpu, file_size=11786 MB, license=MIT), FoundryModelInfo(alias=deepseek-r1-7b, id=deepseek-r1-distill-qwen-7b-cuda-gpu, runtime=cuda, file_size=5406 MB, license=MIT), FoundryModelInfo(alias=deepseek-r1-7b, id=deepseek-r1-distill-qwen-7b-generic-gpu, runtime=webgpu, file_size=5713 MB, license=MIT), FoundryModelInfo(alias=deepseek-r1-7b, id=deepseek-r1-distill-qwen-7b-generic-cpu, runtime=cpu, file_size=6584 MB, license=MIT), FoundryModelInfo(alias=qwen2.5-0.5b, id=qwen2.5-0.5b-instruct-cuda-gpu, runtime=cuda, file_size=528 MB, license=apache-2.0), FoundryModelInfo(alias=qwen2.5-0.5b, id=qwen2.5-0.5b-instruct-generic-gpu, runtime=webgpu, file_size=700 MB, license=apache-2.0), FoundryModelInfo(alias=qwen2.5-0.5b, id=qwen2.5-0.5b-instruct-generic-cpu, runtime=cpu, file_size=822 MB, license=apache-2.0), FoundryModelInfo(alias=qwen2.5-1.5b, id=qwen2.5-1.5b-instruct-cuda-gpu, runtime=cuda, file_size=1280 MB, license=apache-2.0), FoundryModelInfo(alias=qwen2.5-1.5b, id=qwen2.5-1.5b-instruct-generic-gpu, runtime=webgpu, file_size=1546 MB, license=apache-2.0), FoundryModelInfo(alias=qwen2.5-1.5b, id=qwen2.5-1.5b-instruct-generic-cpu, runtime=cpu, file_size=1822 MB, license=apache-2.0), FoundryModelInfo(alias=qwen2.5-coder-7b, id=qwen2.5-coder-7b-instruct-cuda-gpu, runtime=cuda, file_size=4843 MB, license=apache-2.0), FoundryModelInfo(alias=qwen2.5-coder-7b, id=qwen2.5-coder-7b-instruct-generic-gpu, runtime=webgpu, file_size=4843 MB, license=apache-2.0), FoundryModelInfo(alias=qwen2.5-coder-7b, id=qwen2.5-coder-7b-instruct-generic-cpu, runtime=cpu, file_size=6307 MB, license=apache-2.0), FoundryModelInfo(alias=qwen2.5-coder-0.5b, id=qwen2.5-coder-0.5b-instruct-cuda-gpu, runtime=cuda, file_size=528 MB, license=apache-2.0), FoundryModelInfo(alias=qwen2.5-coder-0.5b, id=qwen2.5-coder-0.5b-instruct-generic-gpu, runtime=webgpu, file_size=528 MB, license=apache-2.0), FoundryModelInfo(alias=qwen2.5-coder-0.5b, id=qwen2.5-coder-0.5b-instruct-generic-cpu, runtime=cpu, file_size=822 MB, license=apache-2.0), FoundryModelInfo(alias=qwen2.5-coder-1.5b, id=qwen2.5-coder-1.5b-instruct-cuda-gpu, runtime=cuda, file_size=1280 MB, license=apache-2.0), FoundryModelInfo(alias=qwen2.5-coder-1.5b, id=qwen2.5-coder-1.5b-instruct-generic-gpu, runtime=webgpu, file_size=1280 MB, license=apache-2.0), FoundryModelInfo(alias=qwen2.5-coder-1.5b, id=qwen2.5-coder-1.5b-instruct-generic-cpu, runtime=cpu, file_size=1822 MB, license=apache-2.0), FoundryModelInfo(alias=phi-4-mini, id=Phi-4-mini-instruct-cuda-gpu, runtime=cuda, file_size=3686 MB, license=MIT), FoundryModelInfo(alias=phi-4-mini, id=Phi-4-mini-instruct-generic-gpu, runtime=webgpu, file_size=3809 MB, license=MIT), FoundryModelInfo(alias=phi-4-mini, id=Phi-4-mini-instruct-generic-cpu, runtime=cpu, file_size=4915 MB, license=MIT), FoundryModelInfo(alias=phi-4-mini-reasoning, id=Phi-4-mini-reasoning-cuda-gpu, runtime=cuda, file_size=3225 MB, license=MIT), FoundryModelInfo(alias=phi-4-mini-reasoning, id=Phi-4-mini-reasoning-generic-gpu, runtime=webgpu, file_size=3225 MB, license=MIT), FoundryModelInfo(alias=phi-4-mini-reasoning, id=Phi-4-mini-reasoning-generic-cpu, runtime=cpu, file_size=4628 MB, license=MIT), FoundryModelInfo(alias=qwen2.5-14b, id=qwen2.5-14b-instruct-cuda-gpu, runtime=cuda, file_size=9000 MB, license=apache-2.0), FoundryModelInfo(alias=qwen2.5-14b, id=qwen2.5-14b-instruct-generic-cpu, runtime=cpu, file_size=11325 MB, license=apache-2.0), FoundryModelInfo(alias=qwen2.5-7b, id=qwen2.5-7b-instruct-cuda-gpu, runtime=cuda, file_size=4843 MB, license=apache-2.0), FoundryModelInfo(alias=qwen2.5-7b, id=qwen2.5-7b-instruct-generic-gpu, runtime=webgpu, file_size=5324 MB, license=apache-2.0), FoundryModelInfo(alias=qwen2.5-7b, id=qwen2.5-7b-instruct-generic-cpu, runtime=cpu, file_size=6307 MB, license=apache-2.0), FoundryModelInfo(alias=qwen2.5-coder-14b, id=qwen2.5-coder-14b-instruct-cuda-gpu, runtime=cuda, file_size=9000 MB, license=apache-2.0), FoundryModelInfo(alias=qwen2.5-coder-14b, id=qwen2.5-coder-14b-instruct-generic-gpu, runtime=webgpu, file_size=9000 MB, license=apache-2.0), FoundryModelInfo(alias=qwen2.5-coder-14b, id=qwen2.5-coder-14b-instruct-generic-cpu, runtime=cpu, file_size=11325 MB, license=apache-2.0)]\n"
     ]
    }
   ],
   "source": [
    "# List available models in the catalog\n",
    "catalog = manager.list_catalog_models()\n",
    "print(f\"Available models in the catalog: {catalog}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1bfe862d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1: alias='phi-4' id='Phi-4-cuda-gpu' version='1' runtime=<ExecutionProvider.CUDA: 'CUDAExecutionProvider'> uri='azureml://registries/azureml/models/Phi-4-cuda-gpu/versions/1' file_size_mb=8570 prompt_template={'system': '<|system|>\\n{Content}<|im_end|>', 'user': '<|user|>\\n{Content}<|im_end|>', 'assistant': '<|assistant|>\\n{Content}<|im_end|>', 'prompt': '<|user|>\\n{Content}<|im_end|>\\n<|assistant|>'} provider='AzureFoundry' publisher='Microsoft' license='MIT' task='chat-completion'\n",
      "\n",
      "2: alias='phi-4' id='Phi-4-generic-gpu' version='1' runtime=<ExecutionProvider.WEBGPU: 'WebGpuExecutionProvider'> uri='azureml://registries/azureml/models/Phi-4-generic-gpu/versions/1' file_size_mb=8570 prompt_template={'system': '<|system|>\\n{Content}<|im_end|>', 'user': '<|user|>\\n{Content}<|im_end|>', 'assistant': '<|assistant|>\\n{Content}<|im_end|>', 'prompt': '<|user|>\\n{Content}<|im_end|>\\n<|assistant|>'} provider='AzureFoundry' publisher='Microsoft' license='MIT' task='chat-completion'\n",
      "\n",
      "3: alias='phi-4' id='Phi-4-generic-cpu' version='1' runtime=<ExecutionProvider.CPU: 'CPUExecutionProvider'> uri='azureml://registries/azureml/models/Phi-4-generic-cpu/versions/1' file_size_mb=10403 prompt_template={'system': '<|system|>\\n{Content}<|im_end|>', 'user': '<|user|>\\n{Content}<|im_end|>', 'assistant': '<|assistant|>\\n{Content}<|im_end|>', 'prompt': '<|user|>\\n{Content}<|im_end|>\\n<|assistant|>'} provider='AzureFoundry' publisher='Microsoft' license='MIT' task='chat-completion'\n",
      "\n",
      "4: alias='phi-3-mini-128k' id='Phi-3-mini-128k-instruct-cuda-gpu' version='1' runtime=<ExecutionProvider.CUDA: 'CUDAExecutionProvider'> uri='azureml://registries/azureml/models/Phi-3-mini-128k-instruct-cuda-gpu/versions/1' file_size_mb=2181 prompt_template={'prompt': '<|user|>\\n{Content}<|end|>\\n<|assistant|>', 'assistant': '<|assistant|>\\n{Content}<|end|>'} provider='AzureFoundry' publisher='Microsoft' license='MIT' task='chat-completion'\n",
      "\n",
      "5: alias='phi-3-mini-128k' id='Phi-3-mini-128k-instruct-generic-gpu' version='1' runtime=<ExecutionProvider.WEBGPU: 'WebGpuExecutionProvider'> uri='azureml://registries/azureml/models/Phi-3-mini-128k-instruct-generic-gpu/versions/1' file_size_mb=2181 prompt_template={'system': '<|system|>\\n{Content}<|end|>', 'user': '<|user|>\\n{Content}<|end|>', 'assistant': '<|assistant|>\\n{Content}<|end|>', 'prompt': '<|user|>\\n{Content}<|end|>\\n<|assistant|>'} provider='AzureFoundry' publisher='Microsoft' license='MIT' task='chat-completion'\n",
      "\n",
      "6: alias='phi-3-mini-128k' id='Phi-3-mini-128k-instruct-generic-cpu' version='2' runtime=<ExecutionProvider.CPU: 'CPUExecutionProvider'> uri='azureml://registries/azureml/models/Phi-3-mini-128k-instruct-generic-cpu/versions/2' file_size_mb=2600 prompt_template={'system': '<|system|>\\n{Content}<|end|>', 'user': '<|user|>\\n{Content}<|end|>', 'assistant': '<|assistant|>\\n{Content}<|end|>', 'prompt': '<|user|>\\n{Content}<|end|>\\n<|assistant|>'} provider='AzureFoundry' publisher='Microsoft' license='MIT' task='chat-completion'\n",
      "\n",
      "7: alias='phi-3-mini-4k' id='Phi-3-mini-4k-instruct-cuda-gpu' version='1' runtime=<ExecutionProvider.CUDA: 'CUDAExecutionProvider'> uri='azureml://registries/azureml/models/Phi-3-mini-4k-instruct-cuda-gpu/versions/1' file_size_mb=2181 prompt_template={'prompt': '<|user|>\\n{Content}<|end|>\\n<|assistant|>', 'assistant': '<|assistant|>\\n{Content}<|end|>'} provider='AzureFoundry' publisher='Microsoft' license='MIT' task='chat-completion'\n",
      "\n",
      "8: alias='phi-3-mini-4k' id='Phi-3-mini-4k-instruct-generic-gpu' version='1' runtime=<ExecutionProvider.WEBGPU: 'WebGpuExecutionProvider'> uri='azureml://registries/azureml/models/Phi-3-mini-4k-instruct-generic-gpu/versions/1' file_size_mb=2181 prompt_template={'system': '<|system|>\\n{Content}<|end|>', 'user': '<|user|>\\n{Content}<|end|>', 'assistant': '<|assistant|>\\n{Content}<|end|>', 'prompt': '<|user|>\\n{Content}<|end|>\\n<|assistant|>'} provider='AzureFoundry' publisher='Microsoft' license='MIT' task='chat-completion'\n",
      "\n",
      "9: alias='phi-3-mini-4k' id='Phi-3-mini-4k-instruct-generic-cpu' version='2' runtime=<ExecutionProvider.CPU: 'CPUExecutionProvider'> uri='azureml://registries/azureml/models/Phi-3-mini-4k-instruct-generic-cpu/versions/2' file_size_mb=2590 prompt_template={'system': '<|system|>\\n{Content}<|end|>', 'user': '<|user|>\\n{Content}<|end|>', 'assistant': '<|assistant|>\\n{Content}<|end|>', 'prompt': '<|user|>\\n{Content}<|end|>\\n<|assistant|>'} provider='AzureFoundry' publisher='Microsoft' license='MIT' task='chat-completion'\n",
      "\n",
      "10: alias='mistral-7b-v0.2' id='mistralai-Mistral-7B-Instruct-v0-2-cuda-gpu' version='1' runtime=<ExecutionProvider.CUDA: 'CUDAExecutionProvider'> uri='azureml://registries/azureml/models/mistralai-Mistral-7B-Instruct-v0-2-cuda-gpu/versions/1' file_size_mb=4075 prompt_template={'prompt': '[INST]\\n{Content}\\n[/INST]', 'assistant': '{Content}</s>'} provider='AzureFoundry' publisher='Microsoft' license='apache-2.0' task='chat-completion'\n",
      "\n",
      "11: alias='mistral-7b-v0.2' id='mistralai-Mistral-7B-Instruct-v0-2-generic-gpu' version='1' runtime=<ExecutionProvider.WEBGPU: 'WebGpuExecutionProvider'> uri='azureml://registries/azureml/models/mistralai-Mistral-7B-Instruct-v0-2-generic-gpu/versions/1' file_size_mb=4167 prompt_template={'prompt': '[INST]\\n{Content}\\n[/INST]', 'assistant': '{Content}</s>'} provider='AzureFoundry' publisher='Microsoft' license='apache-2.0' task='chat-completion'\n",
      "\n",
      "12: alias='mistral-7b-v0.2' id='mistralai-Mistral-7B-Instruct-v0-2-generic-cpu' version='2' runtime=<ExecutionProvider.CPU: 'CPUExecutionProvider'> uri='azureml://registries/azureml/models/mistralai-Mistral-7B-Instruct-v0-2-generic-cpu/versions/2' file_size_mb=4167 prompt_template={'system': '<s>', 'user': '[INST]\\n{Content}\\n[/INST]', 'assistant': '{Content}</s>', 'prompt': '[INST]\\n{Content}\\n[/INST]'} provider='AzureFoundry' publisher='Microsoft' license='apache-2.0' task='chat-completion'\n",
      "\n",
      "13: alias='phi-3.5-mini' id='Phi-3.5-mini-instruct-cuda-gpu' version='1' runtime=<ExecutionProvider.CUDA: 'CUDAExecutionProvider'> uri='azureml://registries/azureml/models/Phi-3.5-mini-instruct-cuda-gpu/versions/1' file_size_mb=2181 prompt_template={'prompt': '<|user|>\\n{Content}<|end|>\\n<|assistant|>', 'assistant': '<|assistant|>\\n{Content}<|end|>'} provider='AzureFoundry' publisher='Microsoft' license='MIT' task='chat-completion'\n",
      "\n",
      "14: alias='phi-3.5-mini' id='Phi-3.5-mini-instruct-generic-gpu' version='1' runtime=<ExecutionProvider.WEBGPU: 'WebGpuExecutionProvider'> uri='azureml://registries/azureml/models/Phi-3.5-mini-instruct-generic-gpu/versions/1' file_size_mb=2211 prompt_template={'prompt': '<|user|>\\n{Content}<|end|>\\n<|assistant|>', 'assistant': '<|assistant|>\\n{Content}<|end|>'} provider='AzureFoundry' publisher='Microsoft' license='MIT' task='chat-completion'\n",
      "\n",
      "15: alias='phi-3.5-mini' id='Phi-3.5-mini-instruct-generic-cpu' version='1' runtime=<ExecutionProvider.CPU: 'CPUExecutionProvider'> uri='azureml://registries/azureml/models/Phi-3.5-mini-instruct-generic-cpu/versions/1' file_size_mb=2590 prompt_template={'prompt': '<|user|>\\n{Content}<|end|>\\n<|assistant|>', 'assistant': '<|assistant|>\\n{Content}<|end|>'} provider='AzureFoundry' publisher='Microsoft' license='MIT' task='chat-completion'\n",
      "\n",
      "16: alias='deepseek-r1-14b' id='deepseek-r1-distill-qwen-14b-cuda-gpu' version='3' runtime=<ExecutionProvider.CUDA: 'CUDAExecutionProvider'> uri='azureml://registries/azureml/models/deepseek-r1-distill-qwen-14b-cuda-gpu/versions/3' file_size_mb=10065 prompt_template={'assistant': '{Content}', 'prompt': '\\\\u003C\\\\uFF5CUser\\\\uFF5C\\\\u003E{Content}\\\\u003C\\\\uFF5CAssistant\\\\uFF5C\\\\u003E'} provider='AzureFoundry' publisher='Microsoft' license='MIT' task='chat-completion'\n",
      "\n",
      "17: alias='deepseek-r1-14b' id='deepseek-r1-distill-qwen-14b-generic-gpu' version='3' runtime=<ExecutionProvider.WEBGPU: 'WebGpuExecutionProvider'> uri='azureml://registries/azureml/models/deepseek-r1-distill-qwen-14b-generic-gpu/versions/3' file_size_mb=10516 prompt_template={'assistant': '{Content}', 'prompt': '\\\\u003C\\\\uFF5CUser\\\\uFF5C\\\\u003E{Content}\\\\u003C\\\\uFF5CAssistant\\\\uFF5C\\\\u003E'} provider='AzureFoundry' publisher='Microsoft' license='MIT' task='chat-completion'\n",
      "\n",
      "18: alias='deepseek-r1-14b' id='deepseek-r1-distill-qwen-14b-generic-cpu' version='3' runtime=<ExecutionProvider.CPU: 'CPUExecutionProvider'> uri='azureml://registries/azureml/models/deepseek-r1-distill-qwen-14b-generic-cpu/versions/3' file_size_mb=11786 prompt_template={'assistant': '{Content}', 'prompt': '\\\\u003C\\\\uFF5CUser\\\\uFF5C\\\\u003E{Content}\\\\u003C\\\\uFF5CAssistant\\\\uFF5C\\\\u003E'} provider='AzureFoundry' publisher='Microsoft' license='MIT' task='chat-completion'\n",
      "\n",
      "19: alias='deepseek-r1-7b' id='deepseek-r1-distill-qwen-7b-cuda-gpu' version='3' runtime=<ExecutionProvider.CUDA: 'CUDAExecutionProvider'> uri='azureml://registries/azureml/models/deepseek-r1-distill-qwen-7b-cuda-gpu/versions/3' file_size_mb=5406 prompt_template={'assistant': '{Content}', 'prompt': '\\\\u003C\\\\uFF5CUser\\\\uFF5C\\\\u003E{Content}\\\\u003C\\\\uFF5CAssistant\\\\uFF5C\\\\u003E'} provider='AzureFoundry' publisher='Microsoft' license='MIT' task='chat-completion'\n",
      "\n",
      "20: alias='deepseek-r1-7b' id='deepseek-r1-distill-qwen-7b-generic-gpu' version='3' runtime=<ExecutionProvider.WEBGPU: 'WebGpuExecutionProvider'> uri='azureml://registries/azureml/models/deepseek-r1-distill-qwen-7b-generic-gpu/versions/3' file_size_mb=5713 prompt_template={'assistant': '{Content}', 'prompt': '\\\\u003C\\\\uFF5CUser\\\\uFF5C\\\\u003E{Content}\\\\u003C\\\\uFF5CAssistant\\\\uFF5C\\\\u003E'} provider='AzureFoundry' publisher='Microsoft' license='MIT' task='chat-completion'\n",
      "\n",
      "21: alias='deepseek-r1-7b' id='deepseek-r1-distill-qwen-7b-generic-cpu' version='3' runtime=<ExecutionProvider.CPU: 'CPUExecutionProvider'> uri='azureml://registries/azureml/models/deepseek-r1-distill-qwen-7b-generic-cpu/versions/3' file_size_mb=6584 prompt_template={'assistant': '{Content}', 'prompt': '\\\\u003C\\\\uFF5CUser\\\\uFF5C\\\\u003E{Content}\\\\u003C\\\\uFF5CAssistant\\\\uFF5C\\\\u003E'} provider='AzureFoundry' publisher='Microsoft' license='MIT' task='chat-completion'\n",
      "\n",
      "22: alias='qwen2.5-0.5b' id='qwen2.5-0.5b-instruct-cuda-gpu' version='3' runtime=<ExecutionProvider.CUDA: 'CUDAExecutionProvider'> uri='azureml://registries/azureml/models/qwen2.5-0.5b-instruct-cuda-gpu/versions/3' file_size_mb=528 prompt_template={'system': '<|im_start|>system\\n{Content}<|im_end|>', 'user': '<|im_start|>user\\n{Content}<|im_end|>', 'assistant': '<|im_start|>assistant\\n{Content}<|im_end|>', 'prompt': '<|im_start|>user\\n{Content}<|im_end|>\\n<|im_start|>assistant'} provider='AzureFoundry' publisher='Microsoft' license='apache-2.0' task='chat-completion'\n",
      "\n",
      "23: alias='qwen2.5-0.5b' id='qwen2.5-0.5b-instruct-generic-gpu' version='3' runtime=<ExecutionProvider.WEBGPU: 'WebGpuExecutionProvider'> uri='azureml://registries/azureml/models/qwen2.5-0.5b-instruct-generic-gpu/versions/3' file_size_mb=700 prompt_template={'system': '<|im_start|>system\\n{Content}<|im_end|>', 'user': '<|im_start|>user\\n{Content}<|im_end|>', 'assistant': '<|im_start|>assistant\\n{Content}<|im_end|>', 'prompt': '<|im_start|>user\\n{Content}<|im_end|>\\n<|im_start|>assistant'} provider='AzureFoundry' publisher='Microsoft' license='apache-2.0' task='chat-completion'\n",
      "\n",
      "24: alias='qwen2.5-0.5b' id='qwen2.5-0.5b-instruct-generic-cpu' version='3' runtime=<ExecutionProvider.CPU: 'CPUExecutionProvider'> uri='azureml://registries/azureml/models/qwen2.5-0.5b-instruct-generic-cpu/versions/3' file_size_mb=822 prompt_template={'system': '<|im_start|>system\\n{Content}<|im_end|>', 'user': '<|im_start|>user\\n{Content}<|im_end|>', 'assistant': '<|im_start|>assistant\\n{Content}<|im_end|>', 'prompt': '<|im_start|>user\\n{Content}<|im_end|>\\n<|im_start|>assistant'} provider='AzureFoundry' publisher='Microsoft' license='apache-2.0' task='chat-completion'\n",
      "\n",
      "25: alias='qwen2.5-1.5b' id='qwen2.5-1.5b-instruct-cuda-gpu' version='3' runtime=<ExecutionProvider.CUDA: 'CUDAExecutionProvider'> uri='azureml://registries/azureml/models/qwen2.5-1.5b-instruct-cuda-gpu/versions/3' file_size_mb=1280 prompt_template={'system': '<|im_start|>system\\n{Content}<|im_end|>', 'user': '<|im_start|>user\\n{Content}<|im_end|>', 'assistant': '<|im_start|>assistant\\n{Content}<|im_end|>', 'prompt': '<|im_start|>user\\n{Content}<|im_end|>\\n<|im_start|>assistant'} provider='AzureFoundry' publisher='Microsoft' license='apache-2.0' task='chat-completion'\n",
      "\n",
      "26: alias='qwen2.5-1.5b' id='qwen2.5-1.5b-instruct-generic-gpu' version='3' runtime=<ExecutionProvider.WEBGPU: 'WebGpuExecutionProvider'> uri='azureml://registries/azureml/models/qwen2.5-1.5b-instruct-generic-gpu/versions/3' file_size_mb=1546 prompt_template={'system': '<|im_start|>system\\n{Content}<|im_end|>', 'user': '<|im_start|>user\\n{Content}<|im_end|>', 'assistant': '<|im_start|>assistant\\n{Content}<|im_end|>', 'prompt': '<|im_start|>user\\n{Content}<|im_end|>\\n<|im_start|>assistant'} provider='AzureFoundry' publisher='Microsoft' license='apache-2.0' task='chat-completion'\n",
      "\n",
      "27: alias='qwen2.5-1.5b' id='qwen2.5-1.5b-instruct-generic-cpu' version='3' runtime=<ExecutionProvider.CPU: 'CPUExecutionProvider'> uri='azureml://registries/azureml/models/qwen2.5-1.5b-instruct-generic-cpu/versions/3' file_size_mb=1822 prompt_template={'system': '<|im_start|>system\\n{Content}<|im_end|>', 'user': '<|im_start|>user\\n{Content}<|im_end|>', 'assistant': '<|im_start|>assistant\\n{Content}<|im_end|>', 'prompt': '<|im_start|>user\\n{Content}<|im_end|>\\n<|im_start|>assistant'} provider='AzureFoundry' publisher='Microsoft' license='apache-2.0' task='chat-completion'\n",
      "\n",
      "28: alias='qwen2.5-coder-7b' id='qwen2.5-coder-7b-instruct-cuda-gpu' version='3' runtime=<ExecutionProvider.CUDA: 'CUDAExecutionProvider'> uri='azureml://registries/azureml/models/qwen2.5-coder-7b-instruct-cuda-gpu/versions/3' file_size_mb=4843 prompt_template={'system': '<|im_start|>system\\n{Content}<|im_end|>', 'user': '<|im_start|>user\\n{Content}<|im_end|>', 'assistant': '<|im_start|>assistant\\n{Content}<|im_end|>', 'prompt': '<|im_start|>user\\n{Content}<|im_end|>\\n<|im_start|>assistant'} provider='AzureFoundry' publisher='Microsoft' license='apache-2.0' task='chat-completion'\n",
      "\n",
      "29: alias='qwen2.5-coder-7b' id='qwen2.5-coder-7b-instruct-generic-gpu' version='3' runtime=<ExecutionProvider.WEBGPU: 'WebGpuExecutionProvider'> uri='azureml://registries/azureml/models/qwen2.5-coder-7b-instruct-generic-gpu/versions/3' file_size_mb=4843 prompt_template={'system': '<|im_start|>system\\n{Content}<|im_end|>', 'user': '<|im_start|>user\\n{Content}<|im_end|>', 'assistant': '<|im_start|>assistant\\n{Content}<|im_end|>', 'prompt': '<|im_start|>user\\n{Content}<|im_end|>\\n<|im_start|>assistant'} provider='AzureFoundry' publisher='Microsoft' license='apache-2.0' task='chat-completion'\n",
      "\n",
      "30: alias='qwen2.5-coder-7b' id='qwen2.5-coder-7b-instruct-generic-cpu' version='3' runtime=<ExecutionProvider.CPU: 'CPUExecutionProvider'> uri='azureml://registries/azureml/models/qwen2.5-coder-7b-instruct-generic-cpu/versions/3' file_size_mb=6307 prompt_template={'system': '<|im_start|>system\\n{Content}<|im_end|>', 'user': '<|im_start|>user\\n{Content}<|im_end|>', 'assistant': '<|im_start|>assistant\\n{Content}<|im_end|>', 'prompt': '<|im_start|>user\\n{Content}<|im_end|>\\n<|im_start|>assistant'} provider='AzureFoundry' publisher='Microsoft' license='apache-2.0' task='chat-completion'\n",
      "\n",
      "31: alias='qwen2.5-coder-0.5b' id='qwen2.5-coder-0.5b-instruct-cuda-gpu' version='3' runtime=<ExecutionProvider.CUDA: 'CUDAExecutionProvider'> uri='azureml://registries/azureml/models/qwen2.5-coder-0.5b-instruct-cuda-gpu/versions/3' file_size_mb=528 prompt_template={'system': '<|im_start|>system\\n{Content}<|im_end|>', 'user': '<|im_start|>user\\n{Content}<|im_end|>', 'assistant': '<|im_start|>assistant\\n{Content}<|im_end|>', 'prompt': '<|im_start|>user\\n{Content}<|im_end|>\\n<|im_start|>assistant'} provider='AzureFoundry' publisher='Microsoft' license='apache-2.0' task='chat-completion'\n",
      "\n",
      "32: alias='qwen2.5-coder-0.5b' id='qwen2.5-coder-0.5b-instruct-generic-gpu' version='3' runtime=<ExecutionProvider.WEBGPU: 'WebGpuExecutionProvider'> uri='azureml://registries/azureml/models/qwen2.5-coder-0.5b-instruct-generic-gpu/versions/3' file_size_mb=528 prompt_template={'system': '<|im_start|>system\\n{Content}<|im_end|>', 'user': '<|im_start|>user\\n{Content}<|im_end|>', 'assistant': '<|im_start|>assistant\\n{Content}<|im_end|>', 'prompt': '<|im_start|>user\\n{Content}<|im_end|>\\n<|im_start|>assistant'} provider='AzureFoundry' publisher='Microsoft' license='apache-2.0' task='chat-completion'\n",
      "\n",
      "33: alias='qwen2.5-coder-0.5b' id='qwen2.5-coder-0.5b-instruct-generic-cpu' version='3' runtime=<ExecutionProvider.CPU: 'CPUExecutionProvider'> uri='azureml://registries/azureml/models/qwen2.5-coder-0.5b-instruct-generic-cpu/versions/3' file_size_mb=822 prompt_template={'system': '<|im_start|>system\\n{Content}<|im_end|>', 'user': '<|im_start|>user\\n{Content}<|im_end|>', 'assistant': '<|im_start|>assistant\\n{Content}<|im_end|>', 'prompt': '<|im_start|>user\\n{Content}<|im_end|>\\n<|im_start|>assistant'} provider='AzureFoundry' publisher='Microsoft' license='apache-2.0' task='chat-completion'\n",
      "\n",
      "34: alias='qwen2.5-coder-1.5b' id='qwen2.5-coder-1.5b-instruct-cuda-gpu' version='3' runtime=<ExecutionProvider.CUDA: 'CUDAExecutionProvider'> uri='azureml://registries/azureml/models/qwen2.5-coder-1.5b-instruct-cuda-gpu/versions/3' file_size_mb=1280 prompt_template={'system': '<|im_start|>system\\n{Content}<|im_end|>', 'user': '<|im_start|>user\\n{Content}<|im_end|>', 'assistant': '<|im_start|>assistant\\n{Content}<|im_end|>', 'prompt': '<|im_start|>user\\n{Content}<|im_end|>\\n<|im_start|>assistant'} provider='AzureFoundry' publisher='Microsoft' license='apache-2.0' task='chat-completion'\n",
      "\n",
      "35: alias='qwen2.5-coder-1.5b' id='qwen2.5-coder-1.5b-instruct-generic-gpu' version='3' runtime=<ExecutionProvider.WEBGPU: 'WebGpuExecutionProvider'> uri='azureml://registries/azureml/models/qwen2.5-coder-1.5b-instruct-generic-gpu/versions/3' file_size_mb=1280 prompt_template={'system': '<|im_start|>system\\n{Content}<|im_end|>', 'user': '<|im_start|>user\\n{Content}<|im_end|>', 'assistant': '<|im_start|>assistant\\n{Content}<|im_end|>', 'prompt': '<|im_start|>user\\n{Content}<|im_end|>\\n<|im_start|>assistant'} provider='AzureFoundry' publisher='Microsoft' license='apache-2.0' task='chat-completion'\n",
      "\n",
      "36: alias='qwen2.5-coder-1.5b' id='qwen2.5-coder-1.5b-instruct-generic-cpu' version='3' runtime=<ExecutionProvider.CPU: 'CPUExecutionProvider'> uri='azureml://registries/azureml/models/qwen2.5-coder-1.5b-instruct-generic-cpu/versions/3' file_size_mb=1822 prompt_template={'system': '<|im_start|>system\\n{Content}<|im_end|>', 'user': '<|im_start|>user\\n{Content}<|im_end|>', 'assistant': '<|im_start|>assistant\\n{Content}<|im_end|>', 'prompt': '<|im_start|>user\\n{Content}<|im_end|>\\n<|im_start|>assistant'} provider='AzureFoundry' publisher='Microsoft' license='apache-2.0' task='chat-completion'\n",
      "\n",
      "37: alias='phi-4-mini' id='Phi-4-mini-instruct-cuda-gpu' version='4' runtime=<ExecutionProvider.CUDA: 'CUDAExecutionProvider'> uri='azureml://registries/azureml/models/Phi-4-mini-instruct-cuda-gpu/versions/4' file_size_mb=3686 prompt_template={'system': '<|system|>{Content}<|end|>', 'user': '<|user|>{Content}<|end|>', 'assistant': '<|assistant|>{Content}<|end|>', 'prompt': '<|user|>{Content}<|end|><|assistant|>'} provider='AzureFoundry' publisher='Microsoft' license='MIT' task='chat-completion'\n",
      "\n",
      "38: alias='phi-4-mini' id='Phi-4-mini-instruct-generic-gpu' version='4' runtime=<ExecutionProvider.WEBGPU: 'WebGpuExecutionProvider'> uri='azureml://registries/azureml/models/Phi-4-mini-instruct-generic-gpu/versions/4' file_size_mb=3809 prompt_template={'system': '<|system|>{Content}<|end|>', 'user': '<|user|>{Content}<|end|>', 'assistant': '<|assistant|>{Content}<|end|>', 'prompt': '<|user|>{Content}<|end|><|assistant|>'} provider='AzureFoundry' publisher='Microsoft' license='MIT' task='chat-completion'\n",
      "\n",
      "39: alias='phi-4-mini' id='Phi-4-mini-instruct-generic-cpu' version='4' runtime=<ExecutionProvider.CPU: 'CPUExecutionProvider'> uri='azureml://registries/azureml/models/Phi-4-mini-instruct-generic-cpu/versions/4' file_size_mb=4915 prompt_template={'system': '<|system|>{Content}<|end|>', 'user': '<|user|>{Content}<|end|>', 'assistant': '<|assistant|>{Content}<|end|>', 'prompt': '<|user|>{Content}<|end|><|assistant|>'} provider='AzureFoundry' publisher='Microsoft' license='MIT' task='chat-completion'\n",
      "\n",
      "40: alias='phi-4-mini-reasoning' id='Phi-4-mini-reasoning-cuda-gpu' version='2' runtime=<ExecutionProvider.CUDA: 'CUDAExecutionProvider'> uri='azureml://registries/azureml/models/Phi-4-mini-reasoning-cuda-gpu/versions/2' file_size_mb=3225 prompt_template={'system': '<|system|>Your name is Phi, an AI math expert developed by Microsoft. {Content}<|end|>', 'user': '<|user|>{Content}<|end|>', 'assistant': '<|assistant|>{Content}<|end|>', 'prompt': '<|user|>{Content}<|end|><|assistant|>'} provider='AzureFoundry' publisher='Microsoft' license='MIT' task='chat-completion'\n",
      "\n",
      "41: alias='phi-4-mini-reasoning' id='Phi-4-mini-reasoning-generic-gpu' version='2' runtime=<ExecutionProvider.WEBGPU: 'WebGpuExecutionProvider'> uri='azureml://registries/azureml/models/Phi-4-mini-reasoning-generic-gpu/versions/2' file_size_mb=3225 prompt_template={'system': '<|system|>Your name is Phi, an AI math expert developed by Microsoft. {Content}<|end|>', 'user': '<|user|>{Content}<|end|>', 'assistant': '<|assistant|>{Content}<|end|>', 'prompt': '<|user|>{Content}<|end|><|assistant|>'} provider='AzureFoundry' publisher='Microsoft' license='MIT' task='chat-completion'\n",
      "\n",
      "42: alias='phi-4-mini-reasoning' id='Phi-4-mini-reasoning-generic-cpu' version='2' runtime=<ExecutionProvider.CPU: 'CPUExecutionProvider'> uri='azureml://registries/azureml/models/Phi-4-mini-reasoning-generic-cpu/versions/2' file_size_mb=4628 prompt_template={'system': '<|system|>Your name is Phi, an AI math expert developed by Microsoft. {Content}<|end|>', 'user': '<|user|>{Content}<|end|>', 'assistant': '<|assistant|>{Content}<|end|>', 'prompt': '<|user|>{Content}<|end|><|assistant|>'} provider='AzureFoundry' publisher='Microsoft' license='MIT' task='chat-completion'\n",
      "\n",
      "43: alias='qwen2.5-14b' id='qwen2.5-14b-instruct-cuda-gpu' version='3' runtime=<ExecutionProvider.CUDA: 'CUDAExecutionProvider'> uri='azureml://registries/azureml/models/qwen2.5-14b-instruct-cuda-gpu/versions/3' file_size_mb=9000 prompt_template={'system': '<|im_start|>system\\n{Content}<|im_end|>', 'user': '<|im_start|>user\\n{Content}<|im_end|>', 'assistant': '<|im_start|>assistant\\n{Content}<|im_end|>', 'prompt': '<|im_start|>user\\n{Content}<|im_end|>\\n<|im_start|>assistant'} provider='AzureFoundry' publisher='Microsoft' license='apache-2.0' task='chat-completion'\n",
      "\n",
      "44: alias='qwen2.5-14b' id='qwen2.5-14b-instruct-generic-cpu' version='3' runtime=<ExecutionProvider.CPU: 'CPUExecutionProvider'> uri='azureml://registries/azureml/models/qwen2.5-14b-instruct-generic-cpu/versions/3' file_size_mb=11325 prompt_template={'system': '<|im_start|>system\\n{Content}<|im_end|>', 'user': '<|im_start|>user\\n{Content}<|im_end|>', 'assistant': '<|im_start|>assistant\\n{Content}<|im_end|>', 'prompt': '<|im_start|>user\\n{Content}<|im_end|>\\n<|im_start|>assistant'} provider='AzureFoundry' publisher='Microsoft' license='apache-2.0' task='chat-completion'\n",
      "\n",
      "45: alias='qwen2.5-7b' id='qwen2.5-7b-instruct-cuda-gpu' version='3' runtime=<ExecutionProvider.CUDA: 'CUDAExecutionProvider'> uri='azureml://registries/azureml/models/qwen2.5-7b-instruct-cuda-gpu/versions/3' file_size_mb=4843 prompt_template={'system': '<|im_start|>system\\n{Content}<|im_end|>', 'user': '<|im_start|>user\\n{Content}<|im_end|>', 'assistant': '<|im_start|>assistant\\n{Content}<|im_end|>', 'prompt': '<|im_start|>user\\n{Content}<|im_end|>\\n<|im_start|>assistant'} provider='AzureFoundry' publisher='Microsoft' license='apache-2.0' task='chat-completion'\n",
      "\n",
      "46: alias='qwen2.5-7b' id='qwen2.5-7b-instruct-generic-gpu' version='3' runtime=<ExecutionProvider.WEBGPU: 'WebGpuExecutionProvider'> uri='azureml://registries/azureml/models/qwen2.5-7b-instruct-generic-gpu/versions/3' file_size_mb=5324 prompt_template={'system': '<|im_start|>system\\n{Content}<|im_end|>', 'user': '<|im_start|>user\\n{Content}<|im_end|>', 'assistant': '<|im_start|>assistant\\n{Content}<|im_end|>', 'prompt': '<|im_start|>user\\n{Content}<|im_end|>\\n<|im_start|>assistant'} provider='AzureFoundry' publisher='Microsoft' license='apache-2.0' task='chat-completion'\n",
      "\n",
      "47: alias='qwen2.5-7b' id='qwen2.5-7b-instruct-generic-cpu' version='3' runtime=<ExecutionProvider.CPU: 'CPUExecutionProvider'> uri='azureml://registries/azureml/models/qwen2.5-7b-instruct-generic-cpu/versions/3' file_size_mb=6307 prompt_template={'system': '<|im_start|>system\\n{Content}<|im_end|>', 'user': '<|im_start|>user\\n{Content}<|im_end|>', 'assistant': '<|im_start|>assistant\\n{Content}<|im_end|>', 'prompt': '<|im_start|>user\\n{Content}<|im_end|>\\n<|im_start|>assistant'} provider='AzureFoundry' publisher='Microsoft' license='apache-2.0' task='chat-completion'\n",
      "\n",
      "48: alias='qwen2.5-coder-14b' id='qwen2.5-coder-14b-instruct-cuda-gpu' version='3' runtime=<ExecutionProvider.CUDA: 'CUDAExecutionProvider'> uri='azureml://registries/azureml/models/qwen2.5-coder-14b-instruct-cuda-gpu/versions/3' file_size_mb=9000 prompt_template={'system': '<|im_start|>system\\n{Content}<|im_end|>', 'user': '<|im_start|>user\\n{Content}<|im_end|>', 'assistant': '<|im_start|>assistant\\n{Content}<|im_end|>', 'prompt': '<|im_start|>user\\n{Content}<|im_end|>\\n<|im_start|>assistant'} provider='AzureFoundry' publisher='Microsoft' license='apache-2.0' task='chat-completion'\n",
      "\n",
      "49: alias='qwen2.5-coder-14b' id='qwen2.5-coder-14b-instruct-generic-gpu' version='3' runtime=<ExecutionProvider.WEBGPU: 'WebGpuExecutionProvider'> uri='azureml://registries/azureml/models/qwen2.5-coder-14b-instruct-generic-gpu/versions/3' file_size_mb=9000 prompt_template={'system': '<|im_start|>system\\n{Content}<|im_end|>', 'user': '<|im_start|>user\\n{Content}<|im_end|>', 'assistant': '<|im_start|>assistant\\n{Content}<|im_end|>', 'prompt': '<|im_start|>user\\n{Content}<|im_end|>\\n<|im_start|>assistant'} provider='AzureFoundry' publisher='Microsoft' license='apache-2.0' task='chat-completion'\n",
      "\n",
      "50: alias='qwen2.5-coder-14b' id='qwen2.5-coder-14b-instruct-generic-cpu' version='3' runtime=<ExecutionProvider.CPU: 'CPUExecutionProvider'> uri='azureml://registries/azureml/models/qwen2.5-coder-14b-instruct-generic-cpu/versions/3' file_size_mb=11325 prompt_template={'system': '<|im_start|>system\\n{Content}<|im_end|>', 'user': '<|im_start|>user\\n{Content}<|im_end|>', 'assistant': '<|im_start|>assistant\\n{Content}<|im_end|>', 'prompt': '<|im_start|>user\\n{Content}<|im_end|>\\n<|im_start|>assistant'} provider='AzureFoundry' publisher='Microsoft' license='apache-2.0' task='chat-completion'\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for idx, item in enumerate(catalog, start=1):\n",
    "    print(f\"{idx}: {item}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e5aa7204",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>alias</th>\n",
       "      <th>id</th>\n",
       "      <th>version</th>\n",
       "      <th>runtime</th>\n",
       "      <th>uri</th>\n",
       "      <th>file_size_mb</th>\n",
       "      <th>prompt_template</th>\n",
       "      <th>provider</th>\n",
       "      <th>publisher</th>\n",
       "      <th>license</th>\n",
       "      <th>task</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>phi-4</td>\n",
       "      <td>Phi-4-cuda-gpu</td>\n",
       "      <td>1</td>\n",
       "      <td>CUDAExecutionProvider</td>\n",
       "      <td>azureml://registries/azureml/models/Phi-4-cuda...</td>\n",
       "      <td>8570</td>\n",
       "      <td>{'system': '&lt;|system|&gt;\n",
       "{Content}&lt;|im_end|&gt;', '...</td>\n",
       "      <td>AzureFoundry</td>\n",
       "      <td>Microsoft</td>\n",
       "      <td>MIT</td>\n",
       "      <td>chat-completion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>phi-4</td>\n",
       "      <td>Phi-4-generic-gpu</td>\n",
       "      <td>1</td>\n",
       "      <td>WebGpuExecutionProvider</td>\n",
       "      <td>azureml://registries/azureml/models/Phi-4-gene...</td>\n",
       "      <td>8570</td>\n",
       "      <td>{'system': '&lt;|system|&gt;\n",
       "{Content}&lt;|im_end|&gt;', '...</td>\n",
       "      <td>AzureFoundry</td>\n",
       "      <td>Microsoft</td>\n",
       "      <td>MIT</td>\n",
       "      <td>chat-completion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>phi-4</td>\n",
       "      <td>Phi-4-generic-cpu</td>\n",
       "      <td>1</td>\n",
       "      <td>CPUExecutionProvider</td>\n",
       "      <td>azureml://registries/azureml/models/Phi-4-gene...</td>\n",
       "      <td>10403</td>\n",
       "      <td>{'system': '&lt;|system|&gt;\n",
       "{Content}&lt;|im_end|&gt;', '...</td>\n",
       "      <td>AzureFoundry</td>\n",
       "      <td>Microsoft</td>\n",
       "      <td>MIT</td>\n",
       "      <td>chat-completion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>phi-3-mini-128k</td>\n",
       "      <td>Phi-3-mini-128k-instruct-cuda-gpu</td>\n",
       "      <td>1</td>\n",
       "      <td>CUDAExecutionProvider</td>\n",
       "      <td>azureml://registries/azureml/models/Phi-3-mini...</td>\n",
       "      <td>2181</td>\n",
       "      <td>{'prompt': '&lt;|user|&gt;\n",
       "{Content}&lt;|end|&gt;\n",
       "&lt;|assist...</td>\n",
       "      <td>AzureFoundry</td>\n",
       "      <td>Microsoft</td>\n",
       "      <td>MIT</td>\n",
       "      <td>chat-completion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>phi-3-mini-128k</td>\n",
       "      <td>Phi-3-mini-128k-instruct-generic-gpu</td>\n",
       "      <td>1</td>\n",
       "      <td>WebGpuExecutionProvider</td>\n",
       "      <td>azureml://registries/azureml/models/Phi-3-mini...</td>\n",
       "      <td>2181</td>\n",
       "      <td>{'system': '&lt;|system|&gt;\n",
       "{Content}&lt;|end|&gt;', 'use...</td>\n",
       "      <td>AzureFoundry</td>\n",
       "      <td>Microsoft</td>\n",
       "      <td>MIT</td>\n",
       "      <td>chat-completion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>phi-3-mini-128k</td>\n",
       "      <td>Phi-3-mini-128k-instruct-generic-cpu</td>\n",
       "      <td>2</td>\n",
       "      <td>CPUExecutionProvider</td>\n",
       "      <td>azureml://registries/azureml/models/Phi-3-mini...</td>\n",
       "      <td>2600</td>\n",
       "      <td>{'system': '&lt;|system|&gt;\n",
       "{Content}&lt;|end|&gt;', 'use...</td>\n",
       "      <td>AzureFoundry</td>\n",
       "      <td>Microsoft</td>\n",
       "      <td>MIT</td>\n",
       "      <td>chat-completion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>phi-3-mini-4k</td>\n",
       "      <td>Phi-3-mini-4k-instruct-cuda-gpu</td>\n",
       "      <td>1</td>\n",
       "      <td>CUDAExecutionProvider</td>\n",
       "      <td>azureml://registries/azureml/models/Phi-3-mini...</td>\n",
       "      <td>2181</td>\n",
       "      <td>{'prompt': '&lt;|user|&gt;\n",
       "{Content}&lt;|end|&gt;\n",
       "&lt;|assist...</td>\n",
       "      <td>AzureFoundry</td>\n",
       "      <td>Microsoft</td>\n",
       "      <td>MIT</td>\n",
       "      <td>chat-completion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>phi-3-mini-4k</td>\n",
       "      <td>Phi-3-mini-4k-instruct-generic-gpu</td>\n",
       "      <td>1</td>\n",
       "      <td>WebGpuExecutionProvider</td>\n",
       "      <td>azureml://registries/azureml/models/Phi-3-mini...</td>\n",
       "      <td>2181</td>\n",
       "      <td>{'system': '&lt;|system|&gt;\n",
       "{Content}&lt;|end|&gt;', 'use...</td>\n",
       "      <td>AzureFoundry</td>\n",
       "      <td>Microsoft</td>\n",
       "      <td>MIT</td>\n",
       "      <td>chat-completion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>phi-3-mini-4k</td>\n",
       "      <td>Phi-3-mini-4k-instruct-generic-cpu</td>\n",
       "      <td>2</td>\n",
       "      <td>CPUExecutionProvider</td>\n",
       "      <td>azureml://registries/azureml/models/Phi-3-mini...</td>\n",
       "      <td>2590</td>\n",
       "      <td>{'system': '&lt;|system|&gt;\n",
       "{Content}&lt;|end|&gt;', 'use...</td>\n",
       "      <td>AzureFoundry</td>\n",
       "      <td>Microsoft</td>\n",
       "      <td>MIT</td>\n",
       "      <td>chat-completion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>mistral-7b-v0.2</td>\n",
       "      <td>mistralai-Mistral-7B-Instruct-v0-2-cuda-gpu</td>\n",
       "      <td>1</td>\n",
       "      <td>CUDAExecutionProvider</td>\n",
       "      <td>azureml://registries/azureml/models/mistralai-...</td>\n",
       "      <td>4075</td>\n",
       "      <td>{'prompt': '[INST]\n",
       "{Content}\n",
       "[/INST]', 'assist...</td>\n",
       "      <td>AzureFoundry</td>\n",
       "      <td>Microsoft</td>\n",
       "      <td>apache-2.0</td>\n",
       "      <td>chat-completion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>11</td>\n",
       "      <td>mistral-7b-v0.2</td>\n",
       "      <td>mistralai-Mistral-7B-Instruct-v0-2-generic-gpu</td>\n",
       "      <td>1</td>\n",
       "      <td>WebGpuExecutionProvider</td>\n",
       "      <td>azureml://registries/azureml/models/mistralai-...</td>\n",
       "      <td>4167</td>\n",
       "      <td>{'prompt': '[INST]\n",
       "{Content}\n",
       "[/INST]', 'assist...</td>\n",
       "      <td>AzureFoundry</td>\n",
       "      <td>Microsoft</td>\n",
       "      <td>apache-2.0</td>\n",
       "      <td>chat-completion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>12</td>\n",
       "      <td>mistral-7b-v0.2</td>\n",
       "      <td>mistralai-Mistral-7B-Instruct-v0-2-generic-cpu</td>\n",
       "      <td>2</td>\n",
       "      <td>CPUExecutionProvider</td>\n",
       "      <td>azureml://registries/azureml/models/mistralai-...</td>\n",
       "      <td>4167</td>\n",
       "      <td>{'system': '&lt;s&gt;', 'user': '[INST]\n",
       "{Content}\n",
       "[/...</td>\n",
       "      <td>AzureFoundry</td>\n",
       "      <td>Microsoft</td>\n",
       "      <td>apache-2.0</td>\n",
       "      <td>chat-completion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>13</td>\n",
       "      <td>phi-3.5-mini</td>\n",
       "      <td>Phi-3.5-mini-instruct-cuda-gpu</td>\n",
       "      <td>1</td>\n",
       "      <td>CUDAExecutionProvider</td>\n",
       "      <td>azureml://registries/azureml/models/Phi-3.5-mi...</td>\n",
       "      <td>2181</td>\n",
       "      <td>{'prompt': '&lt;|user|&gt;\n",
       "{Content}&lt;|end|&gt;\n",
       "&lt;|assist...</td>\n",
       "      <td>AzureFoundry</td>\n",
       "      <td>Microsoft</td>\n",
       "      <td>MIT</td>\n",
       "      <td>chat-completion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>14</td>\n",
       "      <td>phi-3.5-mini</td>\n",
       "      <td>Phi-3.5-mini-instruct-generic-gpu</td>\n",
       "      <td>1</td>\n",
       "      <td>WebGpuExecutionProvider</td>\n",
       "      <td>azureml://registries/azureml/models/Phi-3.5-mi...</td>\n",
       "      <td>2211</td>\n",
       "      <td>{'prompt': '&lt;|user|&gt;\n",
       "{Content}&lt;|end|&gt;\n",
       "&lt;|assist...</td>\n",
       "      <td>AzureFoundry</td>\n",
       "      <td>Microsoft</td>\n",
       "      <td>MIT</td>\n",
       "      <td>chat-completion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>15</td>\n",
       "      <td>phi-3.5-mini</td>\n",
       "      <td>Phi-3.5-mini-instruct-generic-cpu</td>\n",
       "      <td>1</td>\n",
       "      <td>CPUExecutionProvider</td>\n",
       "      <td>azureml://registries/azureml/models/Phi-3.5-mi...</td>\n",
       "      <td>2590</td>\n",
       "      <td>{'prompt': '&lt;|user|&gt;\n",
       "{Content}&lt;|end|&gt;\n",
       "&lt;|assist...</td>\n",
       "      <td>AzureFoundry</td>\n",
       "      <td>Microsoft</td>\n",
       "      <td>MIT</td>\n",
       "      <td>chat-completion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>16</td>\n",
       "      <td>deepseek-r1-14b</td>\n",
       "      <td>deepseek-r1-distill-qwen-14b-cuda-gpu</td>\n",
       "      <td>3</td>\n",
       "      <td>CUDAExecutionProvider</td>\n",
       "      <td>azureml://registries/azureml/models/deepseek-r...</td>\n",
       "      <td>10065</td>\n",
       "      <td>{'assistant': '{Content}', 'prompt': '\\u003C\\u...</td>\n",
       "      <td>AzureFoundry</td>\n",
       "      <td>Microsoft</td>\n",
       "      <td>MIT</td>\n",
       "      <td>chat-completion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>17</td>\n",
       "      <td>deepseek-r1-14b</td>\n",
       "      <td>deepseek-r1-distill-qwen-14b-generic-gpu</td>\n",
       "      <td>3</td>\n",
       "      <td>WebGpuExecutionProvider</td>\n",
       "      <td>azureml://registries/azureml/models/deepseek-r...</td>\n",
       "      <td>10516</td>\n",
       "      <td>{'assistant': '{Content}', 'prompt': '\\u003C\\u...</td>\n",
       "      <td>AzureFoundry</td>\n",
       "      <td>Microsoft</td>\n",
       "      <td>MIT</td>\n",
       "      <td>chat-completion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>18</td>\n",
       "      <td>deepseek-r1-14b</td>\n",
       "      <td>deepseek-r1-distill-qwen-14b-generic-cpu</td>\n",
       "      <td>3</td>\n",
       "      <td>CPUExecutionProvider</td>\n",
       "      <td>azureml://registries/azureml/models/deepseek-r...</td>\n",
       "      <td>11786</td>\n",
       "      <td>{'assistant': '{Content}', 'prompt': '\\u003C\\u...</td>\n",
       "      <td>AzureFoundry</td>\n",
       "      <td>Microsoft</td>\n",
       "      <td>MIT</td>\n",
       "      <td>chat-completion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>19</td>\n",
       "      <td>deepseek-r1-7b</td>\n",
       "      <td>deepseek-r1-distill-qwen-7b-cuda-gpu</td>\n",
       "      <td>3</td>\n",
       "      <td>CUDAExecutionProvider</td>\n",
       "      <td>azureml://registries/azureml/models/deepseek-r...</td>\n",
       "      <td>5406</td>\n",
       "      <td>{'assistant': '{Content}', 'prompt': '\\u003C\\u...</td>\n",
       "      <td>AzureFoundry</td>\n",
       "      <td>Microsoft</td>\n",
       "      <td>MIT</td>\n",
       "      <td>chat-completion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>20</td>\n",
       "      <td>deepseek-r1-7b</td>\n",
       "      <td>deepseek-r1-distill-qwen-7b-generic-gpu</td>\n",
       "      <td>3</td>\n",
       "      <td>WebGpuExecutionProvider</td>\n",
       "      <td>azureml://registries/azureml/models/deepseek-r...</td>\n",
       "      <td>5713</td>\n",
       "      <td>{'assistant': '{Content}', 'prompt': '\\u003C\\u...</td>\n",
       "      <td>AzureFoundry</td>\n",
       "      <td>Microsoft</td>\n",
       "      <td>MIT</td>\n",
       "      <td>chat-completion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>21</td>\n",
       "      <td>deepseek-r1-7b</td>\n",
       "      <td>deepseek-r1-distill-qwen-7b-generic-cpu</td>\n",
       "      <td>3</td>\n",
       "      <td>CPUExecutionProvider</td>\n",
       "      <td>azureml://registries/azureml/models/deepseek-r...</td>\n",
       "      <td>6584</td>\n",
       "      <td>{'assistant': '{Content}', 'prompt': '\\u003C\\u...</td>\n",
       "      <td>AzureFoundry</td>\n",
       "      <td>Microsoft</td>\n",
       "      <td>MIT</td>\n",
       "      <td>chat-completion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>22</td>\n",
       "      <td>qwen2.5-0.5b</td>\n",
       "      <td>qwen2.5-0.5b-instruct-cuda-gpu</td>\n",
       "      <td>3</td>\n",
       "      <td>CUDAExecutionProvider</td>\n",
       "      <td>azureml://registries/azureml/models/qwen2.5-0....</td>\n",
       "      <td>528</td>\n",
       "      <td>{'system': '&lt;|im_start|&gt;system\n",
       "{Content}&lt;|im_e...</td>\n",
       "      <td>AzureFoundry</td>\n",
       "      <td>Microsoft</td>\n",
       "      <td>apache-2.0</td>\n",
       "      <td>chat-completion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>23</td>\n",
       "      <td>qwen2.5-0.5b</td>\n",
       "      <td>qwen2.5-0.5b-instruct-generic-gpu</td>\n",
       "      <td>3</td>\n",
       "      <td>WebGpuExecutionProvider</td>\n",
       "      <td>azureml://registries/azureml/models/qwen2.5-0....</td>\n",
       "      <td>700</td>\n",
       "      <td>{'system': '&lt;|im_start|&gt;system\n",
       "{Content}&lt;|im_e...</td>\n",
       "      <td>AzureFoundry</td>\n",
       "      <td>Microsoft</td>\n",
       "      <td>apache-2.0</td>\n",
       "      <td>chat-completion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>24</td>\n",
       "      <td>qwen2.5-0.5b</td>\n",
       "      <td>qwen2.5-0.5b-instruct-generic-cpu</td>\n",
       "      <td>3</td>\n",
       "      <td>CPUExecutionProvider</td>\n",
       "      <td>azureml://registries/azureml/models/qwen2.5-0....</td>\n",
       "      <td>822</td>\n",
       "      <td>{'system': '&lt;|im_start|&gt;system\n",
       "{Content}&lt;|im_e...</td>\n",
       "      <td>AzureFoundry</td>\n",
       "      <td>Microsoft</td>\n",
       "      <td>apache-2.0</td>\n",
       "      <td>chat-completion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>25</td>\n",
       "      <td>qwen2.5-1.5b</td>\n",
       "      <td>qwen2.5-1.5b-instruct-cuda-gpu</td>\n",
       "      <td>3</td>\n",
       "      <td>CUDAExecutionProvider</td>\n",
       "      <td>azureml://registries/azureml/models/qwen2.5-1....</td>\n",
       "      <td>1280</td>\n",
       "      <td>{'system': '&lt;|im_start|&gt;system\n",
       "{Content}&lt;|im_e...</td>\n",
       "      <td>AzureFoundry</td>\n",
       "      <td>Microsoft</td>\n",
       "      <td>apache-2.0</td>\n",
       "      <td>chat-completion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>26</td>\n",
       "      <td>qwen2.5-1.5b</td>\n",
       "      <td>qwen2.5-1.5b-instruct-generic-gpu</td>\n",
       "      <td>3</td>\n",
       "      <td>WebGpuExecutionProvider</td>\n",
       "      <td>azureml://registries/azureml/models/qwen2.5-1....</td>\n",
       "      <td>1546</td>\n",
       "      <td>{'system': '&lt;|im_start|&gt;system\n",
       "{Content}&lt;|im_e...</td>\n",
       "      <td>AzureFoundry</td>\n",
       "      <td>Microsoft</td>\n",
       "      <td>apache-2.0</td>\n",
       "      <td>chat-completion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>27</td>\n",
       "      <td>qwen2.5-1.5b</td>\n",
       "      <td>qwen2.5-1.5b-instruct-generic-cpu</td>\n",
       "      <td>3</td>\n",
       "      <td>CPUExecutionProvider</td>\n",
       "      <td>azureml://registries/azureml/models/qwen2.5-1....</td>\n",
       "      <td>1822</td>\n",
       "      <td>{'system': '&lt;|im_start|&gt;system\n",
       "{Content}&lt;|im_e...</td>\n",
       "      <td>AzureFoundry</td>\n",
       "      <td>Microsoft</td>\n",
       "      <td>apache-2.0</td>\n",
       "      <td>chat-completion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>28</td>\n",
       "      <td>qwen2.5-coder-7b</td>\n",
       "      <td>qwen2.5-coder-7b-instruct-cuda-gpu</td>\n",
       "      <td>3</td>\n",
       "      <td>CUDAExecutionProvider</td>\n",
       "      <td>azureml://registries/azureml/models/qwen2.5-co...</td>\n",
       "      <td>4843</td>\n",
       "      <td>{'system': '&lt;|im_start|&gt;system\n",
       "{Content}&lt;|im_e...</td>\n",
       "      <td>AzureFoundry</td>\n",
       "      <td>Microsoft</td>\n",
       "      <td>apache-2.0</td>\n",
       "      <td>chat-completion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>29</td>\n",
       "      <td>qwen2.5-coder-7b</td>\n",
       "      <td>qwen2.5-coder-7b-instruct-generic-gpu</td>\n",
       "      <td>3</td>\n",
       "      <td>WebGpuExecutionProvider</td>\n",
       "      <td>azureml://registries/azureml/models/qwen2.5-co...</td>\n",
       "      <td>4843</td>\n",
       "      <td>{'system': '&lt;|im_start|&gt;system\n",
       "{Content}&lt;|im_e...</td>\n",
       "      <td>AzureFoundry</td>\n",
       "      <td>Microsoft</td>\n",
       "      <td>apache-2.0</td>\n",
       "      <td>chat-completion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>30</td>\n",
       "      <td>qwen2.5-coder-7b</td>\n",
       "      <td>qwen2.5-coder-7b-instruct-generic-cpu</td>\n",
       "      <td>3</td>\n",
       "      <td>CPUExecutionProvider</td>\n",
       "      <td>azureml://registries/azureml/models/qwen2.5-co...</td>\n",
       "      <td>6307</td>\n",
       "      <td>{'system': '&lt;|im_start|&gt;system\n",
       "{Content}&lt;|im_e...</td>\n",
       "      <td>AzureFoundry</td>\n",
       "      <td>Microsoft</td>\n",
       "      <td>apache-2.0</td>\n",
       "      <td>chat-completion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>31</td>\n",
       "      <td>qwen2.5-coder-0.5b</td>\n",
       "      <td>qwen2.5-coder-0.5b-instruct-cuda-gpu</td>\n",
       "      <td>3</td>\n",
       "      <td>CUDAExecutionProvider</td>\n",
       "      <td>azureml://registries/azureml/models/qwen2.5-co...</td>\n",
       "      <td>528</td>\n",
       "      <td>{'system': '&lt;|im_start|&gt;system\n",
       "{Content}&lt;|im_e...</td>\n",
       "      <td>AzureFoundry</td>\n",
       "      <td>Microsoft</td>\n",
       "      <td>apache-2.0</td>\n",
       "      <td>chat-completion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>32</td>\n",
       "      <td>qwen2.5-coder-0.5b</td>\n",
       "      <td>qwen2.5-coder-0.5b-instruct-generic-gpu</td>\n",
       "      <td>3</td>\n",
       "      <td>WebGpuExecutionProvider</td>\n",
       "      <td>azureml://registries/azureml/models/qwen2.5-co...</td>\n",
       "      <td>528</td>\n",
       "      <td>{'system': '&lt;|im_start|&gt;system\n",
       "{Content}&lt;|im_e...</td>\n",
       "      <td>AzureFoundry</td>\n",
       "      <td>Microsoft</td>\n",
       "      <td>apache-2.0</td>\n",
       "      <td>chat-completion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>33</td>\n",
       "      <td>qwen2.5-coder-0.5b</td>\n",
       "      <td>qwen2.5-coder-0.5b-instruct-generic-cpu</td>\n",
       "      <td>3</td>\n",
       "      <td>CPUExecutionProvider</td>\n",
       "      <td>azureml://registries/azureml/models/qwen2.5-co...</td>\n",
       "      <td>822</td>\n",
       "      <td>{'system': '&lt;|im_start|&gt;system\n",
       "{Content}&lt;|im_e...</td>\n",
       "      <td>AzureFoundry</td>\n",
       "      <td>Microsoft</td>\n",
       "      <td>apache-2.0</td>\n",
       "      <td>chat-completion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>34</td>\n",
       "      <td>qwen2.5-coder-1.5b</td>\n",
       "      <td>qwen2.5-coder-1.5b-instruct-cuda-gpu</td>\n",
       "      <td>3</td>\n",
       "      <td>CUDAExecutionProvider</td>\n",
       "      <td>azureml://registries/azureml/models/qwen2.5-co...</td>\n",
       "      <td>1280</td>\n",
       "      <td>{'system': '&lt;|im_start|&gt;system\n",
       "{Content}&lt;|im_e...</td>\n",
       "      <td>AzureFoundry</td>\n",
       "      <td>Microsoft</td>\n",
       "      <td>apache-2.0</td>\n",
       "      <td>chat-completion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>35</td>\n",
       "      <td>qwen2.5-coder-1.5b</td>\n",
       "      <td>qwen2.5-coder-1.5b-instruct-generic-gpu</td>\n",
       "      <td>3</td>\n",
       "      <td>WebGpuExecutionProvider</td>\n",
       "      <td>azureml://registries/azureml/models/qwen2.5-co...</td>\n",
       "      <td>1280</td>\n",
       "      <td>{'system': '&lt;|im_start|&gt;system\n",
       "{Content}&lt;|im_e...</td>\n",
       "      <td>AzureFoundry</td>\n",
       "      <td>Microsoft</td>\n",
       "      <td>apache-2.0</td>\n",
       "      <td>chat-completion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>36</td>\n",
       "      <td>qwen2.5-coder-1.5b</td>\n",
       "      <td>qwen2.5-coder-1.5b-instruct-generic-cpu</td>\n",
       "      <td>3</td>\n",
       "      <td>CPUExecutionProvider</td>\n",
       "      <td>azureml://registries/azureml/models/qwen2.5-co...</td>\n",
       "      <td>1822</td>\n",
       "      <td>{'system': '&lt;|im_start|&gt;system\n",
       "{Content}&lt;|im_e...</td>\n",
       "      <td>AzureFoundry</td>\n",
       "      <td>Microsoft</td>\n",
       "      <td>apache-2.0</td>\n",
       "      <td>chat-completion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>37</td>\n",
       "      <td>phi-4-mini</td>\n",
       "      <td>Phi-4-mini-instruct-cuda-gpu</td>\n",
       "      <td>4</td>\n",
       "      <td>CUDAExecutionProvider</td>\n",
       "      <td>azureml://registries/azureml/models/Phi-4-mini...</td>\n",
       "      <td>3686</td>\n",
       "      <td>{'system': '&lt;|system|&gt;{Content}&lt;|end|&gt;', 'user...</td>\n",
       "      <td>AzureFoundry</td>\n",
       "      <td>Microsoft</td>\n",
       "      <td>MIT</td>\n",
       "      <td>chat-completion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>38</td>\n",
       "      <td>phi-4-mini</td>\n",
       "      <td>Phi-4-mini-instruct-generic-gpu</td>\n",
       "      <td>4</td>\n",
       "      <td>WebGpuExecutionProvider</td>\n",
       "      <td>azureml://registries/azureml/models/Phi-4-mini...</td>\n",
       "      <td>3809</td>\n",
       "      <td>{'system': '&lt;|system|&gt;{Content}&lt;|end|&gt;', 'user...</td>\n",
       "      <td>AzureFoundry</td>\n",
       "      <td>Microsoft</td>\n",
       "      <td>MIT</td>\n",
       "      <td>chat-completion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>39</td>\n",
       "      <td>phi-4-mini</td>\n",
       "      <td>Phi-4-mini-instruct-generic-cpu</td>\n",
       "      <td>4</td>\n",
       "      <td>CPUExecutionProvider</td>\n",
       "      <td>azureml://registries/azureml/models/Phi-4-mini...</td>\n",
       "      <td>4915</td>\n",
       "      <td>{'system': '&lt;|system|&gt;{Content}&lt;|end|&gt;', 'user...</td>\n",
       "      <td>AzureFoundry</td>\n",
       "      <td>Microsoft</td>\n",
       "      <td>MIT</td>\n",
       "      <td>chat-completion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>40</td>\n",
       "      <td>phi-4-mini-reasoning</td>\n",
       "      <td>Phi-4-mini-reasoning-cuda-gpu</td>\n",
       "      <td>2</td>\n",
       "      <td>CUDAExecutionProvider</td>\n",
       "      <td>azureml://registries/azureml/models/Phi-4-mini...</td>\n",
       "      <td>3225</td>\n",
       "      <td>{'system': '&lt;|system|&gt;Your name is Phi, an AI ...</td>\n",
       "      <td>AzureFoundry</td>\n",
       "      <td>Microsoft</td>\n",
       "      <td>MIT</td>\n",
       "      <td>chat-completion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>41</td>\n",
       "      <td>phi-4-mini-reasoning</td>\n",
       "      <td>Phi-4-mini-reasoning-generic-gpu</td>\n",
       "      <td>2</td>\n",
       "      <td>WebGpuExecutionProvider</td>\n",
       "      <td>azureml://registries/azureml/models/Phi-4-mini...</td>\n",
       "      <td>3225</td>\n",
       "      <td>{'system': '&lt;|system|&gt;Your name is Phi, an AI ...</td>\n",
       "      <td>AzureFoundry</td>\n",
       "      <td>Microsoft</td>\n",
       "      <td>MIT</td>\n",
       "      <td>chat-completion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>42</td>\n",
       "      <td>phi-4-mini-reasoning</td>\n",
       "      <td>Phi-4-mini-reasoning-generic-cpu</td>\n",
       "      <td>2</td>\n",
       "      <td>CPUExecutionProvider</td>\n",
       "      <td>azureml://registries/azureml/models/Phi-4-mini...</td>\n",
       "      <td>4628</td>\n",
       "      <td>{'system': '&lt;|system|&gt;Your name is Phi, an AI ...</td>\n",
       "      <td>AzureFoundry</td>\n",
       "      <td>Microsoft</td>\n",
       "      <td>MIT</td>\n",
       "      <td>chat-completion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>43</td>\n",
       "      <td>qwen2.5-14b</td>\n",
       "      <td>qwen2.5-14b-instruct-cuda-gpu</td>\n",
       "      <td>3</td>\n",
       "      <td>CUDAExecutionProvider</td>\n",
       "      <td>azureml://registries/azureml/models/qwen2.5-14...</td>\n",
       "      <td>9000</td>\n",
       "      <td>{'system': '&lt;|im_start|&gt;system\n",
       "{Content}&lt;|im_e...</td>\n",
       "      <td>AzureFoundry</td>\n",
       "      <td>Microsoft</td>\n",
       "      <td>apache-2.0</td>\n",
       "      <td>chat-completion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>44</td>\n",
       "      <td>qwen2.5-14b</td>\n",
       "      <td>qwen2.5-14b-instruct-generic-cpu</td>\n",
       "      <td>3</td>\n",
       "      <td>CPUExecutionProvider</td>\n",
       "      <td>azureml://registries/azureml/models/qwen2.5-14...</td>\n",
       "      <td>11325</td>\n",
       "      <td>{'system': '&lt;|im_start|&gt;system\n",
       "{Content}&lt;|im_e...</td>\n",
       "      <td>AzureFoundry</td>\n",
       "      <td>Microsoft</td>\n",
       "      <td>apache-2.0</td>\n",
       "      <td>chat-completion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>45</td>\n",
       "      <td>qwen2.5-7b</td>\n",
       "      <td>qwen2.5-7b-instruct-cuda-gpu</td>\n",
       "      <td>3</td>\n",
       "      <td>CUDAExecutionProvider</td>\n",
       "      <td>azureml://registries/azureml/models/qwen2.5-7b...</td>\n",
       "      <td>4843</td>\n",
       "      <td>{'system': '&lt;|im_start|&gt;system\n",
       "{Content}&lt;|im_e...</td>\n",
       "      <td>AzureFoundry</td>\n",
       "      <td>Microsoft</td>\n",
       "      <td>apache-2.0</td>\n",
       "      <td>chat-completion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>46</td>\n",
       "      <td>qwen2.5-7b</td>\n",
       "      <td>qwen2.5-7b-instruct-generic-gpu</td>\n",
       "      <td>3</td>\n",
       "      <td>WebGpuExecutionProvider</td>\n",
       "      <td>azureml://registries/azureml/models/qwen2.5-7b...</td>\n",
       "      <td>5324</td>\n",
       "      <td>{'system': '&lt;|im_start|&gt;system\n",
       "{Content}&lt;|im_e...</td>\n",
       "      <td>AzureFoundry</td>\n",
       "      <td>Microsoft</td>\n",
       "      <td>apache-2.0</td>\n",
       "      <td>chat-completion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>47</td>\n",
       "      <td>qwen2.5-7b</td>\n",
       "      <td>qwen2.5-7b-instruct-generic-cpu</td>\n",
       "      <td>3</td>\n",
       "      <td>CPUExecutionProvider</td>\n",
       "      <td>azureml://registries/azureml/models/qwen2.5-7b...</td>\n",
       "      <td>6307</td>\n",
       "      <td>{'system': '&lt;|im_start|&gt;system\n",
       "{Content}&lt;|im_e...</td>\n",
       "      <td>AzureFoundry</td>\n",
       "      <td>Microsoft</td>\n",
       "      <td>apache-2.0</td>\n",
       "      <td>chat-completion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>48</td>\n",
       "      <td>qwen2.5-coder-14b</td>\n",
       "      <td>qwen2.5-coder-14b-instruct-cuda-gpu</td>\n",
       "      <td>3</td>\n",
       "      <td>CUDAExecutionProvider</td>\n",
       "      <td>azureml://registries/azureml/models/qwen2.5-co...</td>\n",
       "      <td>9000</td>\n",
       "      <td>{'system': '&lt;|im_start|&gt;system\n",
       "{Content}&lt;|im_e...</td>\n",
       "      <td>AzureFoundry</td>\n",
       "      <td>Microsoft</td>\n",
       "      <td>apache-2.0</td>\n",
       "      <td>chat-completion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>49</td>\n",
       "      <td>qwen2.5-coder-14b</td>\n",
       "      <td>qwen2.5-coder-14b-instruct-generic-gpu</td>\n",
       "      <td>3</td>\n",
       "      <td>WebGpuExecutionProvider</td>\n",
       "      <td>azureml://registries/azureml/models/qwen2.5-co...</td>\n",
       "      <td>9000</td>\n",
       "      <td>{'system': '&lt;|im_start|&gt;system\n",
       "{Content}&lt;|im_e...</td>\n",
       "      <td>AzureFoundry</td>\n",
       "      <td>Microsoft</td>\n",
       "      <td>apache-2.0</td>\n",
       "      <td>chat-completion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>50</td>\n",
       "      <td>qwen2.5-coder-14b</td>\n",
       "      <td>qwen2.5-coder-14b-instruct-generic-cpu</td>\n",
       "      <td>3</td>\n",
       "      <td>CPUExecutionProvider</td>\n",
       "      <td>azureml://registries/azureml/models/qwen2.5-co...</td>\n",
       "      <td>11325</td>\n",
       "      <td>{'system': '&lt;|im_start|&gt;system\n",
       "{Content}&lt;|im_e...</td>\n",
       "      <td>AzureFoundry</td>\n",
       "      <td>Microsoft</td>\n",
       "      <td>apache-2.0</td>\n",
       "      <td>chat-completion</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    index                 alias  \\\n",
       "0       1                 phi-4   \n",
       "1       2                 phi-4   \n",
       "2       3                 phi-4   \n",
       "3       4       phi-3-mini-128k   \n",
       "4       5       phi-3-mini-128k   \n",
       "5       6       phi-3-mini-128k   \n",
       "6       7         phi-3-mini-4k   \n",
       "7       8         phi-3-mini-4k   \n",
       "8       9         phi-3-mini-4k   \n",
       "9      10       mistral-7b-v0.2   \n",
       "10     11       mistral-7b-v0.2   \n",
       "11     12       mistral-7b-v0.2   \n",
       "12     13          phi-3.5-mini   \n",
       "13     14          phi-3.5-mini   \n",
       "14     15          phi-3.5-mini   \n",
       "15     16       deepseek-r1-14b   \n",
       "16     17       deepseek-r1-14b   \n",
       "17     18       deepseek-r1-14b   \n",
       "18     19        deepseek-r1-7b   \n",
       "19     20        deepseek-r1-7b   \n",
       "20     21        deepseek-r1-7b   \n",
       "21     22          qwen2.5-0.5b   \n",
       "22     23          qwen2.5-0.5b   \n",
       "23     24          qwen2.5-0.5b   \n",
       "24     25          qwen2.5-1.5b   \n",
       "25     26          qwen2.5-1.5b   \n",
       "26     27          qwen2.5-1.5b   \n",
       "27     28      qwen2.5-coder-7b   \n",
       "28     29      qwen2.5-coder-7b   \n",
       "29     30      qwen2.5-coder-7b   \n",
       "30     31    qwen2.5-coder-0.5b   \n",
       "31     32    qwen2.5-coder-0.5b   \n",
       "32     33    qwen2.5-coder-0.5b   \n",
       "33     34    qwen2.5-coder-1.5b   \n",
       "34     35    qwen2.5-coder-1.5b   \n",
       "35     36    qwen2.5-coder-1.5b   \n",
       "36     37            phi-4-mini   \n",
       "37     38            phi-4-mini   \n",
       "38     39            phi-4-mini   \n",
       "39     40  phi-4-mini-reasoning   \n",
       "40     41  phi-4-mini-reasoning   \n",
       "41     42  phi-4-mini-reasoning   \n",
       "42     43           qwen2.5-14b   \n",
       "43     44           qwen2.5-14b   \n",
       "44     45            qwen2.5-7b   \n",
       "45     46            qwen2.5-7b   \n",
       "46     47            qwen2.5-7b   \n",
       "47     48     qwen2.5-coder-14b   \n",
       "48     49     qwen2.5-coder-14b   \n",
       "49     50     qwen2.5-coder-14b   \n",
       "\n",
       "                                                id version  \\\n",
       "0                                   Phi-4-cuda-gpu       1   \n",
       "1                                Phi-4-generic-gpu       1   \n",
       "2                                Phi-4-generic-cpu       1   \n",
       "3                Phi-3-mini-128k-instruct-cuda-gpu       1   \n",
       "4             Phi-3-mini-128k-instruct-generic-gpu       1   \n",
       "5             Phi-3-mini-128k-instruct-generic-cpu       2   \n",
       "6                  Phi-3-mini-4k-instruct-cuda-gpu       1   \n",
       "7               Phi-3-mini-4k-instruct-generic-gpu       1   \n",
       "8               Phi-3-mini-4k-instruct-generic-cpu       2   \n",
       "9      mistralai-Mistral-7B-Instruct-v0-2-cuda-gpu       1   \n",
       "10  mistralai-Mistral-7B-Instruct-v0-2-generic-gpu       1   \n",
       "11  mistralai-Mistral-7B-Instruct-v0-2-generic-cpu       2   \n",
       "12                  Phi-3.5-mini-instruct-cuda-gpu       1   \n",
       "13               Phi-3.5-mini-instruct-generic-gpu       1   \n",
       "14               Phi-3.5-mini-instruct-generic-cpu       1   \n",
       "15           deepseek-r1-distill-qwen-14b-cuda-gpu       3   \n",
       "16        deepseek-r1-distill-qwen-14b-generic-gpu       3   \n",
       "17        deepseek-r1-distill-qwen-14b-generic-cpu       3   \n",
       "18            deepseek-r1-distill-qwen-7b-cuda-gpu       3   \n",
       "19         deepseek-r1-distill-qwen-7b-generic-gpu       3   \n",
       "20         deepseek-r1-distill-qwen-7b-generic-cpu       3   \n",
       "21                  qwen2.5-0.5b-instruct-cuda-gpu       3   \n",
       "22               qwen2.5-0.5b-instruct-generic-gpu       3   \n",
       "23               qwen2.5-0.5b-instruct-generic-cpu       3   \n",
       "24                  qwen2.5-1.5b-instruct-cuda-gpu       3   \n",
       "25               qwen2.5-1.5b-instruct-generic-gpu       3   \n",
       "26               qwen2.5-1.5b-instruct-generic-cpu       3   \n",
       "27              qwen2.5-coder-7b-instruct-cuda-gpu       3   \n",
       "28           qwen2.5-coder-7b-instruct-generic-gpu       3   \n",
       "29           qwen2.5-coder-7b-instruct-generic-cpu       3   \n",
       "30            qwen2.5-coder-0.5b-instruct-cuda-gpu       3   \n",
       "31         qwen2.5-coder-0.5b-instruct-generic-gpu       3   \n",
       "32         qwen2.5-coder-0.5b-instruct-generic-cpu       3   \n",
       "33            qwen2.5-coder-1.5b-instruct-cuda-gpu       3   \n",
       "34         qwen2.5-coder-1.5b-instruct-generic-gpu       3   \n",
       "35         qwen2.5-coder-1.5b-instruct-generic-cpu       3   \n",
       "36                    Phi-4-mini-instruct-cuda-gpu       4   \n",
       "37                 Phi-4-mini-instruct-generic-gpu       4   \n",
       "38                 Phi-4-mini-instruct-generic-cpu       4   \n",
       "39                   Phi-4-mini-reasoning-cuda-gpu       2   \n",
       "40                Phi-4-mini-reasoning-generic-gpu       2   \n",
       "41                Phi-4-mini-reasoning-generic-cpu       2   \n",
       "42                   qwen2.5-14b-instruct-cuda-gpu       3   \n",
       "43                qwen2.5-14b-instruct-generic-cpu       3   \n",
       "44                    qwen2.5-7b-instruct-cuda-gpu       3   \n",
       "45                 qwen2.5-7b-instruct-generic-gpu       3   \n",
       "46                 qwen2.5-7b-instruct-generic-cpu       3   \n",
       "47             qwen2.5-coder-14b-instruct-cuda-gpu       3   \n",
       "48          qwen2.5-coder-14b-instruct-generic-gpu       3   \n",
       "49          qwen2.5-coder-14b-instruct-generic-cpu       3   \n",
       "\n",
       "                    runtime  \\\n",
       "0     CUDAExecutionProvider   \n",
       "1   WebGpuExecutionProvider   \n",
       "2      CPUExecutionProvider   \n",
       "3     CUDAExecutionProvider   \n",
       "4   WebGpuExecutionProvider   \n",
       "5      CPUExecutionProvider   \n",
       "6     CUDAExecutionProvider   \n",
       "7   WebGpuExecutionProvider   \n",
       "8      CPUExecutionProvider   \n",
       "9     CUDAExecutionProvider   \n",
       "10  WebGpuExecutionProvider   \n",
       "11     CPUExecutionProvider   \n",
       "12    CUDAExecutionProvider   \n",
       "13  WebGpuExecutionProvider   \n",
       "14     CPUExecutionProvider   \n",
       "15    CUDAExecutionProvider   \n",
       "16  WebGpuExecutionProvider   \n",
       "17     CPUExecutionProvider   \n",
       "18    CUDAExecutionProvider   \n",
       "19  WebGpuExecutionProvider   \n",
       "20     CPUExecutionProvider   \n",
       "21    CUDAExecutionProvider   \n",
       "22  WebGpuExecutionProvider   \n",
       "23     CPUExecutionProvider   \n",
       "24    CUDAExecutionProvider   \n",
       "25  WebGpuExecutionProvider   \n",
       "26     CPUExecutionProvider   \n",
       "27    CUDAExecutionProvider   \n",
       "28  WebGpuExecutionProvider   \n",
       "29     CPUExecutionProvider   \n",
       "30    CUDAExecutionProvider   \n",
       "31  WebGpuExecutionProvider   \n",
       "32     CPUExecutionProvider   \n",
       "33    CUDAExecutionProvider   \n",
       "34  WebGpuExecutionProvider   \n",
       "35     CPUExecutionProvider   \n",
       "36    CUDAExecutionProvider   \n",
       "37  WebGpuExecutionProvider   \n",
       "38     CPUExecutionProvider   \n",
       "39    CUDAExecutionProvider   \n",
       "40  WebGpuExecutionProvider   \n",
       "41     CPUExecutionProvider   \n",
       "42    CUDAExecutionProvider   \n",
       "43     CPUExecutionProvider   \n",
       "44    CUDAExecutionProvider   \n",
       "45  WebGpuExecutionProvider   \n",
       "46     CPUExecutionProvider   \n",
       "47    CUDAExecutionProvider   \n",
       "48  WebGpuExecutionProvider   \n",
       "49     CPUExecutionProvider   \n",
       "\n",
       "                                                  uri  file_size_mb  \\\n",
       "0   azureml://registries/azureml/models/Phi-4-cuda...          8570   \n",
       "1   azureml://registries/azureml/models/Phi-4-gene...          8570   \n",
       "2   azureml://registries/azureml/models/Phi-4-gene...         10403   \n",
       "3   azureml://registries/azureml/models/Phi-3-mini...          2181   \n",
       "4   azureml://registries/azureml/models/Phi-3-mini...          2181   \n",
       "5   azureml://registries/azureml/models/Phi-3-mini...          2600   \n",
       "6   azureml://registries/azureml/models/Phi-3-mini...          2181   \n",
       "7   azureml://registries/azureml/models/Phi-3-mini...          2181   \n",
       "8   azureml://registries/azureml/models/Phi-3-mini...          2590   \n",
       "9   azureml://registries/azureml/models/mistralai-...          4075   \n",
       "10  azureml://registries/azureml/models/mistralai-...          4167   \n",
       "11  azureml://registries/azureml/models/mistralai-...          4167   \n",
       "12  azureml://registries/azureml/models/Phi-3.5-mi...          2181   \n",
       "13  azureml://registries/azureml/models/Phi-3.5-mi...          2211   \n",
       "14  azureml://registries/azureml/models/Phi-3.5-mi...          2590   \n",
       "15  azureml://registries/azureml/models/deepseek-r...         10065   \n",
       "16  azureml://registries/azureml/models/deepseek-r...         10516   \n",
       "17  azureml://registries/azureml/models/deepseek-r...         11786   \n",
       "18  azureml://registries/azureml/models/deepseek-r...          5406   \n",
       "19  azureml://registries/azureml/models/deepseek-r...          5713   \n",
       "20  azureml://registries/azureml/models/deepseek-r...          6584   \n",
       "21  azureml://registries/azureml/models/qwen2.5-0....           528   \n",
       "22  azureml://registries/azureml/models/qwen2.5-0....           700   \n",
       "23  azureml://registries/azureml/models/qwen2.5-0....           822   \n",
       "24  azureml://registries/azureml/models/qwen2.5-1....          1280   \n",
       "25  azureml://registries/azureml/models/qwen2.5-1....          1546   \n",
       "26  azureml://registries/azureml/models/qwen2.5-1....          1822   \n",
       "27  azureml://registries/azureml/models/qwen2.5-co...          4843   \n",
       "28  azureml://registries/azureml/models/qwen2.5-co...          4843   \n",
       "29  azureml://registries/azureml/models/qwen2.5-co...          6307   \n",
       "30  azureml://registries/azureml/models/qwen2.5-co...           528   \n",
       "31  azureml://registries/azureml/models/qwen2.5-co...           528   \n",
       "32  azureml://registries/azureml/models/qwen2.5-co...           822   \n",
       "33  azureml://registries/azureml/models/qwen2.5-co...          1280   \n",
       "34  azureml://registries/azureml/models/qwen2.5-co...          1280   \n",
       "35  azureml://registries/azureml/models/qwen2.5-co...          1822   \n",
       "36  azureml://registries/azureml/models/Phi-4-mini...          3686   \n",
       "37  azureml://registries/azureml/models/Phi-4-mini...          3809   \n",
       "38  azureml://registries/azureml/models/Phi-4-mini...          4915   \n",
       "39  azureml://registries/azureml/models/Phi-4-mini...          3225   \n",
       "40  azureml://registries/azureml/models/Phi-4-mini...          3225   \n",
       "41  azureml://registries/azureml/models/Phi-4-mini...          4628   \n",
       "42  azureml://registries/azureml/models/qwen2.5-14...          9000   \n",
       "43  azureml://registries/azureml/models/qwen2.5-14...         11325   \n",
       "44  azureml://registries/azureml/models/qwen2.5-7b...          4843   \n",
       "45  azureml://registries/azureml/models/qwen2.5-7b...          5324   \n",
       "46  azureml://registries/azureml/models/qwen2.5-7b...          6307   \n",
       "47  azureml://registries/azureml/models/qwen2.5-co...          9000   \n",
       "48  azureml://registries/azureml/models/qwen2.5-co...          9000   \n",
       "49  azureml://registries/azureml/models/qwen2.5-co...         11325   \n",
       "\n",
       "                                      prompt_template      provider  \\\n",
       "0   {'system': '<|system|>\n",
       "{Content}<|im_end|>', '...  AzureFoundry   \n",
       "1   {'system': '<|system|>\n",
       "{Content}<|im_end|>', '...  AzureFoundry   \n",
       "2   {'system': '<|system|>\n",
       "{Content}<|im_end|>', '...  AzureFoundry   \n",
       "3   {'prompt': '<|user|>\n",
       "{Content}<|end|>\n",
       "<|assist...  AzureFoundry   \n",
       "4   {'system': '<|system|>\n",
       "{Content}<|end|>', 'use...  AzureFoundry   \n",
       "5   {'system': '<|system|>\n",
       "{Content}<|end|>', 'use...  AzureFoundry   \n",
       "6   {'prompt': '<|user|>\n",
       "{Content}<|end|>\n",
       "<|assist...  AzureFoundry   \n",
       "7   {'system': '<|system|>\n",
       "{Content}<|end|>', 'use...  AzureFoundry   \n",
       "8   {'system': '<|system|>\n",
       "{Content}<|end|>', 'use...  AzureFoundry   \n",
       "9   {'prompt': '[INST]\n",
       "{Content}\n",
       "[/INST]', 'assist...  AzureFoundry   \n",
       "10  {'prompt': '[INST]\n",
       "{Content}\n",
       "[/INST]', 'assist...  AzureFoundry   \n",
       "11  {'system': '<s>', 'user': '[INST]\n",
       "{Content}\n",
       "[/...  AzureFoundry   \n",
       "12  {'prompt': '<|user|>\n",
       "{Content}<|end|>\n",
       "<|assist...  AzureFoundry   \n",
       "13  {'prompt': '<|user|>\n",
       "{Content}<|end|>\n",
       "<|assist...  AzureFoundry   \n",
       "14  {'prompt': '<|user|>\n",
       "{Content}<|end|>\n",
       "<|assist...  AzureFoundry   \n",
       "15  {'assistant': '{Content}', 'prompt': '\\u003C\\u...  AzureFoundry   \n",
       "16  {'assistant': '{Content}', 'prompt': '\\u003C\\u...  AzureFoundry   \n",
       "17  {'assistant': '{Content}', 'prompt': '\\u003C\\u...  AzureFoundry   \n",
       "18  {'assistant': '{Content}', 'prompt': '\\u003C\\u...  AzureFoundry   \n",
       "19  {'assistant': '{Content}', 'prompt': '\\u003C\\u...  AzureFoundry   \n",
       "20  {'assistant': '{Content}', 'prompt': '\\u003C\\u...  AzureFoundry   \n",
       "21  {'system': '<|im_start|>system\n",
       "{Content}<|im_e...  AzureFoundry   \n",
       "22  {'system': '<|im_start|>system\n",
       "{Content}<|im_e...  AzureFoundry   \n",
       "23  {'system': '<|im_start|>system\n",
       "{Content}<|im_e...  AzureFoundry   \n",
       "24  {'system': '<|im_start|>system\n",
       "{Content}<|im_e...  AzureFoundry   \n",
       "25  {'system': '<|im_start|>system\n",
       "{Content}<|im_e...  AzureFoundry   \n",
       "26  {'system': '<|im_start|>system\n",
       "{Content}<|im_e...  AzureFoundry   \n",
       "27  {'system': '<|im_start|>system\n",
       "{Content}<|im_e...  AzureFoundry   \n",
       "28  {'system': '<|im_start|>system\n",
       "{Content}<|im_e...  AzureFoundry   \n",
       "29  {'system': '<|im_start|>system\n",
       "{Content}<|im_e...  AzureFoundry   \n",
       "30  {'system': '<|im_start|>system\n",
       "{Content}<|im_e...  AzureFoundry   \n",
       "31  {'system': '<|im_start|>system\n",
       "{Content}<|im_e...  AzureFoundry   \n",
       "32  {'system': '<|im_start|>system\n",
       "{Content}<|im_e...  AzureFoundry   \n",
       "33  {'system': '<|im_start|>system\n",
       "{Content}<|im_e...  AzureFoundry   \n",
       "34  {'system': '<|im_start|>system\n",
       "{Content}<|im_e...  AzureFoundry   \n",
       "35  {'system': '<|im_start|>system\n",
       "{Content}<|im_e...  AzureFoundry   \n",
       "36  {'system': '<|system|>{Content}<|end|>', 'user...  AzureFoundry   \n",
       "37  {'system': '<|system|>{Content}<|end|>', 'user...  AzureFoundry   \n",
       "38  {'system': '<|system|>{Content}<|end|>', 'user...  AzureFoundry   \n",
       "39  {'system': '<|system|>Your name is Phi, an AI ...  AzureFoundry   \n",
       "40  {'system': '<|system|>Your name is Phi, an AI ...  AzureFoundry   \n",
       "41  {'system': '<|system|>Your name is Phi, an AI ...  AzureFoundry   \n",
       "42  {'system': '<|im_start|>system\n",
       "{Content}<|im_e...  AzureFoundry   \n",
       "43  {'system': '<|im_start|>system\n",
       "{Content}<|im_e...  AzureFoundry   \n",
       "44  {'system': '<|im_start|>system\n",
       "{Content}<|im_e...  AzureFoundry   \n",
       "45  {'system': '<|im_start|>system\n",
       "{Content}<|im_e...  AzureFoundry   \n",
       "46  {'system': '<|im_start|>system\n",
       "{Content}<|im_e...  AzureFoundry   \n",
       "47  {'system': '<|im_start|>system\n",
       "{Content}<|im_e...  AzureFoundry   \n",
       "48  {'system': '<|im_start|>system\n",
       "{Content}<|im_e...  AzureFoundry   \n",
       "49  {'system': '<|im_start|>system\n",
       "{Content}<|im_e...  AzureFoundry   \n",
       "\n",
       "    publisher     license             task  \n",
       "0   Microsoft         MIT  chat-completion  \n",
       "1   Microsoft         MIT  chat-completion  \n",
       "2   Microsoft         MIT  chat-completion  \n",
       "3   Microsoft         MIT  chat-completion  \n",
       "4   Microsoft         MIT  chat-completion  \n",
       "5   Microsoft         MIT  chat-completion  \n",
       "6   Microsoft         MIT  chat-completion  \n",
       "7   Microsoft         MIT  chat-completion  \n",
       "8   Microsoft         MIT  chat-completion  \n",
       "9   Microsoft  apache-2.0  chat-completion  \n",
       "10  Microsoft  apache-2.0  chat-completion  \n",
       "11  Microsoft  apache-2.0  chat-completion  \n",
       "12  Microsoft         MIT  chat-completion  \n",
       "13  Microsoft         MIT  chat-completion  \n",
       "14  Microsoft         MIT  chat-completion  \n",
       "15  Microsoft         MIT  chat-completion  \n",
       "16  Microsoft         MIT  chat-completion  \n",
       "17  Microsoft         MIT  chat-completion  \n",
       "18  Microsoft         MIT  chat-completion  \n",
       "19  Microsoft         MIT  chat-completion  \n",
       "20  Microsoft         MIT  chat-completion  \n",
       "21  Microsoft  apache-2.0  chat-completion  \n",
       "22  Microsoft  apache-2.0  chat-completion  \n",
       "23  Microsoft  apache-2.0  chat-completion  \n",
       "24  Microsoft  apache-2.0  chat-completion  \n",
       "25  Microsoft  apache-2.0  chat-completion  \n",
       "26  Microsoft  apache-2.0  chat-completion  \n",
       "27  Microsoft  apache-2.0  chat-completion  \n",
       "28  Microsoft  apache-2.0  chat-completion  \n",
       "29  Microsoft  apache-2.0  chat-completion  \n",
       "30  Microsoft  apache-2.0  chat-completion  \n",
       "31  Microsoft  apache-2.0  chat-completion  \n",
       "32  Microsoft  apache-2.0  chat-completion  \n",
       "33  Microsoft  apache-2.0  chat-completion  \n",
       "34  Microsoft  apache-2.0  chat-completion  \n",
       "35  Microsoft  apache-2.0  chat-completion  \n",
       "36  Microsoft         MIT  chat-completion  \n",
       "37  Microsoft         MIT  chat-completion  \n",
       "38  Microsoft         MIT  chat-completion  \n",
       "39  Microsoft         MIT  chat-completion  \n",
       "40  Microsoft         MIT  chat-completion  \n",
       "41  Microsoft         MIT  chat-completion  \n",
       "42  Microsoft  apache-2.0  chat-completion  \n",
       "43  Microsoft  apache-2.0  chat-completion  \n",
       "44  Microsoft  apache-2.0  chat-completion  \n",
       "45  Microsoft  apache-2.0  chat-completion  \n",
       "46  Microsoft  apache-2.0  chat-completion  \n",
       "47  Microsoft  apache-2.0  chat-completion  \n",
       "48  Microsoft  apache-2.0  chat-completion  \n",
       "49  Microsoft  apache-2.0  chat-completion  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = []\n",
    "\n",
    "for idx, item in enumerate(catalog, start=1):\n",
    "    data.append({\n",
    "        \"index\": idx,\n",
    "        \"alias\": item.alias,\n",
    "        \"id\": item.id,\n",
    "        \"version\": item.version,\n",
    "        \"runtime\": str(item.runtime),\n",
    "        \"uri\": item.uri,\n",
    "        \"file_size_mb\": item.file_size_mb,\n",
    "        \"prompt_template\": item.prompt_template,\n",
    "        \"provider\": item.provider,\n",
    "        \"publisher\": item.publisher,\n",
    "        \"license\": item.license,\n",
    "        \"task\": item.task\n",
    "    })\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "28bcd51e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Phi-4-cuda-gpu\n",
      "Phi-4-generic-gpu\n",
      "Phi-4-generic-cpu\n",
      "Phi-3-mini-128k-instruct-cuda-gpu\n",
      "Phi-3-mini-128k-instruct-generic-gpu\n",
      "Phi-3-mini-128k-instruct-generic-cpu\n",
      "Phi-3-mini-4k-instruct-cuda-gpu\n",
      "Phi-3-mini-4k-instruct-generic-gpu\n",
      "Phi-3-mini-4k-instruct-generic-cpu\n",
      "mistralai-Mistral-7B-Instruct-v0-2-cuda-gpu\n",
      "mistralai-Mistral-7B-Instruct-v0-2-generic-gpu\n",
      "mistralai-Mistral-7B-Instruct-v0-2-generic-cpu\n",
      "Phi-3.5-mini-instruct-cuda-gpu\n",
      "Phi-3.5-mini-instruct-generic-gpu\n",
      "Phi-3.5-mini-instruct-generic-cpu\n",
      "deepseek-r1-distill-qwen-14b-cuda-gpu\n",
      "deepseek-r1-distill-qwen-14b-generic-gpu\n",
      "deepseek-r1-distill-qwen-14b-generic-cpu\n",
      "deepseek-r1-distill-qwen-7b-cuda-gpu\n",
      "deepseek-r1-distill-qwen-7b-generic-gpu\n",
      "deepseek-r1-distill-qwen-7b-generic-cpu\n",
      "qwen2.5-0.5b-instruct-cuda-gpu\n",
      "qwen2.5-0.5b-instruct-generic-gpu\n",
      "qwen2.5-0.5b-instruct-generic-cpu\n",
      "qwen2.5-1.5b-instruct-cuda-gpu\n",
      "qwen2.5-1.5b-instruct-generic-gpu\n",
      "qwen2.5-1.5b-instruct-generic-cpu\n",
      "qwen2.5-coder-7b-instruct-cuda-gpu\n",
      "qwen2.5-coder-7b-instruct-generic-gpu\n",
      "qwen2.5-coder-7b-instruct-generic-cpu\n",
      "qwen2.5-coder-0.5b-instruct-cuda-gpu\n",
      "qwen2.5-coder-0.5b-instruct-generic-gpu\n",
      "qwen2.5-coder-0.5b-instruct-generic-cpu\n",
      "qwen2.5-coder-1.5b-instruct-cuda-gpu\n",
      "qwen2.5-coder-1.5b-instruct-generic-gpu\n",
      "qwen2.5-coder-1.5b-instruct-generic-cpu\n",
      "Phi-4-mini-instruct-cuda-gpu\n",
      "Phi-4-mini-instruct-generic-gpu\n",
      "Phi-4-mini-instruct-generic-cpu\n",
      "Phi-4-mini-reasoning-cuda-gpu\n",
      "Phi-4-mini-reasoning-generic-gpu\n",
      "Phi-4-mini-reasoning-generic-cpu\n",
      "qwen2.5-14b-instruct-cuda-gpu\n",
      "qwen2.5-14b-instruct-generic-cpu\n",
      "qwen2.5-7b-instruct-cuda-gpu\n",
      "qwen2.5-7b-instruct-generic-gpu\n",
      "qwen2.5-7b-instruct-generic-cpu\n",
      "qwen2.5-coder-14b-instruct-cuda-gpu\n",
      "qwen2.5-coder-14b-instruct-generic-gpu\n",
      "qwen2.5-coder-14b-instruct-generic-cpu\n"
     ]
    }
   ],
   "source": [
    "for idx in range(len(catalog)):\n",
    "    model = catalog[idx].id\n",
    "    print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "777c87bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of models in the catalog = 50\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of models in the catalog =\", len(catalog))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e95451a7",
   "metadata": {},
   "source": [
    "## Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1fa45ed2",
   "metadata": {},
   "outputs": [],
   "source": [
    "alias = \"phi-3.5-mini\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "07e39c36",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model info:\n",
      "alias='phi-3.5-mini' id='Phi-3.5-mini-instruct-cuda-gpu' version='1' runtime=<ExecutionProvider.CUDA: 'CUDAExecutionProvider'> uri='azureml://registries/azureml/models/Phi-3.5-mini-instruct-cuda-gpu/versions/1' file_size_mb=2181 prompt_template={'prompt': '<|user|>\\n{Content}<|end|>\\n<|assistant|>', 'assistant': '<|assistant|>\\n{Content}<|end|>'} provider='AzureFoundry' publisher='Microsoft' license='MIT' task='chat-completion'\n"
     ]
    }
   ],
   "source": [
    "# Download and load a model\n",
    "model_info = manager.download_model(alias)\n",
    "model_info = manager.load_model(alias)\n",
    "print(f\"Model info:\\n{model_info}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f1d83fd9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Models in cache:\n",
      "[FoundryModelInfo(alias=phi-3.5-mini, id=Phi-3.5-mini-instruct-cuda-gpu, runtime=cuda, file_size=2181 MB, license=MIT)]\n"
     ]
    }
   ],
   "source": [
    "# List models in cache\n",
    "local_models = manager.list_cached_models()\n",
    "print(f\"Models in cache:\\n{local_models}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7ef88026",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Models running in the service:\n",
      "[FoundryModelInfo(alias=phi-3.5-mini, id=Phi-3.5-mini-instruct-cuda-gpu, runtime=cuda, file_size=2181 MB, license=MIT), FoundryModelInfo(alias=phi-4-mini-reasoning, id=Phi-4-mini-reasoning-generic-cpu, runtime=cpu, file_size=4628 MB, license=MIT)]\n"
     ]
    }
   ],
   "source": [
    "# List loaded models\n",
    "loaded = manager.list_loaded_models()\n",
    "print(f\"Models running in the service:\\n{loaded}\")\n",
    "\n",
    "# Unload a model\n",
    "manager.unload_model(alias)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8aeb996e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " The number 3.1415 is a decimal approximation of the mathematical constant pi (), which represents the ratio of a circle' extruded circumference to its diameter. Pi is an irrational number, meaning it has an infinite number of non-repeating decimals. The value 3.1415 is accurate to four decimal places, but it is often rounded to 3.14 for simplicity in many practical applications. The more precise value of pi to five decimal places is 3.14159."
     ]
    }
   ],
   "source": [
    "# Streaming\n",
    "\n",
    "alias = \"phi-3.5-mini\"\n",
    "\n",
    "manager = FoundryLocalManager(alias)\n",
    "\n",
    "client = openai.OpenAI(\n",
    "    base_url=manager.endpoint,\n",
    "    api_key=manager.api_key  # API key is not required for local usage\n",
    ")\n",
    "\n",
    "# Set the model to use and generate a streaming response\n",
    "stream = client.chat.completions.create(model=manager.get_model_info(alias).id,\n",
    "                                        messages=[{\n",
    "                                            \"role\": \"user\",\n",
    "                                            \"content\": \"What is 3.1415?\"\n",
    "                                        }],\n",
    "                                        stream=True)\n",
    "\n",
    "# Print the streaming response\n",
    "for chunk in stream:\n",
    "    if chunk.choices[0].delta.content is not None:\n",
    "        print(chunk.choices[0].delta.content, end=\"\", flush=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0cfb167e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatCompletion(id='chat.id.440', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content=\" The capital of France is Paris. It is not only the country'thy largest city but also serves as the political, cultural, and economic center of the nation. Paris is located in the northern part of France and is home to numerous iconic landmarks such as the Eiffel Tower, Louvre Museum, and Notre-Dame Cathedral. The city is also known for its significant influence on art, fashion, and cuisine. Paris has a rich history that dates back to the 3rd century and has been an important center for commerce and diplomacy for centuries. The city's status as a capital is further solidified by its role as the seat of the French government and the residence of the President of France.\", refusal=None, role='assistant', audio=None, function_call=None, tool_calls=[], name=None, tool_call_id=None), delta={'role': 'assistant', 'content': \" The capital of France is Paris. It is not only the country'thy largest city but also serves as the political, cultural, and economic center of the nation. Paris is located in the northern part of France and is home to numerous iconic landmarks such as the Eiffel Tower, Louvre Museum, and Notre-Dame Cathedral. The city is also known for its significant influence on art, fashion, and cuisine. Paris has a rich history that dates back to the 3rd century and has been an important center for commerce and diplomacy for centuries. The city's status as a capital is further solidified by its role as the seat of the French government and the residence of the President of France.\", 'name': None, 'tool_call_id': None, 'function_call': None, 'tool_calls': []}, finish_details=None)], created=1749490004, model=None, object='chat.completion', service_tier=None, system_fingerprint=None, usage=None, CreatedAt='2025-06-09T17:26:44+00:00', StreamEvent=None, IsDelta=False, Successful=True, error=None, HttpStatusCode=0, HeaderValues=None)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# No streaming mode\n",
    "resp = client.chat.completions.create(\n",
    "    model=manager.get_model_info(alias).id,\n",
    "    messages=[{\n",
    "        \"role\": \"user\",\n",
    "        \"content\": \"What is the capital of France?\"\n",
    "    }],\n",
    ")\n",
    "\n",
    "resp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "36411bd4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " The capital of France is Paris. It is not only the country'thy largest city but also serves as the political, cultural, and economic center of the nation. Paris is located in the northern part of France and is home to numerous iconic landmarks such as the Eiffel Tower, Louvre Museum, and Notre-Dame Cathedral. The city is also known for its significant influence on art, fashion, and cuisine. Paris has a rich history that dates back to the 3rd century and has been an important center for commerce and diplomacy for centuries. The city's status as a capital is further solidified by its role as the seat of the French government and the residence of the President of France.\n"
     ]
    }
   ],
   "source": [
    "print(resp.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b3ad7918",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Models in cache:\n",
      "[FoundryModelInfo(alias=phi-3.5-mini, id=Phi-3.5-mini-instruct-cuda-gpu, runtime=cuda, file_size=2181 MB, license=MIT)]\n"
     ]
    }
   ],
   "source": [
    "# List models in cache\n",
    "local_models = manager.list_cached_models()\n",
    "print(f\"Models in cache:\\n{local_models}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4e15d300",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of models in cache = 1\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of models in cache =\", len(local_models))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b2e3c526",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Models running in the service:\n",
      "[FoundryModelInfo(alias=phi-3.5-mini, id=Phi-3.5-mini-instruct-cuda-gpu, runtime=cuda, file_size=2181 MB, license=MIT), FoundryModelInfo(alias=phi-4-mini-reasoning, id=Phi-4-mini-reasoning-generic-cpu, runtime=cpu, file_size=4628 MB, license=MIT)]\n"
     ]
    }
   ],
   "source": [
    "# List loaded models\n",
    "loaded = manager.list_loaded_models()\n",
    "print(f\"Models running in the service:\\n{loaded}\")\n",
    "\n",
    "# Unload a model\n",
    "manager.unload_model(alias)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcee53e0",
   "metadata": {},
   "source": [
    "## Rest API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "2d261682",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Azure is a cloud computing platform and set of services offered by Microsoft. It provides a range of solutions including those for computing, storage, networking, databases, analytics, artificial intelligence, and Internet of Things (IoT). Azure enables users to build, deploy, and manage applications and services through a global network of Microsoft-managed data centers. With Azure, businesses and developers can build and run applications with the flexibility of the cloud, while also benefiting from the security, reliability, and scalability of Microsoft's infrastructure.\n"
     ]
    }
   ],
   "source": [
    "alias = \"mistralai-Mistral-7B-Instruct-v0-2-generic-cpu\"\n",
    "\n",
    "manager = FoundryLocalManager(alias)\n",
    "url = manager.endpoint + \"/chat/completions\"\n",
    "\n",
    "payload = {\n",
    "    \"model\": manager.get_model_info(alias).id,\n",
    "    \"messages\": [{\n",
    "        \"role\": \"user\",\n",
    "        \"content\": \"What is Azure?\",\n",
    "    }]\n",
    "}\n",
    "\n",
    "headers = {\"Content-Type\": \"application/json\"}\n",
    "\n",
    "response = requests.post(url, headers=headers, data=json.dumps(payload))\n",
    "print(response.json()[\"choices\"][0][\"message\"][\"content\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "177055da",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'model': None,\n",
       " 'choices': [{'delta': {'role': 'assistant',\n",
       "    'content': \" Azure is a cloud computing platform and set of services offered by Microsoft. It provides a range of solutions including those for computing, storage, networking, databases, analytics, artificial intelligence, and Internet of Things (IoT). Azure enables users to build, deploy, and manage applications and services through a global network of Microsoft-managed data centers. With Azure, businesses and developers can build and run applications with the flexibility of the cloud, while also benefiting from the security, reliability, and scalability of Microsoft's infrastructure.\",\n",
       "    'name': None,\n",
       "    'tool_call_id': None,\n",
       "    'function_call': None,\n",
       "    'tool_calls': []},\n",
       "   'message': {'role': 'assistant',\n",
       "    'content': \" Azure is a cloud computing platform and set of services offered by Microsoft. It provides a range of solutions including those for computing, storage, networking, databases, analytics, artificial intelligence, and Internet of Things (IoT). Azure enables users to build, deploy, and manage applications and services through a global network of Microsoft-managed data centers. With Azure, businesses and developers can build and run applications with the flexibility of the cloud, while also benefiting from the security, reliability, and scalability of Microsoft's infrastructure.\",\n",
       "    'name': None,\n",
       "    'tool_call_id': None,\n",
       "    'function_call': None,\n",
       "    'tool_calls': []},\n",
       "   'index': 0,\n",
       "   'finish_reason': 'stop',\n",
       "   'finish_details': None,\n",
       "   'logprobs': None}],\n",
       " 'usage': None,\n",
       " 'system_fingerprint': None,\n",
       " 'service_tier': None,\n",
       " 'created': 1749490123,\n",
       " 'CreatedAt': '2025-06-09T17:28:43+00:00',\n",
       " 'id': 'chat.id.441',\n",
       " 'StreamEvent': None,\n",
       " 'IsDelta': False,\n",
       " 'Successful': True,\n",
       " 'error': None,\n",
       " 'HttpStatusCode': 0,\n",
       " 'HeaderValues': None,\n",
       " 'object': 'chat.completion'}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "97681de9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Models in cache:\n",
      "[FoundryModelInfo(alias=mistral-7b-v0.2, id=mistralai-Mistral-7B-Instruct-v0-2-generic-cpu, runtime=cpu, file_size=4167 MB, license=apache-2.0), FoundryModelInfo(alias=phi-3.5-mini, id=Phi-3.5-mini-instruct-cuda-gpu, runtime=cuda, file_size=2181 MB, license=MIT)]\n"
     ]
    }
   ],
   "source": [
    "# List models in cache\n",
    "local_models = manager.list_cached_models()\n",
    "print(f\"Models in cache:\\n{local_models}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "fb490f26",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "alias='mistral-7b-v0.2' id='mistralai-Mistral-7B-Instruct-v0-2-generic-cpu' version='2' runtime=<ExecutionProvider.CPU: 'CPUExecutionProvider'> uri='azureml://registries/azureml/models/mistralai-Mistral-7B-Instruct-v0-2-generic-cpu/versions/2' file_size_mb=4167 prompt_template={'system': '<s>', 'user': '[INST]\\n{Content}\\n[/INST]', 'assistant': '{Content}</s>', 'prompt': '[INST]\\n{Content}\\n[/INST]'} provider='AzureFoundry' publisher='Microsoft' license='apache-2.0' task='chat-completion'\n",
      "\n",
      "alias='phi-3.5-mini' id='Phi-3.5-mini-instruct-cuda-gpu' version='1' runtime=<ExecutionProvider.CUDA: 'CUDAExecutionProvider'> uri='azureml://registries/azureml/models/Phi-3.5-mini-instruct-cuda-gpu/versions/1' file_size_mb=2181 prompt_template={'prompt': '<|user|>\\n{Content}<|end|>\\n<|assistant|>', 'assistant': '<|assistant|>\\n{Content}<|end|>'} provider='AzureFoundry' publisher='Microsoft' license='MIT' task='chat-completion'\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for idx in range(len(local_models)):\n",
    "    print(local_models[idx])\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "fe7f7f0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of models in cache = 2\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of models in cache =\", len(local_models))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7184eeb0",
   "metadata": {},
   "source": [
    "## CLI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "66353390",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Description:\n",
      "  Foundry Local CLI: Run AI models on your device.\n",
      "  \n",
      "   Getting started:\n",
      "  \n",
      "     1. To view available models: foundry model list\n",
      "     2. To run a model: foundry model run <model>\n",
      "  \n",
      "     EXAMPLES:\n",
      "         foundry model run phi-3-mini-4k\n",
      "\n",
      "Utilisation:\n",
      "  foundry [command] [options]\n",
      "\n",
      "Options:\n",
      "  -?, -h, --help  Show help and usage information\n",
      "  --version       Afficher les informations de version\n",
      "  --license       Display foudry license information\n",
      "\n",
      "Commandes:\n",
      "  model    Discover, run and manage models\n",
      "  cache    Manage the local cache\n",
      "  service  Manage the local model inference service\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!foundry -h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "621d6d28",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4.91+269dfd9ed1\n"
     ]
    }
   ],
   "source": [
    "!foundry --version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "e54e917b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Alias                          Device     Task               File Size    License      Model ID            \n",
      "-----------------------------------------------------------------------------------------------\n",
      "phi-4                          GPU        chat-completion    8.37 GB      MIT          Phi-4-cuda-gpu      \n",
      "                               GPU        chat-completion    8.37 GB      MIT          Phi-4-generic-gpu   \n",
      "                               CPU        chat-completion    10.16 GB     MIT          Phi-4-generic-cpu   \n",
      "--------------------------------------------------------------------------------------------------------\n",
      "phi-3-mini-128k                GPU        chat-completion    2.13 GB      MIT          Phi-3-mini-128k-instruct-cuda-gpu\n",
      "                               GPU        chat-completion    2.13 GB      MIT          Phi-3-mini-128k-instruct-generic-gpu\n",
      "                               CPU        chat-completion    2.54 GB      MIT          Phi-3-mini-128k-instruct-generic-cpu\n",
      "---------------------------------------------------------------------------------------------------------------------------\n",
      "phi-3-mini-4k                  GPU        chat-completion    2.13 GB      MIT          Phi-3-mini-4k-instruct-cuda-gpu\n",
      "                               GPU        chat-completion    2.13 GB      MIT          Phi-3-mini-4k-instruct-generic-gpu\n",
      "                               CPU        chat-completion    2.53 GB      MIT          Phi-3-mini-4k-instruct-generic-cpu\n",
      "-------------------------------------------------------------------------------------------------------------------------\n",
      "mistral-7b-v0.2                GPU        chat-completion    3.98 GB      apache-2.0   mistralai-Mistral-7B-Instruct-v0-2-cuda-gpu\n",
      "                               GPU        chat-completion    4.07 GB      apache-2.0   mistralai-Mistral-7B-Instruct-v0-2-generic-gpu\n",
      "                               CPU        chat-completion    4.07 GB      apache-2.0   mistralai-Mistral-7B-Instruct-v0-2-generic-cpu\n",
      "-------------------------------------------------------------------------------------------------------------------------------------\n",
      "phi-3.5-mini                   GPU        chat-completion    2.13 GB      MIT          Phi-3.5-mini-instruct-cuda-gpu\n",
      "                               GPU        chat-completion    2.16 GB      MIT          Phi-3.5-mini-instruct-generic-gpu\n",
      "                               CPU        chat-completion    2.53 GB      MIT          Phi-3.5-mini-instruct-generic-cpu\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "deepseek-r1-14b                GPU        chat-completion    9.83 GB      MIT          deepseek-r1-distill-qwen-14b-cuda-gpu\n",
      "                               GPU        chat-completion    10.27 GB     MIT          deepseek-r1-distill-qwen-14b-generic-gpu\n",
      "                               CPU        chat-completion    11.51 GB     MIT          deepseek-r1-distill-qwen-14b-generic-cpu\n",
      "-------------------------------------------------------------------------------------------------------------------------------\n",
      "deepseek-r1-7b                 GPU        chat-completion    5.28 GB      MIT          deepseek-r1-distill-qwen-7b-cuda-gpu\n",
      "                               GPU        chat-completion    5.58 GB      MIT          deepseek-r1-distill-qwen-7b-generic-gpu\n",
      "                               CPU        chat-completion    6.43 GB      MIT          deepseek-r1-distill-qwen-7b-generic-cpu\n",
      "------------------------------------------------------------------------------------------------------------------------------\n",
      "qwen2.5-0.5b                   GPU        chat-completion    0.52 GB      apache-2.0   qwen2.5-0.5b-instruct-cuda-gpu\n",
      "                               GPU        chat-completion    0.68 GB      apache-2.0   qwen2.5-0.5b-instruct-generic-gpu\n",
      "                               CPU        chat-completion    0.80 GB      apache-2.0   qwen2.5-0.5b-instruct-generic-cpu\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "qwen2.5-1.5b                   GPU        chat-completion    1.25 GB      apache-2.0   qwen2.5-1.5b-instruct-cuda-gpu\n",
      "                               GPU        chat-completion    1.51 GB      apache-2.0   qwen2.5-1.5b-instruct-generic-gpu\n",
      "                               CPU        chat-completion    1.78 GB      apache-2.0   qwen2.5-1.5b-instruct-generic-cpu\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "qwen2.5-coder-7b               GPU        chat-completion    4.73 GB      apache-2.0   qwen2.5-coder-7b-instruct-cuda-gpu\n",
      "                               GPU        chat-completion    4.73 GB      apache-2.0   qwen2.5-coder-7b-instruct-generic-gpu\n",
      "                               CPU        chat-completion    6.16 GB      apache-2.0   qwen2.5-coder-7b-instruct-generic-cpu\n",
      "----------------------------------------------------------------------------------------------------------------------------\n",
      "qwen2.5-coder-0.5b             GPU        chat-completion    0.52 GB      apache-2.0   qwen2.5-coder-0.5b-instruct-cuda-gpu\n",
      "                               GPU        chat-completion    0.52 GB      apache-2.0   qwen2.5-coder-0.5b-instruct-generic-gpu\n",
      "                               CPU        chat-completion    0.80 GB      apache-2.0   qwen2.5-coder-0.5b-instruct-generic-cpu\n",
      "------------------------------------------------------------------------------------------------------------------------------\n",
      "qwen2.5-coder-1.5b             GPU        chat-completion    1.25 GB      apache-2.0   qwen2.5-coder-1.5b-instruct-cuda-gpu\n",
      "                               GPU        chat-completion    1.25 GB      apache-2.0   qwen2.5-coder-1.5b-instruct-generic-gpu\n",
      "                               CPU        chat-completion    1.78 GB      apache-2.0   qwen2.5-coder-1.5b-instruct-generic-cpu\n",
      "------------------------------------------------------------------------------------------------------------------------------\n",
      "phi-4-mini                     GPU        chat-completion    3.60 GB      MIT          Phi-4-mini-instruct-cuda-gpu\n",
      "                               GPU        chat-completion    3.72 GB      MIT          Phi-4-mini-instruct-generic-gpu\n",
      "                               CPU        chat-completion    4.80 GB      MIT          Phi-4-mini-instruct-generic-cpu\n",
      "----------------------------------------------------------------------------------------------------------------------\n",
      "phi-4-mini-reasoning           GPU        chat-completion    3.15 GB      MIT          Phi-4-mini-reasoning-cuda-gpu\n",
      "                               GPU        chat-completion    3.15 GB      MIT          Phi-4-mini-reasoning-generic-gpu\n",
      "                               CPU        chat-completion    4.52 GB      MIT          Phi-4-mini-reasoning-generic-cpu\n",
      "-----------------------------------------------------------------------------------------------------------------------\n",
      "qwen2.5-14b                    GPU        chat-completion    8.79 GB      apache-2.0   qwen2.5-14b-instruct-cuda-gpu\n",
      "                               CPU        chat-completion    11.06 GB     apache-2.0   qwen2.5-14b-instruct-generic-cpu\n",
      "-----------------------------------------------------------------------------------------------------------------------\n",
      "qwen2.5-7b                     GPU        chat-completion    4.73 GB      apache-2.0   qwen2.5-7b-instruct-cuda-gpu\n",
      "                               GPU        chat-completion    5.20 GB      apache-2.0   qwen2.5-7b-instruct-generic-gpu\n",
      "                               CPU        chat-completion    6.16 GB      apache-2.0   qwen2.5-7b-instruct-generic-cpu\n",
      "----------------------------------------------------------------------------------------------------------------------\n",
      "qwen2.5-coder-14b              GPU        chat-completion    8.79 GB      apache-2.0   qwen2.5-coder-14b-instruct-cuda-gpu\n",
      "                               GPU        chat-completion    8.79 GB      apache-2.0   qwen2.5-coder-14b-instruct-generic-gpu\n",
      "                               CPU        chat-completion    11.06 GB     apache-2.0   qwen2.5-coder-14b-instruct-generic-cpu\n"
     ]
    }
   ],
   "source": [
    "!foundry model list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "93981275",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Alias                          Device     Task               File Size    License      Model ID            \n",
      "phi-4-mini-reasoning           GPU        chat-completion    3.15 GB      MIT          Phi-4-mini-reasoning-cuda-gpu\n"
     ]
    }
   ],
   "source": [
    "!foundry model info phi-4-mini-reasoning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "71c01724",
   "metadata": {},
   "outputs": [],
   "source": [
    "!foundry service restart"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "ffe21281",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Restarting service...\n",
      " Service is stopped.\n",
      " Service is Started on http://localhost:5273, PID 17624!\n",
      " Service is stopped.\n"
     ]
    }
   ],
   "source": [
    "!foundry service stop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cef3dd2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
