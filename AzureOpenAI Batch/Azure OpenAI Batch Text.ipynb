{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5b570f64",
   "metadata": {},
   "source": [
    "# Azure OpenAI Batch Text\n",
    "\n",
    "The Azure OpenAI Batch API is designed to handle large-scale and high-volume processing tasks efficiently. **Process asynchronous groups of requests with separate quota, with 24-hour target turnaround, at 50% less cost than global standard.** With batch processing, rather than send one request at a time you send a large number of requests in a single file. Global batch requests have a separate enqueued token quota avoiding any disruption of your online workloads.\n",
    "\n",
    "Key use cases include:\n",
    "- Large-Scale Data Processing: Quickly analyze extensive datasets in parallel.\n",
    "- Content Generation: Create large volumes of text, such as product descriptions or articles.\n",
    "- Document Review and Summarization: Automate the review and summarization of lengthy documents.\n",
    "- Customer Support Automation: Handle numerous queries simultaneously for faster responses.\n",
    "- Data Extraction and Analysis: Extract and analyze information from vast amounts of unstructured data.\n",
    "- Natural Language Processing (NLP) Tasks: Perform tasks like sentiment analysis or translation on large datasets.\n",
    "- Marketing and Personalization: Generate personalized content and recommendations at scale.\n",
    "\n",
    "https://learn.microsoft.com/en-us/azure/ai-services/openai/how-to/batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0fac5af4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "import json\n",
    "import openai\n",
    "import os\n",
    "import sys\n",
    "import time\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "from openai import AzureOpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2733de3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python version: 3.10.11 (main, May 16 2023, 00:28:57) [GCC 11.2.0]\n",
      "OpenAI version: 1.43.0\n"
     ]
    }
   ],
   "source": [
    "print(f\"Python version: {sys.version}\")\n",
    "print(f\"OpenAI version: {openai.__version__}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "33fb0028",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Today is 06-Sep-2024 08:41:33\n"
     ]
    }
   ],
   "source": [
    "print(f\"Today is {datetime.datetime.today().strftime('%d-%b-%Y %H:%M:%S')}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d8eb392",
   "metadata": {},
   "source": [
    "## Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3985cdba",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv(\"azure.env\")\n",
    "\n",
    "# Azure OpenAI\n",
    "AZURE_OPENAI_API_ENDPOINT: str = os.getenv(\"AZURE_OPENAI_API_ENDPOINT\")\n",
    "AZURE_OPENAI_API_KEY: str = os.getenv(\"AZURE_OPENAI_API_KEY\")\n",
    "\n",
    "# Azure OpenAI batch model\n",
    "AOAI_BATCH_MODEL: str = \"gpt-4o-batch\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8fb6af0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "JSONL_DIR = \"jsonl\"\n",
    "RESULTS_DIR = \"results\"\n",
    "\n",
    "os.makedirs(JSONL_DIR, exist_ok=True)\n",
    "os.makedirs(RESULTS_DIR, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0ed039c",
   "metadata": {},
   "source": [
    "## Creating some prompts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f68f398d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Hello. Who are you?',\n",
       " 'What is Azure OpenAI?',\n",
       " 'What are Arima models?',\n",
       " \"Translate this from English to French: 'Welcome'\"]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompts = [\n",
    "    \"Hello. Who are you?\",\n",
    "    \"What is Azure OpenAI?\",\n",
    "    \"What are Arima models?\",\n",
    "    \"Translate this from English to French: 'Welcome'\",\n",
    "]\n",
    "\n",
    "prompts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6e69c9fc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(prompts)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3bff504",
   "metadata": {},
   "source": [
    "## Creating the jsonl input file for batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bd8bc24c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# File to create\n",
    "jsonlfile = os.path.join(JSONL_DIR, \"batch_text.jsonl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c00db6e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "JSONL file jsonl/batch_text.jsonl created successfully.\n"
     ]
    }
   ],
   "source": [
    "# Define the structure template\n",
    "template = {\n",
    "    \"custom_id\": \"\",\n",
    "    \"method\": \"POST\",\n",
    "    \"url\": \"/chat/completions\",\n",
    "    \"body\": {\n",
    "        \"model\":\n",
    "        AOAI_BATCH_MODEL,\n",
    "        \"messages\": [{\n",
    "            \"role\": \"system\",\n",
    "            \"content\": \"You are an AI assistant that helps people find information.\"\n",
    "        }, {\n",
    "            \"role\": \"user\", \"content\": \"\"\n",
    "        }]\n",
    "    }\n",
    "}\n",
    "\n",
    "# Generate the JSONL content\n",
    "jsonl_content = \"\"\n",
    "\n",
    "for i, prompt in enumerate(prompts):\n",
    "    entry = template.copy()\n",
    "    entry[\"custom_id\"] = f\"task-{i}\"\n",
    "    entry[\"body\"][\"messages\"][1][\"content\"] = prompt\n",
    "    jsonl_content += json.dumps(entry) + \"\\n\"\n",
    "\n",
    "# Write to a file\n",
    "with open(jsonlfile, \"w\") as file:\n",
    "    file.write(jsonl_content)\n",
    "\n",
    "print(f\"JSONL file {jsonlfile} created successfully.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "54939da1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-rwxrwxrwx 1 root root 1.1K Sep  6 08:41 jsonl/batch_text.jsonl\r\n"
     ]
    }
   ],
   "source": [
    "!ls $jsonlfile -lh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4421c9b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"custom_id\": \"task-0\", \"method\": \"POST\", \"url\": \"/chat/completions\", \"body\": {\"model\": \"gpt-4o-batch\", \"messages\": [{\"role\": \"system\", \"content\": \"You are an AI assistant that helps people find information.\"}, {\"role\": \"user\", \"content\": \"Hello. Who are you?\"}]}}\n",
      "{\"custom_id\": \"task-1\", \"method\": \"POST\", \"url\": \"/chat/completions\", \"body\": {\"model\": \"gpt-4o-batch\", \"messages\": [{\"role\": \"system\", \"content\": \"You are an AI assistant that helps people find information.\"}, {\"role\": \"user\", \"content\": \"What is Azure OpenAI?\"}]}}\n",
      "{\"custom_id\": \"task-2\", \"method\": \"POST\", \"url\": \"/chat/completions\", \"body\": {\"model\": \"gpt-4o-batch\", \"messages\": [{\"role\": \"system\", \"content\": \"You are an AI assistant that helps people find information.\"}, {\"role\": \"user\", \"content\": \"What are Arima models?\"}]}}\n",
      "{\"custom_id\": \"task-3\", \"method\": \"POST\", \"url\": \"/chat/completions\", \"body\": {\"model\": \"gpt-4o-batch\", \"messages\": [{\"role\": \"system\", \"content\": \"You are an AI assistant that helps people find information.\"}, {\"role\": \"user\", \"content\": \"Translate this from English to French: 'Welcome'\"}]}}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(jsonl_content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc4f9f54",
   "metadata": {},
   "source": [
    "## Azure OpenAI client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "87c00aca",
   "metadata": {},
   "outputs": [],
   "source": [
    "client = AzureOpenAI(\n",
    "    api_key=AZURE_OPENAI_API_KEY,\n",
    "    api_version=\"2024-07-01-preview\",\n",
    "    azure_endpoint=AZURE_OPENAI_API_ENDPOINT,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34df5b9c",
   "metadata": {},
   "source": [
    "## Upload batch file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a785af43",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;34m\n",
      "{\n",
      "  \"id\": \"file-8f12ac7ee99c4401acecee44f87f4de3\",\n",
      "  \"bytes\": 1094,\n",
      "  \"created_at\": 1725612095,\n",
      "  \"filename\": \"batch_text.jsonl\",\n",
      "  \"object\": \"file\",\n",
      "  \"purpose\": \"batch\",\n",
      "  \"status\": \"pending\",\n",
      "  \"status_details\": null\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# Upload a file with a purpose of \"batch\"\n",
    "file = client.files.create(file=open(jsonlfile, \"rb\"), purpose=\"batch\")\n",
    "\n",
    "print(\"\\033[1;34m\")\n",
    "print(file.model_dump_json(indent=2))\n",
    "file_id = file.id"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "113a8124",
   "metadata": {},
   "source": [
    "## Track file upload status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b3a5c8f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;34m\n",
      "2024-09-06 08:41:36.815144 | File Id: file-8f12ac7ee99c4401acecee44f87f4de3 | Status: running\n",
      "2024-09-06 08:41:37.939146 | File Id: file-8f12ac7ee99c4401acecee44f87f4de3 | Status: processed\n",
      "2024-09-06 08:41:37.939399 End\n"
     ]
    }
   ],
   "source": [
    "# Wait until the uploaded file is in processed state\n",
    "status = \"pending\"\n",
    "\n",
    "print(\"\\033[1;34m\")\n",
    "\n",
    "while status != \"processed\":\n",
    "    time.sleep(1)\n",
    "    file_response = client.files.retrieve(file_id)\n",
    "    status = file_response.status\n",
    "    print(f\"{datetime.datetime.now()} | File Id: {file_id} | Status: {status}\")\n",
    "\n",
    "print(f\"{datetime.datetime.now()} End\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cbcdfa7",
   "metadata": {},
   "source": [
    "## Create batch job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7c2ac242",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;34m\n",
      "{\n",
      "  \"id\": \"batch_4bc6fc5e-3b0f-4ddf-936a-ef1b204977da\",\n",
      "  \"completion_window\": \"24h\",\n",
      "  \"created_at\": 1725612098,\n",
      "  \"endpoint\": \"/chat/completions\",\n",
      "  \"input_file_id\": \"file-8f12ac7ee99c4401acecee44f87f4de3\",\n",
      "  \"object\": \"batch\",\n",
      "  \"status\": \"validating\",\n",
      "  \"cancelled_at\": null,\n",
      "  \"cancelling_at\": null,\n",
      "  \"completed_at\": null,\n",
      "  \"error_file_id\": null,\n",
      "  \"errors\": null,\n",
      "  \"expired_at\": null,\n",
      "  \"expires_at\": 1725698498,\n",
      "  \"failed_at\": null,\n",
      "  \"finalizing_at\": null,\n",
      "  \"in_progress_at\": null,\n",
      "  \"metadata\": null,\n",
      "  \"output_file_id\": null,\n",
      "  \"request_counts\": {\n",
      "    \"completed\": 0,\n",
      "    \"failed\": 0,\n",
      "    \"total\": 0\n",
      "  }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# Submit a batch job with the file\n",
    "batch_response = client.batches.create(\n",
    "    input_file_id=file_id,\n",
    "    endpoint=\"/chat/completions\",\n",
    "    completion_window=\"24h\",\n",
    ")\n",
    "\n",
    "# Save batch ID for later use\n",
    "batch_id = batch_response.id\n",
    "\n",
    "print(\"\\033[1;34m\")\n",
    "print(batch_response.model_dump_json(indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f03348a3",
   "metadata": {},
   "source": [
    "## Track batch job progress"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2b7a7345",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;30m2024-09-06 08:42:09.076954 | Batch Id: batch_4bc6fc5e-3b0f-4ddf-936a-ef1b204977da | Status: validating\n",
      "\u001b[1;31;30m2024-09-06 08:42:39.510865 | Batch Id: batch_4bc6fc5e-3b0f-4ddf-936a-ef1b204977da | Status: validating\n",
      "\u001b[1;31;30m2024-09-06 08:43:10.001034 | Batch Id: batch_4bc6fc5e-3b0f-4ddf-936a-ef1b204977da | Status: validating\n",
      "\u001b[1;31;30m2024-09-06 08:43:40.440202 | Batch Id: batch_4bc6fc5e-3b0f-4ddf-936a-ef1b204977da | Status: validating\n",
      "\u001b[1;31;30m2024-09-06 08:44:11.015461 | Batch Id: batch_4bc6fc5e-3b0f-4ddf-936a-ef1b204977da | Status: validating\n",
      "\u001b[1;31;34m2024-09-06 08:44:41.618230 | Batch Id: batch_4bc6fc5e-3b0f-4ddf-936a-ef1b204977da | Status: in_progress\n",
      "\u001b[1;31;34m2024-09-06 08:45:12.109175 | Batch Id: batch_4bc6fc5e-3b0f-4ddf-936a-ef1b204977da | Status: in_progress\n",
      "\u001b[1;31;34m2024-09-06 08:45:42.586080 | Batch Id: batch_4bc6fc5e-3b0f-4ddf-936a-ef1b204977da | Status: in_progress\n",
      "\u001b[1;31;34m2024-09-06 08:46:13.102200 | Batch Id: batch_4bc6fc5e-3b0f-4ddf-936a-ef1b204977da | Status: in_progress\n",
      "\u001b[1;31;34m2024-09-06 08:46:43.659903 | Batch Id: batch_4bc6fc5e-3b0f-4ddf-936a-ef1b204977da | Status: in_progress\n",
      "\u001b[1;31;34m2024-09-06 08:47:14.144774 | Batch Id: batch_4bc6fc5e-3b0f-4ddf-936a-ef1b204977da | Status: in_progress\n",
      "\u001b[1;31;34m2024-09-06 08:47:44.651205 | Batch Id: batch_4bc6fc5e-3b0f-4ddf-936a-ef1b204977da | Status: in_progress\n",
      "\u001b[1;31;34m2024-09-06 08:48:15.118611 | Batch Id: batch_4bc6fc5e-3b0f-4ddf-936a-ef1b204977da | Status: in_progress\n",
      "\u001b[1;31;34m2024-09-06 08:48:45.753146 | Batch Id: batch_4bc6fc5e-3b0f-4ddf-936a-ef1b204977da | Status: in_progress\n",
      "\u001b[1;31;34m2024-09-06 08:49:16.445617 | Batch Id: batch_4bc6fc5e-3b0f-4ddf-936a-ef1b204977da | Status: in_progress\n",
      "\u001b[1;31;32m2024-09-06 08:49:47.029227 | Batch Id: batch_4bc6fc5e-3b0f-4ddf-936a-ef1b204977da | Status: finalizing\n",
      "\u001b[1;31;32m2024-09-06 08:50:17.548062 | Batch Id: batch_4bc6fc5e-3b0f-4ddf-936a-ef1b204977da | Status: finalizing\n",
      "\u001b[1;31;32m2024-09-06 08:50:48.217257 | Batch Id: batch_4bc6fc5e-3b0f-4ddf-936a-ef1b204977da | Status: finalizing\n",
      "\u001b[1;31;35m2024-09-06 08:51:18.754962 | Batch Id: batch_4bc6fc5e-3b0f-4ddf-936a-ef1b204977da | Status: completed\n",
      "\u001b[0m\n",
      "Elapsed time = 9 minutes and 40 seconds\n"
     ]
    }
   ],
   "source": [
    "status = \"validating\"\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "status_colors = {\n",
    "    \"validating\": \"\\033[1;31;30m\",\n",
    "    \"in_progress\": \"\\033[1;31;34m\",\n",
    "    \"finalizing\": \"\\033[1;31;32m\",\n",
    "    \"completed\": \"\\033[1;31;35m\",\n",
    "}\n",
    "\n",
    "while status not in (\"completed\", \"failed\", \"canceled\"):\n",
    "    time.sleep(30)\n",
    "    batch_response = client.batches.retrieve(batch_id)\n",
    "    status = batch_response.status\n",
    "    print(status_colors.get(status, \"\"), end=\"\")\n",
    "    print(f\"{datetime.datetime.now()} | Batch Id: {batch_id} | Status: {status}\")\n",
    "\n",
    "elapsed = time.time() - start\n",
    "minutes, seconds = divmod(elapsed, 60)\n",
    "print(\"\\033[0m\")\n",
    "print(f\"Elapsed time = {minutes:.0f} minutes and {seconds:.0f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e5752978",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;34m\n",
      "{\n",
      "     \"id\": \"batch_4bc6fc5e-3b0f-4ddf-936a-ef1b204977da\",\n",
      "     \"completion_window\": \"24h\",\n",
      "     \"created_at\": 1725612098,\n",
      "     \"endpoint\": \"/chat/completions\",\n",
      "     \"input_file_id\": \"file-8f12ac7ee99c4401acecee44f87f4de3\",\n",
      "     \"object\": \"batch\",\n",
      "     \"status\": \"completed\",\n",
      "     \"cancelled_at\": null,\n",
      "     \"cancelling_at\": null,\n",
      "     \"completed_at\": 1725612667,\n",
      "     \"error_file_id\": \"file-f6d1e15b-7ccb-45d9-b475-e5bbb4e582aa\",\n",
      "     \"errors\": null,\n",
      "     \"expired_at\": null,\n",
      "     \"expires_at\": 1725698498,\n",
      "     \"failed_at\": null,\n",
      "     \"finalizing_at\": 1725612572,\n",
      "     \"in_progress_at\": 1725612334,\n",
      "     \"metadata\": null,\n",
      "     \"output_file_id\": \"file-e6b599e3-577e-46be-8e10-dc0ca12c1e5d\",\n",
      "     \"request_counts\": {\n",
      "          \"completed\": 4,\n",
      "          \"failed\": 0,\n",
      "          \"total\": 4\n",
      "     }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "print(\"\\033[1;34m\")\n",
    "print(batch_response.model_dump_json(indent=5))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "000e8940",
   "metadata": {},
   "source": [
    "## Retrieve batch job output file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b00e4bd5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "OutputArea.auto_scroll_threshold = 9999\n"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%javascript Python\n",
    "OutputArea.auto_scroll_threshold = 9999"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0f3f7f50",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;34m\n",
      "{\n",
      "     \"custom_id\": \"task-3\",\n",
      "     \"response\": {\n",
      "          \"body\": {\n",
      "               \"choices\": [\n",
      "                    {\n",
      "                         \"content_filter_results\": {\n",
      "                              \"hate\": {\n",
      "                                   \"filtered\": false,\n",
      "                                   \"severity\": \"safe\"\n",
      "                              },\n",
      "                              \"protected_material_code\": {\n",
      "                                   \"filtered\": false,\n",
      "                                   \"detected\": false\n",
      "                              },\n",
      "                              \"protected_material_text\": {\n",
      "                                   \"filtered\": false,\n",
      "                                   \"detected\": false\n",
      "                              },\n",
      "                              \"self_harm\": {\n",
      "                                   \"filtered\": false,\n",
      "                                   \"severity\": \"safe\"\n",
      "                              },\n",
      "                              \"sexual\": {\n",
      "                                   \"filtered\": false,\n",
      "                                   \"severity\": \"safe\"\n",
      "                              },\n",
      "                              \"violence\": {\n",
      "                                   \"filtered\": false,\n",
      "                                   \"severity\": \"safe\"\n",
      "                              }\n",
      "                         },\n",
      "                         \"finish_reason\": \"stop\",\n",
      "                         \"index\": 0,\n",
      "                         \"logprobs\": null,\n",
      "                         \"message\": {\n",
      "                              \"content\": \"The French translation for 'Welcome' is 'Bienvenue'.\",\n",
      "                              \"role\": \"assistant\"\n",
      "                         }\n",
      "                    }\n",
      "               ],\n",
      "               \"created\": 1725612365,\n",
      "               \"id\": \"chatcmpl-A4OtRllzk4Htaz8jcrYCE5RbM0be1\",\n",
      "               \"model\": \"gpt-4o-2024-05-13\",\n",
      "               \"object\": \"chat.completion\",\n",
      "               \"prompt_filter_results\": [\n",
      "                    {\n",
      "                         \"prompt_index\": 0,\n",
      "                         \"content_filter_results\": {\n",
      "                              \"hate\": {\n",
      "                                   \"filtered\": false,\n",
      "                                   \"severity\": \"safe\"\n",
      "                              },\n",
      "                              \"jailbreak\": {\n",
      "                                   \"filtered\": false,\n",
      "                                   \"detected\": false\n",
      "                              },\n",
      "                              \"self_harm\": {\n",
      "                                   \"filtered\": false,\n",
      "                                   \"severity\": \"safe\"\n",
      "                              },\n",
      "                              \"sexual\": {\n",
      "                                   \"filtered\": false,\n",
      "                                   \"severity\": \"safe\"\n",
      "                              },\n",
      "                              \"violence\": {\n",
      "                                   \"filtered\": false,\n",
      "                                   \"severity\": \"safe\"\n",
      "                              }\n",
      "                         }\n",
      "                    }\n",
      "               ],\n",
      "               \"system_fingerprint\": \"fp_f5a70d8dc9\",\n",
      "               \"usage\": {\n",
      "                    \"completion_tokens\": 11,\n",
      "                    \"prompt_tokens\": 32,\n",
      "                    \"total_tokens\": 43\n",
      "               }\n",
      "          },\n",
      "          \"request_id\": \"fcd9ae0b-7585-41ea-ad7a-7af13485aa57\",\n",
      "          \"status_code\": 200\n",
      "     },\n",
      "     \"error\": null\n",
      "}\n",
      "{\n",
      "     \"custom_id\": \"task-0\",\n",
      "     \"response\": {\n",
      "          \"body\": {\n",
      "               \"choices\": [\n",
      "                    {\n",
      "                         \"content_filter_results\": {\n",
      "                              \"hate\": {\n",
      "                                   \"filtered\": false,\n",
      "                                   \"severity\": \"safe\"\n",
      "                              },\n",
      "                              \"self_harm\": {\n",
      "                                   \"filtered\": false,\n",
      "                                   \"severity\": \"safe\"\n",
      "                              },\n",
      "                              \"sexual\": {\n",
      "                                   \"filtered\": false,\n",
      "                                   \"severity\": \"safe\"\n",
      "                              },\n",
      "                              \"violence\": {\n",
      "                                   \"filtered\": false,\n",
      "                                   \"severity\": \"safe\"\n",
      "                              }\n",
      "                         },\n",
      "                         \"finish_reason\": \"stop\",\n",
      "                         \"index\": 0,\n",
      "                         \"logprobs\": null,\n",
      "                         \"message\": {\n",
      "                              \"content\": \"Hello! I'm an AI assistant here to help you find information, answer questions, and provide assistance with various topics. How can I help you today?\",\n",
      "                              \"role\": \"assistant\"\n",
      "                         }\n",
      "                    }\n",
      "               ],\n",
      "               \"created\": 1725612365,\n",
      "               \"id\": \"chatcmpl-A4OtRcvA2ev3xepGZSSA3g35calzK\",\n",
      "               \"model\": \"gpt-4o-2024-05-13\",\n",
      "               \"object\": \"chat.completion\",\n",
      "               \"prompt_filter_results\": [\n",
      "                    {\n",
      "                         \"prompt_index\": 0,\n",
      "                         \"content_filter_results\": {\n",
      "                              \"hate\": {\n",
      "                                   \"filtered\": false,\n",
      "                                   \"severity\": \"safe\"\n",
      "                              },\n",
      "                              \"jailbreak\": {\n",
      "                                   \"filtered\": false,\n",
      "                                   \"detected\": false\n",
      "                              },\n",
      "                              \"self_harm\": {\n",
      "                                   \"filtered\": false,\n",
      "                                   \"severity\": \"safe\"\n",
      "                              },\n",
      "                              \"sexual\": {\n",
      "                                   \"filtered\": false,\n",
      "                                   \"severity\": \"safe\"\n",
      "                              },\n",
      "                              \"violence\": {\n",
      "                                   \"filtered\": false,\n",
      "                                   \"severity\": \"safe\"\n",
      "                              }\n",
      "                         }\n",
      "                    }\n",
      "               ],\n",
      "               \"system_fingerprint\": \"fp_f5a70d8dc9\",\n",
      "               \"usage\": {\n",
      "                    \"completion_tokens\": 30,\n",
      "                    \"prompt_tokens\": 28,\n",
      "                    \"total_tokens\": 58\n",
      "               }\n",
      "          },\n",
      "          \"request_id\": \"1ad7aff5-f89f-4a1b-ab81-4e56cc426ee3\",\n",
      "          \"status_code\": 200\n",
      "     },\n",
      "     \"error\": null\n",
      "}\n",
      "{\n",
      "     \"custom_id\": \"task-1\",\n",
      "     \"response\": {\n",
      "          \"body\": {\n",
      "               \"choices\": [\n",
      "                    {\n",
      "                         \"content_filter_results\": {\n",
      "                              \"hate\": {\n",
      "                                   \"filtered\": false,\n",
      "                                   \"severity\": \"safe\"\n",
      "                              },\n",
      "                              \"protected_material_code\": {\n",
      "                                   \"filtered\": false,\n",
      "                                   \"detected\": false\n",
      "                              },\n",
      "                              \"protected_material_text\": {\n",
      "                                   \"filtered\": false,\n",
      "                                   \"detected\": false\n",
      "                              },\n",
      "                              \"self_harm\": {\n",
      "                                   \"filtered\": false,\n",
      "                                   \"severity\": \"safe\"\n",
      "                              },\n",
      "                              \"sexual\": {\n",
      "                                   \"filtered\": false,\n",
      "                                   \"severity\": \"safe\"\n",
      "                              },\n",
      "                              \"violence\": {\n",
      "                                   \"filtered\": false,\n",
      "                                   \"severity\": \"safe\"\n",
      "                              }\n",
      "                         },\n",
      "                         \"finish_reason\": \"stop\",\n",
      "                         \"index\": 0,\n",
      "                         \"logprobs\": null,\n",
      "                         \"message\": {\n",
      "                              \"content\": \"Azure OpenAI is a service provided by Microsoft Azure that offers access to OpenAI's sophisticated language models, such as GPT-3, through Azure's cloud platform. This service allows developers, enterprises, and data scientists to incorporate advanced artificial intelligence capabilities into their applications more easily and securely. \\n\\nKey features of Azure OpenAI include:\\n\\n1. **Integration with Azure Services**: Seamlessly integrates with other Azure services, providing robust infrastructure, easy scalability, and enhanced security features.\\n\\n2. **API Accessibility**: Provides APIs that developers can use to integrate OpenAI's models into their applications, enabling functionalities like natural language understanding, text generation, translation, summarization, and more.\\n\\n3. **Enterprise-grade Security and Compliance**: Combines OpenAI's machine learning capabilities with Azure\\u2019s industry-leading security, compliance, and enterprise-grade support.\\n\\n4. **Customizability**: Allows for fine-tuning and customizing AI models to better fit specific use cases or industries.\\n\\n5. **Scalability**: Takes advantage of Azure's global scalability to handle the computational requirements of deploying large language models.\\n\\nAzure OpenAI aims to democratize access to powerful AI models, enabling organizations to build innovative solutions with advanced capabilities in natural language processing and understanding.\\n\\nFor more detailed information, you can visit the official Azure OpenAI service page on Microsoft Azure's website.\",\n",
      "                              \"role\": \"assistant\"\n",
      "                         }\n",
      "                    }\n",
      "               ],\n",
      "               \"created\": 1725612365,\n",
      "               \"id\": \"chatcmpl-A4OtR725Q46eP7ZTCLoLpVBjx03bJ\",\n",
      "               \"model\": \"gpt-4o-2024-05-13\",\n",
      "               \"object\": \"chat.completion\",\n",
      "               \"prompt_filter_results\": [\n",
      "                    {\n",
      "                         \"prompt_index\": 0,\n",
      "                         \"content_filter_results\": {\n",
      "                              \"hate\": {\n",
      "                                   \"filtered\": false,\n",
      "                                   \"severity\": \"safe\"\n",
      "                              },\n",
      "                              \"jailbreak\": {\n",
      "                                   \"filtered\": false,\n",
      "                                   \"detected\": false\n",
      "                              },\n",
      "                              \"self_harm\": {\n",
      "                                   \"filtered\": false,\n",
      "                                   \"severity\": \"safe\"\n",
      "                              },\n",
      "                              \"sexual\": {\n",
      "                                   \"filtered\": false,\n",
      "                                   \"severity\": \"safe\"\n",
      "                              },\n",
      "                              \"violence\": {\n",
      "                                   \"filtered\": false,\n",
      "                                   \"severity\": \"safe\"\n",
      "                              }\n",
      "                         }\n",
      "                    }\n",
      "               ],\n",
      "               \"system_fingerprint\": \"fp_f5a70d8dc9\",\n",
      "               \"usage\": {\n",
      "                    \"completion_tokens\": 270,\n",
      "                    \"prompt_tokens\": 28,\n",
      "                    \"total_tokens\": 298\n",
      "               }\n",
      "          },\n",
      "          \"request_id\": \"8aa6621b-0a76-4a65-b90a-f0f709679076\",\n",
      "          \"status_code\": 200\n",
      "     },\n",
      "     \"error\": null\n",
      "}\n",
      "{\n",
      "     \"custom_id\": \"task-2\",\n",
      "     \"response\": {\n",
      "          \"body\": {\n",
      "               \"choices\": [\n",
      "                    {\n",
      "                         \"content_filter_results\": {\n",
      "                              \"hate\": {\n",
      "                                   \"filtered\": false,\n",
      "                                   \"severity\": \"safe\"\n",
      "                              },\n",
      "                              \"protected_material_code\": {\n",
      "                                   \"filtered\": false,\n",
      "                                   \"detected\": false\n",
      "                              },\n",
      "                              \"protected_material_text\": {\n",
      "                                   \"filtered\": false,\n",
      "                                   \"detected\": false\n",
      "                              },\n",
      "                              \"self_harm\": {\n",
      "                                   \"filtered\": false,\n",
      "                                   \"severity\": \"safe\"\n",
      "                              },\n",
      "                              \"sexual\": {\n",
      "                                   \"filtered\": false,\n",
      "                                   \"severity\": \"safe\"\n",
      "                              },\n",
      "                              \"violence\": {\n",
      "                                   \"filtered\": false,\n",
      "                                   \"severity\": \"safe\"\n",
      "                              }\n",
      "                         },\n",
      "                         \"finish_reason\": \"stop\",\n",
      "                         \"index\": 0,\n",
      "                         \"logprobs\": null,\n",
      "                         \"message\": {\n",
      "                              \"content\": \"ARIMA models, which stand for AutoRegressive Integrated Moving Average models, are a class of statistical models for analyzing and forecasting time series data. They are particularly useful for data that shows evidence of non-stationarity, where things like the mean and variance change over time.\\n\\nHere's a breakdown of the components:\\n\\n1. **Autoregressive (AR) part**: This refers to a model that uses the dependent relationship between an observation and a number of lagged observations (i.e., previous time steps).\\n   \\n2. **Integrated (I) part**: This represents the differencing of raw observations to make the time series stationary (i.e., to remove trends and seasonality).\\n\\n3. **Moving Average (MA) part**: This incorporates the dependency between an observation and a residual error from a moving average model applied to lagged observations.\\n\\nThe model is usually denoted as ARIMA(p, d, q):\\n\\n- **p**: the number of lag observations included in the model (i.e., the number of terms in the AR part).\\n- **d**: the number of times that the raw observations are differenced.\\n- **q**: the size of the moving average window (i.e., the number of terms in the MA part).\\n\\n### Steps to Build an ARIMA Model\\n\\n1. **Identification**: The first step is to make the time series stationary. You can use the Augmented Dickey-Fuller test to check stationarity and apply differencing if necessary.\\n   \\n2. **Parameter Estimation**: Once stationarity is achieved, you will choose the values of p, d, and q that minimize the error. Information criteria like AIC (Akaike Information Criterion) or BIC (Bayesian Information Criterion) are often used.\\n\\n3. **Model Fitting**: Using statistical software, you will fit the ARIMA model to the data.\\n\\n4. **Diagnostics**: After fitting the model, it's crucial to check the residuals (errors) of the model to ensure no patterns are left unexplained.\\n\\n5. **Forecasting**: Once satisfied with the model's fit, you can use it to make forecasts.\\n\\n### Applications\\n\\nARIMA models are widely used in finance (such as stock price forecasting), economics (like GDP and inflation prediction), climatology (weather forecasts), and any other domain where time series analysis is relevant.\\n\\n### Software for ARIMA\\n\\nMany statistical software packages support ARIMA modeling, such as:\\n\\n- R (using the `forecast` and `TSA` packages)\\n- Python (using the `statsmodels` library)\\n- SAS\\n- SPSS\\n- EViews\\n\\n### Advantages\\n\\n- Flexibility: ARIMA models can handle various types of time series data.\\n- Comprehensive: By combining AR and MA components with differencing, ARIMA can model a wide range of time series patterns.\\n\\n### Limitations\\n\\n- Complexity: Identifying the correct values for p, d, and q can be challenging.\\n- Stationarity Requirement: The time series must be made stationary before modeling.\\n- Data Requirement: ARIMA needs a sufficiently large dataset to provide good forecasts.\\n\\nOverall, ARIMA models are a powerful tool for time series forecasting, especially when data exhibits complex patterns that simpler models can't capture.\",\n",
      "                              \"role\": \"assistant\"\n",
      "                         }\n",
      "                    }\n",
      "               ],\n",
      "               \"created\": 1725612365,\n",
      "               \"id\": \"chatcmpl-A4OtRqwX45GCAktWjdPNtIZ3pC4Ob\",\n",
      "               \"model\": \"gpt-4o-2024-05-13\",\n",
      "               \"object\": \"chat.completion\",\n",
      "               \"prompt_filter_results\": [\n",
      "                    {\n",
      "                         \"prompt_index\": 0,\n",
      "                         \"content_filter_results\": {\n",
      "                              \"hate\": {\n",
      "                                   \"filtered\": false,\n",
      "                                   \"severity\": \"safe\"\n",
      "                              },\n",
      "                              \"jailbreak\": {\n",
      "                                   \"filtered\": false,\n",
      "                                   \"detected\": false\n",
      "                              },\n",
      "                              \"self_harm\": {\n",
      "                                   \"filtered\": false,\n",
      "                                   \"severity\": \"safe\"\n",
      "                              },\n",
      "                              \"sexual\": {\n",
      "                                   \"filtered\": false,\n",
      "                                   \"severity\": \"safe\"\n",
      "                              },\n",
      "                              \"violence\": {\n",
      "                                   \"filtered\": false,\n",
      "                                   \"severity\": \"safe\"\n",
      "                              }\n",
      "                         }\n",
      "                    }\n",
      "               ],\n",
      "               \"system_fingerprint\": \"fp_f5a70d8dc9\",\n",
      "               \"usage\": {\n",
      "                    \"completion_tokens\": 661,\n",
      "                    \"prompt_tokens\": 28,\n",
      "                    \"total_tokens\": 689\n",
      "               }\n",
      "          },\n",
      "          \"request_id\": \"7111efb3-048f-43cc-994f-497b6c8eee33\",\n",
      "          \"status_code\": 200\n",
      "     },\n",
      "     \"error\": null\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# Retrieve the file content\n",
    "file_response = client.files.content(batch_response.output_file_id)\n",
    "raw_responses = file_response.text.strip().split('\\n')\n",
    "\n",
    "# Set text color to blue\n",
    "print(\"\\033[1;34m\")\n",
    "\n",
    "formatted_json_list = []\n",
    "\n",
    "for raw_response in raw_responses:\n",
    "    try:\n",
    "        # Parse the JSON string\n",
    "        parsed_json = json.loads(raw_response)\n",
    "        formatted_json_list.append(parsed_json)\n",
    "        # Format the JSON with indentation\n",
    "        formatted_json = json.dumps(parsed_json, indent=5)\n",
    "        # Print the formatted JSON\n",
    "        print(formatted_json)\n",
    "    \n",
    "    except json.JSONDecodeError as e:\n",
    "        # Handle the case where a line isn't a valid JSON\n",
    "        print(f\"Error decoding JSON: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a78b658f",
   "metadata": {},
   "source": [
    "## Saving batch job output file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3dfd120d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results has been saved to results/batch_text_results.json\n",
      "\n"
     ]
    }
   ],
   "source": [
    "result_file = os.path.join(RESULTS_DIR, \"batch_text_results.json\")\n",
    "\n",
    "with open(result_file, 'w') as output_file:\n",
    "    json.dump(formatted_json_list, output_file, indent=5)\n",
    "\n",
    "print(f\"Results has been saved to {result_file}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "5fcb7624",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-rwxrwxrwx 1 root root 20K Sep  6 08:51 results/batch_text_results.json\r\n"
     ]
    }
   ],
   "source": [
    "!ls $result_file -lh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d702885e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "********** Result task-0 **********\n",
      "\n",
      "Prompt: Hello. Who are you?\n",
      "\n",
      "\u001b[1;31;34mAnswer: Hello! I'm an AI assistant here to help you find information, answer questions, and provide assistance with various topics. How can I help you today?\n",
      "\u001b[0m\n",
      "********** Result task-1 **********\n",
      "\n",
      "Prompt: What is Azure OpenAI?\n",
      "\n",
      "\u001b[1;31;34mAnswer: Azure OpenAI is a service provided by Microsoft Azure that offers access to OpenAI's sophisticated language models, such as GPT-3, through Azure's cloud platform. This service allows developers, enterprises, and data scientists to incorporate advanced artificial intelligence capabilities into their applications more easily and securely. \n",
      "\n",
      "Key features of Azure OpenAI include:\n",
      "\n",
      "1. **Integration with Azure Services**: Seamlessly integrates with other Azure services, providing robust infrastructure, easy scalability, and enhanced security features.\n",
      "\n",
      "2. **API Accessibility**: Provides APIs that developers can use to integrate OpenAI's models into their applications, enabling functionalities like natural language understanding, text generation, translation, summarization, and more.\n",
      "\n",
      "3. **Enterprise-grade Security and Compliance**: Combines OpenAI's machine learning capabilities with Azure’s industry-leading security, compliance, and enterprise-grade support.\n",
      "\n",
      "4. **Customizability**: Allows for fine-tuning and customizing AI models to better fit specific use cases or industries.\n",
      "\n",
      "5. **Scalability**: Takes advantage of Azure's global scalability to handle the computational requirements of deploying large language models.\n",
      "\n",
      "Azure OpenAI aims to democratize access to powerful AI models, enabling organizations to build innovative solutions with advanced capabilities in natural language processing and understanding.\n",
      "\n",
      "For more detailed information, you can visit the official Azure OpenAI service page on Microsoft Azure's website.\n",
      "\u001b[0m\n",
      "********** Result task-2 **********\n",
      "\n",
      "Prompt: What are Arima models?\n",
      "\n",
      "\u001b[1;31;34mAnswer: ARIMA models, which stand for AutoRegressive Integrated Moving Average models, are a class of statistical models for analyzing and forecasting time series data. They are particularly useful for data that shows evidence of non-stationarity, where things like the mean and variance change over time.\n",
      "\n",
      "Here's a breakdown of the components:\n",
      "\n",
      "1. **Autoregressive (AR) part**: This refers to a model that uses the dependent relationship between an observation and a number of lagged observations (i.e., previous time steps).\n",
      "   \n",
      "2. **Integrated (I) part**: This represents the differencing of raw observations to make the time series stationary (i.e., to remove trends and seasonality).\n",
      "\n",
      "3. **Moving Average (MA) part**: This incorporates the dependency between an observation and a residual error from a moving average model applied to lagged observations.\n",
      "\n",
      "The model is usually denoted as ARIMA(p, d, q):\n",
      "\n",
      "- **p**: the number of lag observations included in the model (i.e., the number of terms in the AR part).\n",
      "- **d**: the number of times that the raw observations are differenced.\n",
      "- **q**: the size of the moving average window (i.e., the number of terms in the MA part).\n",
      "\n",
      "### Steps to Build an ARIMA Model\n",
      "\n",
      "1. **Identification**: The first step is to make the time series stationary. You can use the Augmented Dickey-Fuller test to check stationarity and apply differencing if necessary.\n",
      "   \n",
      "2. **Parameter Estimation**: Once stationarity is achieved, you will choose the values of p, d, and q that minimize the error. Information criteria like AIC (Akaike Information Criterion) or BIC (Bayesian Information Criterion) are often used.\n",
      "\n",
      "3. **Model Fitting**: Using statistical software, you will fit the ARIMA model to the data.\n",
      "\n",
      "4. **Diagnostics**: After fitting the model, it's crucial to check the residuals (errors) of the model to ensure no patterns are left unexplained.\n",
      "\n",
      "5. **Forecasting**: Once satisfied with the model's fit, you can use it to make forecasts.\n",
      "\n",
      "### Applications\n",
      "\n",
      "ARIMA models are widely used in finance (such as stock price forecasting), economics (like GDP and inflation prediction), climatology (weather forecasts), and any other domain where time series analysis is relevant.\n",
      "\n",
      "### Software for ARIMA\n",
      "\n",
      "Many statistical software packages support ARIMA modeling, such as:\n",
      "\n",
      "- R (using the `forecast` and `TSA` packages)\n",
      "- Python (using the `statsmodels` library)\n",
      "- SAS\n",
      "- SPSS\n",
      "- EViews\n",
      "\n",
      "### Advantages\n",
      "\n",
      "- Flexibility: ARIMA models can handle various types of time series data.\n",
      "- Comprehensive: By combining AR and MA components with differencing, ARIMA can model a wide range of time series patterns.\n",
      "\n",
      "### Limitations\n",
      "\n",
      "- Complexity: Identifying the correct values for p, d, and q can be challenging.\n",
      "- Stationarity Requirement: The time series must be made stationary before modeling.\n",
      "- Data Requirement: ARIMA needs a sufficiently large dataset to provide good forecasts.\n",
      "\n",
      "Overall, ARIMA models are a powerful tool for time series forecasting, especially when data exhibits complex patterns that simpler models can't capture.\n",
      "\u001b[0m\n",
      "********** Result task-3 **********\n",
      "\n",
      "Prompt: Translate this from English to French: 'Welcome'\n",
      "\n",
      "\u001b[1;31;34mAnswer: The French translation for 'Welcome' is 'Bienvenue'.\n",
      "\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "with open(result_file, 'r') as file:\n",
    "    data = json.load(file)\n",
    "\n",
    "# First, sort the data by custom_id\n",
    "sorted_data = sorted(data, key=lambda x: x[\"custom_id\"])\n",
    "\n",
    "# Print the results in alphabetical order of custom_id\n",
    "for prompt, item in zip(prompts, sorted_data):\n",
    "    customid = item[\"custom_id\"]\n",
    "    result = item[\"response\"][\"body\"][\"choices\"][0][\"message\"][\"content\"]\n",
    "    print(f\"********** Result {customid} **********\\n\")\n",
    "    print(f\"Prompt: {prompt}\\n\")\n",
    "    print(f\"\\033[1;31;34mAnswer: {result}\\n\\033[0m\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dc81067",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10 - SDK v2",
   "language": "python",
   "name": "python310-sdkv2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
